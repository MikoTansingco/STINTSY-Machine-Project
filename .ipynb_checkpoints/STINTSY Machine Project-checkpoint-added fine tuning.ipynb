{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>STINTSY Machine Project</h2>\n",
    "\n",
    "Group Doc OCT (Patrick Ong, Russel Campol, Miko Tansingco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Library Importing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from random import *\n",
    "#imports for image reading\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "#imports for label encoding for classes\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization,Flatten,GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras import callbacks\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Exploratory Data Analysis</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analysis of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10217</th>\n",
       "      <td>ffd25009d635cfd16e793503ac5edef0</td>\n",
       "      <td>borzoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10218</th>\n",
       "      <td>ffd3f636f7f379c51ba3648a9ff8254f</td>\n",
       "      <td>dandie_dinmont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>ffe2ca6c940cddfee68fa3cc6c63213f</td>\n",
       "      <td>airedale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10220</th>\n",
       "      <td>ffe5f6d8e2bff356e9482a80a6e29aac</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10221</th>\n",
       "      <td>fff43b07992508bc822f33d8ffd902ae</td>\n",
       "      <td>chesapeake_bay_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10222 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                     breed\n",
       "0      000bec180eb18c7604dcecc8fe0dba07               boston_bull\n",
       "1      001513dfcb2ffafc82cccf4d8bbaba97                     dingo\n",
       "2      001cdf01b096e06d78e9e5112d419397                  pekinese\n",
       "3      00214f311d5d2247d5dfe4fe24b2303d                  bluetick\n",
       "4      0021f9ceb3235effd7fcde7f7538ed62          golden_retriever\n",
       "...                                 ...                       ...\n",
       "10217  ffd25009d635cfd16e793503ac5edef0                    borzoi\n",
       "10218  ffd3f636f7f379c51ba3648a9ff8254f            dandie_dinmont\n",
       "10219  ffe2ca6c940cddfee68fa3cc6c63213f                  airedale\n",
       "10220  ffe5f6d8e2bff356e9482a80a6e29aac        miniature_pinscher\n",
       "10221  fff43b07992508bc822f33d8ffd902ae  chesapeake_bay_retriever\n",
       "\n",
       "[10222 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breed\n",
       "weimaraner               85\n",
       "bluetick                 85\n",
       "african_hunting_dog      86\n",
       "schipperke               86\n",
       "kelpie                   86\n",
       "english_foxhound         86\n",
       "bouvier_des_flandres     86\n",
       "collie                   87\n",
       "old_english_sheepdog     87\n",
       "boston_bull              87\n",
       "irish_setter             88\n",
       "sealyham_terrier         88\n",
       "rhodesian_ridgeback      88\n",
       "dandie_dinmont           89\n",
       "bedlington_terrier       89\n",
       "silky_terrier            90\n",
       "lhasa                    90\n",
       "border_terrier           91\n",
       "newfoundland             91\n",
       "ibizan_hound             91\n",
       "pembroke                 92\n",
       "italian_greyhound        92\n",
       "chow                     93\n",
       "pug                      94\n",
       "norwegian_elkhound       95\n",
       "whippet                  95\n",
       "siberian_husky           95\n",
       "papillon                 96\n",
       "saluki                   99\n",
       "lakeland_terrier         99\n",
       "irish_wolfhound         101\n",
       "miniature_pinscher      102\n",
       "blenheim_spaniel        102\n",
       "australian_terrier      102\n",
       "japanese_spaniel        105\n",
       "beagle                  105\n",
       "cairn                   106\n",
       "leonberg                106\n",
       "tibetan_terrier         107\n",
       "airedale                107\n",
       "samoyed                 109\n",
       "basenji                 110\n",
       "pomeranian              111\n",
       "great_pyrenees          111\n",
       "shih-tzu                112\n",
       "bernese_mountain_dog    114\n",
       "entlebucher             115\n",
       "afghan_hound            116\n",
       "maltese_dog             117\n",
       "scottish_deerhound      126\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_plot = data.groupby('breed')['id'].count().sort_values()\n",
    "data_plot.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Count Per Breed'}, ylabel='breed'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABRYAAArNCAYAAABpanPbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzde5heVX33//fHBMM5PCraSNVYjSByCDKgHEWltDUeoGJR0YJa8UytP7RptYq2aqy2olLUaBU81AOKFk0rKJXzcQIhCXjgeSQ+Fn1UqkY5iBq+vz/uNXI7zCE7mck9Sd6v65pr9r322mt998xIruvjWnunqpAkSZIkSZKkLu4z6AIkSZIkSZIkbX4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmS1luSE5NcOug6JEnS4BksSpIkabOV5LlJhpPcluQHSf4zyaGbYN5K8sgJzp+YZF2r6+dJViR56hTN3T/2bUm+k+RlUzG2JElSFwaLkiRJ2iwleQ1wGvA24EHAQ4EzgGcMsKx+V1TVjsAuwL8Cn01yvy4DJJk90dht/GOBf0yyX8cxJEmSNorBoiRJkjY7SeYCbwFeUVXnVNXtVfXrqvpSVb229ZmT5LQk329fpyWZ087daztv/yrEJGcm+Zcky5L8IslVSR7Rzl3cLrm+rRg8bqJaq+pu4CPAdsAftLreleT/Jvlhkg8k2a6NfUSS/07y10n+H/DRyX4WVXUt8A3g0W2M+e1eXpTk/wL/1dpfmOQbSX6a5LwkD+u79z2SfDXJT5J8K8mf9Z27f5Jz28rLq4FHTFaTJEnaOhgsSpIkaXN0ELAt8IUJ+rweeDywENgXOBB4Q4c5ngO8GfhfwP8G3gpQVYe38/u2VYOfmWiQtmLwL4DbgJuAdwCPanU9EtgNeGPfJb8H3A94GHDSZEUmOaCNNzzq1BPohY1/lORo4G+BPwV2BS4BPtWu3wH4KvBvwAPbfZ+R5DFtnH8BfgnMA17YviRJkgwWJUmStFm6P3BrVf1mgj7HA2+pqh9V1Y/phYTP7zDHOVV1dZvjk/SCwC4en+RnwP+jF9YdA/wceDHwV1X1k6r6Bb2t3M/uu+5u4E1VdVdV3TnR2EluA64GPk4vtOx3alvJeSfwEuDtVfWNdj9vAxa2VYtPBdZU1Uer6jdtBeTngWOTzAKeCbyxjbUaOKvjz0GSJG2hfN6KJEmSNkf/AzwgyewJwsUHA9/t+/zd1ra+/l/f8R3Ajt1K5Mqq+p0XySR5ILA9sDzJb5uBWX3dflxVv1zfsZM8iN7qw7cBf9PX53t9xw8D3pPkn/rLobda8mHA41oIOmI2vbBy13bcP1b/z1SSJG3FXLEoSZKkzdEV9LbnHj1Bn+/TC81GPLS1AdxOL+ADIMnvTXF947kVuBN4TFXt0r7mtpewjKguA1bVD+mtMHza6FN9x98DXtI35y5VtV1VXd7OXTTq3I5V9TLgx8BvgIf0jfXQLvVJkqQtl8GiJEmSNjtVtZbecwn/JcnRSbZPsk2SP0nyj63bp4A3JNk1yQNa/0+0c9cDj0myMMm2wKkdS/gh8AcbUPfdwIeAd7fViyTZLckfdR1rRJL709tmfcME3T4A/M3IcxOTzE3yrHbuy8Cjkjy//Qy3SXJAkkdX1TrgHODU9jPeEzhhQ2uVJElbFoNFSZIkbZaq6p+B19B7IcuP6a28eyXwxdblH+i90GQlsAq4trVRVd+m91bpr9F7NuHvvCF6PZwKnNWec/hnk3Ue5a/pvQzmyiQ/bzXs3nGMg9obqW+j90boHwOvGq9zVX2B3ktjPt3mXA38STv3C+Aoes95/D69LeDvAOa0y19Jbxv4/wPOZD3eVC1JkrYOqeq000KSJEmSJEmSXLEoSZIkSZIkqTuDRUmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOps96AKkqfSABzyg5s+fP+gyJEmSJEmSthjLly+/tap2Hd1usKgtyvz58xkeHh50GZIkSZIkSVuMJN8dq92t0JIkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTOfMaitiirblnL/MXLBl2GJEmSJEnaSq1ZsmjQJWwyrliUJEmSJEmS1JnBoiRJkiRJkqTODBY3oSQLkzyl7/MRSQ7u+/zSJH8+wfWnJjllA+fe4Gunc6wOc16YZGhTzilJkiRJkqTx+YzFTWshMAT8R/t8BHAbcDlAVX1gIFV1kMS/GUmSJEmSJLlisYskOyRZluT6JKuTHJfkgCSXt7ark+yUZNskH02yKsl1SZ6Y5L7AW4DjkqxI8tfAS4G/ap8P618JmOTkJDcmWZnk031l7NlW730nycmT1Pv6JN9K8jVg9772RyT5SpLlSS5Jskdr3zXJ55Nc074Oae2nJlma5HzgYxPVkeQ17WezOsmrW9v8JKv7+pyS5NR2fGGSd7Sf3beTHNbat0vy6Xb/nwG224BfmSRJkiRJkqaJq8+6+WPg+1W1CCDJXOA64LiquibJzsCdwF8CVNXeLbQ7H3gU8EZgqKpe2a7fDritqt7VPj+5b67FwMOr6q4ku/S17wE8EdgJ+FaS91fVr0cXmmR/4NnAfvR+z9cCy9vppcBLq+qmJI8DzgCeBLwHeHdVXZrkocB5wKPbNfsDh1bVnS0UvFcdwD7AC4DHAQGuSnIR8NNJfq6zq+rAtk38TcCRwMuAO6pqnyT7tPrHlOQk4CSAWTvvOslUkiRJkiRJmgoGi92sAt6V5B3Al4GfAT+oqmsAqurnAEkOBd7X2r6Z5Lv0gsUuVgKfTPJF4It97cuq6i7griQ/Ah4E/PcY1x8GfKGq7mg1ndu+7wgcDJydZKTvnPb9SHorEUfad06yUzs+t6runKSOQ9uct7e5zml1nDvJvZ7Tvi8H5rfjw4H3AlTVyiQrx7u4qpbSC0uZM29BTTKXJEmSJEmSpoDBYgdV9e22EvApwNvprUQcK8jKGG1dLaIXrj0d+Lskj2ntd/X1WcfEv8OxarsP8LOqWjjOuYNGBYi0oPH2UX3HqmO8+/4Nv7vtfttxxhp9P4aEkiRJkiRJM5TPWOwgyYPpbc/9BPAu4PHAg5Mc0M7v1F5ucjFwfGt7FPBQ4FvAL+htHR4x+vPIPPcBHlJVXwdeB+wC7Nix3IuBY9qzCncCnga/XVV5c5JntbmSZN92zfnAK/vqWLgBcx6dZPskOwDHAJcAPwQemOT+SeYAT13PsUZ+hnvR22YtSZIkSZKkGcIVi93sDbwzyd3Ar+k9BzDA+9rzEu+kt534DOADSVbRW613YntW4teBxUlW0Fvx+CXgc0meAbyqb55ZwCfaMxxD77mHP+vbojypqrq2vfRkBfBdegHfiOOB9yd5A7AN8GngeuBk4F/atuORgPSlHec8E7i6NX24qq4DSPIW4CrgZuCb6zHc+4GPtlpW9I0pSZIkSZKkGSBV7jbVlmPOvAU174TTBl2GJEmSJEnaSq1ZsmjQJUy5JMuramh0uysWtUXZe7e5DG+B/wOWJEmSJEmaaQwWN3NJ7g9cMMapJ1fV/2zqeiRJkiRJkrR1MFjczLXwcOGg65AkSZIkSdLWxbdCS5IkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdzR50AdJUWnXLWuYvXjboMiRJkiRJ2mKsWbJo0CVohnLFoiRJkiRJkqTODBYlSZIkSZIkdWawuBVKckSSL/cdHzyAGk5NcsqmnleSJEmSJElTw2BRRwCbPFiUJEmSJEnS5s1gcTOVZH6Sbyb5cJLVST6Z5MgklyW5KcmB7evyJNe177uPHgN4KfBXSVYkOSzJrkk+n+Sa9nVI6/uE1mdFG2+n1v7a1m9lkjdPUvPrk3wrydeA3fvaFya5so3xhST/q7Uf0NquSPLOJKun9qcoSZIkSZKkDWWwuHl7JPAeYB9gD+C5wKHAKcDfAt8EDq+q/YA3Am/rv7iq1gAfAN5dVQur6pI23rur6gDgmcCHW/dTgFdU1ULgMODOJEcBC4ADgYXA/kkOH6vQJPsDzwb2A/4UOKDv9MeAv66qfYBVwJta+0eBl1bVQcC68X4ISU5KMpxkeN0da8f9YUmSJEmSJGnqzB50AdooN1fVKoAkNwAXVFUlWQXMB+YCZyVZABSwzXqMeSSwZ5KRzzu31YmXAf+c5JPAOVX13y1YPAq4rvXdkV7QePEY4x4GfKGq7mj1ntu+zwV2qaqLWr+zgLOT7ALsVFWXt/Z/A546VsFVtRRYCjBn3oJaj3uUJEmSJEnSRjJY3Lzd1Xd8d9/nu+n9bv8e+HpVHdO2PV+4HmPeBzioqu4c1b4kyTLgKcCVSY4EAry9qj64nvV2Cf0yeRdJkiRJkiQNiluht2xzgVva8Ynj9PkFsFPf5/OBV458SLKwfX9EVa2qqncAw/S2Xp8HvDDJjq3PbkkeOM48FwPHJNmurYB8GkBVrQV+muSw1u/5wEVV9VPgF0ke39qfvX63LEmSJEmSpE3BYHHL9o/A25NcBswap8+X6AV+K1q4dzIw1F6aciO9l7sAvLq9JOZ64E7gP6vqfHpblK9o268/x++GlL9VVdcCnwFWAJ8HLuk7fQLwziQr6T2r8S2t/UXA0iRX0FvB6AMUJUmSJEmSZohU+Ug6zUxJdqyq29rxYmBeVf3lRNcMDQ3V8PDwJqlPkiRJkiRpa5BkeVUNjW73GYuayRYl+Rt6f6ffZfzt3JIkSZIkSdrEDBY1pZLcH7hgjFNPrqr/6TJWVX2G3vZpSZIkSZIkzTAGi5pSLTxcOOg6JEmSJEmSNL18eYskSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1NnsQRcgTaVVt6xl/uJlgy5DkiRJkqTNwpoliwZdgjZjrliUJEmSJEmS1JnBoiRJkiRJkqTODBY3M0meleQbSb4+Sb/bprGG+UlWT9f448x5YpLTN+WckiRJkiRJGp/B4ubnRcDLq+qJgy5EkiRJkiRJWy+DxRksyReTLE9yQ5KTkrwROBT4QJJ3Jtk+yWeTrEzymSRXJRnqu/6tSa5PcmWSB7W2p7V+1yX5Wl/7qUk+kuTCJN9JcvIk5c1K8qFW2/lJtmvjLGzzrUzyhST/q7VfOFJbkgckWdOOT0xyTpKvJLkpyT/21f+CJN9OchFwyAQ/p5OSDCcZXnfH2g34SUuSJEmSJKkrg8WZ7YVVtT8wBJwM/AswDBxfVa8FXg78tKr2Af4e2L/v2h2AK6tqX+Bi4MWt/VLg8VW1H/Bp4HV91+wB/BFwIPCmJNtMUNsC4F+q6jHAz4BntvaPAX/daloFvGk97nMhcBywN3BckockmQe8mV6g+IfAnuNdXFVLq2qoqoZmbT93PaaTJEmSJEnSxpo96AI0oZOTHNOOH0IvzOt3KPAegKpanWRl37lfAV9ux8vphXMAvw98pgV39wVu7rtmWVXdBdyV5EfAg4D/Hqe2m6tqRd/485PMBXapqota+1nA2etxnxdU1VqAJDcCDwMeAFxYVT9u7Z8BHrUeY0mSJEmSJGkTcMXiDJXkCOBI4KC26vA6YNvR3SYY4tdVVe14HfeEyO8DTq+qvYGXjBrzrr7j/mvG0qUvwG+45+9t9H2MN1YhSZIkSZKkGclgceaaS2+b8x1J9gAeP0afS4E/A0iyJ72txOsz7i3t+ISpKHREW3X40ySHtabnAyOrF9dwz1btY9djuKuAI5Lcv23JftZU1ipJkiRJkqSN41bomesrwEvb9uZvAVeO0ecM4KzW5zpgJTDZ20tOBc5Ocksb8+FTVnHPCfReLrM98B3gBa39XcBnkzwf+K/JBqmqHyQ5FbgC+AFwLTBrimuVJEmSJEnSBso9u2W1uUkyC9imqn6Z5BHABcCjqupXAy5tYIaGhmp4eHjQZUiSJEmSJG0xkiyvqqHR7a5Y3LxtD3y9bRUO8LKtOVSUJEmSJEnSpmOwuBmrql8A90qLp0qS+9NbBTnak6vqf6ZrXkmSJEmSJM18BosaVwsPFw66DkmSJEmSJM08vhVakiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnc0edAHSVFp1y1rmL1426DIkSZIkSZoR1ixZNOgStAVzxaIkSZIkSZKkzgwWt0JJjk6yZ9/nM5McO8k1FyYZmoK5J51LkiRJkiRJM5/B4tbpaGDPyTrNNOnxb1aSJEmSJGkGMKTZQiR5XpKrk6xI8sEks5LcluStSa5PcmWSByU5GHg68M7W9xGjxtk/yUVJlic5L8m8vtPPS3J5ktVJDmz9T01ySt/1q5PMb8d/nmRlm//jfeMc3sb5Tv/qxSSvTXJNu+bNrW1+km8kOQO4FnjIFP/oJEmSJEmStAEMFrcASR4NHAccUlULgXXA8cAOwJVVtS9wMfDiqrocOBd4bVUtrKr/0zfONsD7gGOran/gI8Bb+6baoaoOBl7ezk1U02OA1wNPavP/Zd/pecChwFOBJa3/UcAC4EBgIbB/ksNb/92Bj1XVflX13S4/G0mSJEmSJE0P3wq9ZXgysD9wTRKA7YAfAb8Cvtz6LAf+cJJxdgf2Ar7axpkF/KDv/KcAquriJDsn2WWCsZ4EfK6qbm3X/KTv3Ber6m7gxiQPam1Hta/r2ucd6QWN/xf4blVdOd5ESU4CTgKYtfOuk9yiJEmSJEmSpoLB4pYhwFlV9Te/05icUlXVPq5j8t93gBuq6qBxztcYn3/D76583bZvrNH9R9w1as6R72+vqg/+TkG9bdW3T1R0VS0FlgLMmbdgvDklSZIkSZI0hdwKvWW4ADg2yQMBktwvycMm6P8LYKcx2r8F7JrkoDbONm1L84jjWvuhwNqqWgusAR7b2h8LPLyvpj9Lcv+Rmia5h/OAFybZsfXfbeR+JEmSJEmSNPO4YnELUFU3JnkDcH57a/KvgVdMcMmngQ8lORn47ctTqupX7WUq700yl97fx2nADa3LT5NcDuwMvLC1fR748yQrgGuAb7exbkjyVuCiJOvobXE+cYJ7OL89K/KKtg37NuB59FZaSpIkSZIkaYbJPTtlpc3fnHkLat4Jpw26DEmSJEmSZoQ1SxYNugRtAZIsr6qh0e1uhZYkSZIkSZLUmVuhtUXZe7e5DPv/xkiSJEmSJE07VyxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmezB12ANJVW3bKW+YuXDboMSZIkSZKm3ZoliwZdgrZyrliUJEmSJEmS1JnBoiRJkiRJkqTOtopgMcn8JKsHXcdMluSIJAevR7+nJ1k8BfOdmeTYjR1HkiRJkiRJg+EzFieRZHZV/WbQdWwCRwC3AZdP1KmqzgXO3RQFSZIkSZIkaebaKlYsNrOTnJVkZZLPJdk+yf5JLkqyPMl5SeYBJLkwyduSXAT8Zfv8jiRXJ/l2ksNav1lJ3pnkmjbuS1r7vCQXJ1mRZHVf/6OSXJHk2iRnJ9lxvGKTrGk1XJFkOMljW43/J8lLW5+0+VcnWZXkuNZ+RJIv9411epIT+8Z9c6thVZI9kswHXgr8Vav5sCRPS3JVkuuSfC3Jg9r1JyY5vR2fmeS9SS5P8p2JViC2Wk9PcmOSZcAD+849uc2zKslHksxp7U9J8s0kl7Z5vjze+JIkSZIkSdq0tqZgcXdgaVXtA/wceAXwPuDYqtof+Ajw1r7+u1TVE6rqn9rn2VV1IPBq4E2t7UXA2qo6ADgAeHGShwPPBc6rqoXAvsCKJA8A3gAcWVWPBYaB10xS8/eq6iDgEuBM4Fjg8cBb2vk/BUbmOBJ450g4OolbWw3vB06pqjXAB4B3V9XCqroEuBR4fFXtB3waeN04Y80DDgWeCiyZYM5j6P0O9gZeDBwMkGTbdm/HVdXe9FbRvqy1fxD4k6o6FNh1vIGTnNTC1+F1d6xdj9uXJEmSJEnSxtqatkJ/r6oua8efAP4W2Av4ahKAWcAP+vp/ZtT157Tvy4H57fgoYJ++lXpzgQXANcBHkmwDfLGqViR5ArAncFmb777AFZPUPLLleBWwY1X9AvhFkl8m2YVeoPepqloH/LCtsDyAXnA6kf57+dNx+vw+8JkWVN4XuHmcfl+sqruBG0dWNY7j8L5av5/kv1r77sDNVfXt9vkseqHvhcB3qmpk3k8BJ401cFUtBZYCzJm3oCaoQZIkSZIkSVNkawoWRwdOvwBuaCsCx3L7qM93te/ruOfnFuBVVXXe6IuTHA4sAj6e5J3AT4GvVtVzOtQ8Mufdfccjn2e3+cfyG353Neq244zbfy+jvQ/456o6N8kRwKmT1MgE9YwYK/Qb75rJxpIkSZIkSdIAbU1boR+aZCREfA5wJbDrSFuSbZI8puOY59HbtrtNG+NRSXZI8jDgR1X1IeBfgce2+Q5J8sjWd/skj9rIe7oYOK4963FXeqsCrwa+C+yZZE6SucCT12OsXwA79X2eC9zSjk/YyDpHan12q3Ue8MTW/k1g/sjPBXg+cFFr/4P2/EeA46agBkmSJEmSJE2RrWnF4jeAE5J8ELiJ3oq884D3tvBtNnAacEOHMT9Mb1v0tentb/4xcDS9Nyy/Nsmv6b1p+c+r6sftBSqfGnk5Cb1nLn6bDfcF4CDgenqrAV9XVf8PIMlngZX07vW69RjrS8DnkjwDeBW9FYpnJ7mFXij68I2oc6TWJ9Hb1v1teuEhVfXLJC9oc82mt438A1V1V5KXA19Jciu9wFSSJEmSJEkzRKp8JJ1mpiQ7VtVtLbT9F+Cmqnr3RNcMDQ3V8PDwpilQkiRJkiRpK5BkeVUNjW7fmrZCa/Pz4iQr6K0inUvvLdGSJEmSJEmaAbamrdAzUpIvcO9txn891gthNgdJ9gY+Pqr5rqp6XNex2urECVcoSpIkSZIkaTAMFgesqo4ZdA1TqapWAQsHXYckSZIkSZKml1uhJUmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTOZg+6AGkqrbplLfMXLxt0GZIkSZIkTWjNkkWDLkHaaK5YlCRJkiRJktSZwaLWS5I1SR4wRvvTkyxux2cmOXY9xjo6yZ7TUackSZIkSZI2DYNFbZSqOreqlnS87GjAYFGSJEmSJGkzZrCoe0myQ5JlSa5PsjrJce3Uq5Jcm2RVkj1a3xOTnN53+eFJLk/ynbFWLyY5GHg68M4kK5Ic0r6PfK1L8rDRqx+T3Dad9yxJkiRJkqRuDBY1lj8Gvl9V+1bVXsBXWvutVfVY4P3AKeNcOw84FHgqcK+VjFV1OXAu8NqqWlhVl7XvC4EPAZ+vqu92KTbJSUmGkwyvu2Ntl0slSZIkSZK0gQwWNZZVwJFJ3pHksKoaSevOad+XA/PHufaLVXV3Vd0IPGh9J0xyCPAXwAu7FltVS6tqqKqGZm0/t+vlkiRJkiRJ2gCzB12AZp6q+naS/YGnAG9Pcn47dVf7vo7x/3bu6jsOQJK3Aova2AtHX5BkHvCvwNOramTL829owXeSAPfd0PuRJEmSJEnS1HPFou4lyYOBO6rqE8C7gMduzHhV9fq+7c4AvwB2anNtA3wW+Ouq+nbfZWuA/dvxM4BtNqYGSZIkSZIkTS2DRY1lb+DqJCuA1wP/MMXjfxp4bZLrgIOBA4A3973A5cH0nrf4hCRXA48Dbp/iGiRJkiRJkrQRUlWDrkGaMnPmLah5J5w26DIkSZIkSZrQmiWLBl2CtN6SLK+qodHtPmNRW5S9d5vLsP9xliRJkiRJmnZuhZYkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzmYPugBpKq26ZS3zFy8bdBmSJEmSpK3cmiWLBl2CNO1csShJkiRJkiSpM4PFLVSSo5PsOeg6JEmSJEmStGUyWNwMJNmQLetHA9MWLG5gTZIkSZIkSdpCGCzOAEn+Lsk3k3w1yaeSnJLkwiRvS3IR8JdJ9k9yUZLlSc5LMq9d++Ik1yS5Psnnk2yf5GDg6cA7k6xI8ohx5r0wyWlJLk+yOsmBSe6T5KYku7Y+90nyv5M8IMmZSf45ydeBdyR5RJKvtJouSbJHu+bMJO9t434nybF9c7621bsyyZv72p+X5OpW7weTzGpfZ7baViX5q+n7LUiSJEmSJKkLV50NWJIh4JnAfvR+H9cCy9vpXarqCUm2AS4CnlFVP05yHPBW4IXAOVX1oTbWPwAvqqr3JTkX+HJVfW6SEnaoqoOTHA58pKr2SvIJ4HjgNOBI4PqqujUJwKOAI6tqXZILgJdW1U1JHgecATypjTsPOBTYAzgX+FySo4AFwIFAgHPbvD8GjgMOqapfJzmjzX8DsFtV7dXub5euP19JkiRJkiRND4PFwTsU+PequhMgyZf6zn2mfd8d2Av4agv3ZgE/aOf2aoHiLsCOwHkd5/8UQFVdnGTnFt59BPh3esHiC4GP9vU/u4WKOwIHA2e3mgDm9PX7YlXdDdyY5EGt7aj2dV37vCO9oHEfYH/gmjbWdsCPgC8Bf5DkfcAy4PyxbiDJScBJALN23rXj7UuSJEmSJGlDGCwOXiY4d3tfnxuq6qAx+pwJHF1V1yc5ETii4/w1+nNVfS/JD5M8CXgcvdWDo2u6D/Czqlo4zrh39R2n7/vbq+qD/R2TvAo4q6r+ZvQgSfYF/gh4BfBn9ILO0QUvBZYCzJm3YPT9SJIkSZIkaRr4jMXBuxR4WpJt2yrARWP0+Rawa5KDAJJsk+Qx7dxOwA/adun+APAX7dxkjmtjHgqsraq1rf3DwCeAz1bVutEXVdXPgZuTPKtdnxYCTuQ84IXtPkmyW5IHAhcAx7ZjktwvycOSPAC4T1V9Hvg74LHrcT+SJEmSJEnaBFyxOGBVdU17HuL1wHeBYWDtqD6/ai9AeW+SufR+b6fRewbh3wFXtWtXcU+Y+GngQ0lOBo6tqv8zTgk/TXI5sDO/uxrwXHpboD865lU9xwPvT/IGYJs25/UT3Ov5SR4NXNG2PN8GPK+qbmxjnJ/kPsCv6a1QvBP4aGsDuNeKRkmSJEmSJA1Gqtw5OmhJdqyq25JsD1wMnFRV126CeS8ETqmq4THODQHvrqrDpruOqTRn3oKad8Jpgy5DkiRJkrSVW7NkrA2J0uYpyfKqGhrd7orFmWFpkj2Bbek9a3DaQ8WJJFkMvIzf3VotSZIkSZIk/ZYrFrcCSf4FOGRU83uqaqJtzpuloaGhGh6+1wJMSZIkSZIkbSBXLG7FquoVg65BkiRJkiRJWxbfCi1JkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKmz2YMuQJpKq25Zy/zFywZdhiRJkiRpK7dmyaJBlyBNO1csSpIkSZIkSerMYFEDkeTpSRYPug5JkiRJkiRtGLdCa6MkCZCqurvLdVV1LnDu9FQlSZIkSZKk6eaKxS1EkvlJvpnkrCQrk3wuyfZJnpzkuiSrknwkyZzWf02StyW5IslwkscmOS/J/0ny0r5xX5vkmjbmm/vm+kaSM4BrgYckeX8b54aRfn3zvDnJta2GPVr7iUlOb8dPS3JVq/NrSR7U2k9tNV+Y5DtJTt50P1FJkiRJkiRNxGBxy7I7sLSq9gF+DrwGOBM4rqr2prdC9WV9/b9XVQcBl7R+xwKPB94CkOQoYAFwILAQ2D/J4X1zfayq9quq7wKvr6ohYB/gCUn26Zvn1qp6LPB+4JQx6r4UeHxV7Qd8Gnhd37k9gD9qNbwpyTZdfyiSJEmSJEmaegaLW5bvVdVl7fgTwJOBm6vq263tLODwvv4jW5FXAVdV1S+q6sfAL5PsAhzVvq6jtzJxD3pBI8B3q+rKvrH+LMm1re9jgD37zp3Tvi8H5o9R9+8D5yVZBby2XT9iWVXdVVW3Aj8CHjT64iQntdWSw+vuWDvG8JIkSZIkSZpqBotblurY/672/e6+45HPs4EAb6+qhe3rkVX1r63P7SOdkzyc3krEJ7fVksuAbceYZx1jP9fzfcDpbVXlS8a5dtzrq2ppVQ1V1dCs7edOeMOSJEmSJEmaGgaLW5aHJjmoHT8H+BowP8kjW9vzgYs6jHce8MIkOwIk2S3JA8fotzO9oHFtez7in3Ssey5wSzs+oeO1kiRJkiRJGgDfCr1l+QZwQpIPAjcBfwlcCZydZDZwDfCB9R2sqs5P8mjgit7Ln7kNeB69lYP9/a5Pch1wA/Ad4LLRY03i1FbjLa3eh3e8XpIkSZIkSZtYqrruntVMlGQ+8OWq2mvQtQzSnHkLat4Jpw26DEmSJEnSVm7NkkWDLkGaMkmWt5f2/g5XLGqLsvducxn2P96SJEmSJEnTzmBxC1FVa4CterWiJEmSJEmSNh1f3iJJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnc0edAHSVFp1y1rmL1426DIkSZIkSVu4NUsWDboEaeBcsShJkiRJkiSpM4NFrZck85OsHsC8/5Fkl3Z8+aaeX5IkSZIkSWNzK7RmtKp6St/xwYOsRZIkSZIkSfdwxaK6mJ3krCQrk3wuyfZJ3pjkmiSrkyxNEoAkJye5sfX9dGvbIclHWv/rkjyjtZ+Y5JwkX0lyU5J/HJkwyZokD2jHtw3ipiVJkiRJknRvBovqYndgaVXtA/wceDlwelUdUFV7AdsBT219FwP7tb4vbW2vB/6rqg4Angi8M8kO7dxC4Dhgb+C4JA9Z36KSnJRkOMnwujvWbtwdSpIkSZIkab0YLKqL71XVZe34E8ChwBOTXJVkFfAk4DHt/Ergk0meB/ymtR0FLE6yArgQ2BZ4aDt3QVWtrapfAjcCD1vfoqpqaVUNVdXQrO3nbvjdSZIkSZIkab35jEV1UWN8PgMYqqrvJTmVXlgIsAg4HHg68HdJHgMEeGZVfat/kCSPA+7qa1qHf5uSJEmSJEkzmisW1cVDkxzUjp8DXNqOb02yI3AsQJL7AA+pqq8DrwN2AXYEzgNe1fccxv02Ye2SJEmSJEmaQq4KUxffAE5I8kHgJuD9wP8CVgFrgGtav1nAJ5LMpbdK8d1V9bMkfw+cBqxs4eIa7nkm40RGr5SUJEmSJEnSgKXKzEYzU5JZwI+A36uqX6/PNXPmLah5J5w2rXVJkiRJkrRmyaJBlyBtMkmWV9XQ6HZXLGomuwH48PqGigB77zaXYf/jLkmSJEmSNO0MFjVjVdUeg65BkiRJkiRJY/PlLZIkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjqbPegCpKm06pa1zF+8bNBlSJIkSZI2Y2uWLBp0CdJmwRWLkiRJkiRJkjozWNRmIcmpSU4ZdB2SJEmSJEnqMViUJEmSJEmS1JnB4lYuyQ5JliW5PsnqJMcleWOSa9rnpUnS+l6Y5N1JLk7yjSQHJDknyU1J/qFvzNe0a1cneXVr+/skf9nX561JTm7Hr23zrUzy5r4+r0/yrSRfA3bfVD8TSZIkSZIkTc6Xt+iPge9X1SKAJHOBr1bVW9rnjwNPBb7U+v+qqg5vIeG/A/sDPwH+T5J3A/OBFwCPAwJcleQi4F+Bc4D3JLkP8GzgwCRHAQuAA1v/c5McDtze+uxH7+/0WmD5dP4gJEmSJEmStP5csahVwJFJ3pHksKpaCzwxyVVJVgFPAh7T1//cvutuqKofVNVdwHeAhwCHAl+oqtur6jZ6YeJhVbUG+J8k+wFHAddV1f+046OA6+iFh3vQCxoPa+PcUVU/75v3XpKclGQ4yfC6O9ZOzU9FkiRJkiRJE3LF4lauqr6dZH/gKcDbk5wPvAIYqqrvJTkV2Lbvkrva97v7jkc+z6a36nA8HwZOBH4P+EhrC/D2qvpgf8e2hbrW8x6WAksB5sxbsF7XSJIkSZIkaeO4YnErl+TBwB1V9QngXcBj26lbk+wIHNtxyIuBo5Nsn2QH4BjgknbuC/S2Xh8AnNfazgNe2OYiyW5JHtjGOSbJdkl2Ap62YXcoSZIkSZKk6eCKRe0NvDPJ3cCvgZcBR9Pb6rwGuKbLYFV1bZIzgatb04er6rp27ldJvg78rKrWtbbzkzwauKK9I+Y24HltnM8AK4Dvck84KUmSJEmSpBkgVe4c1abRXtpyLfCsqrppOuaYM29BzTvhtOkYWpIkSZK0lVizZNGgS5BmlCTLq2podLtbobVJJNkT+N/ABdMVKkqSJEmSJGnTcSu0NomquhH4g+meZ+/d5jLs/7MkSZIkSZI07VyxKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdzR50AdJUWnXLWuYvXjboMiRJkiRJA7JmyaJBlyBtNVyxKEmSJEmSJKkzg0WttyT/kWSXjbj+1CSnbGwfSZIkSZIkDZ5bobXequopo9uSBEhV3T2AkiRJkiRJkjQgrljUmJJ8McnyJDckOam1rUnygCTzk3wjyRnAtcBDkrw2yTVJViZ5c984r0/yrSRfA3bva39x6399ks8n2X6MGh6R5CutjkuS7LEJbl2SJEmSJEnrwWBR43lhVe0PDAEnJ7n/qPO7Ax+rqv3a8QLgQGAhsH+Sw5PsDzwb2A/4U+CAvuvPqaoDqmpf4BvAi8aoYSnwqlbHKcAZU3Z3kiRJkiRJ2ihuhdZ4Tk5yTDt+CL3gsN93q+rKdnxU+7qufd6x9d8J+EJV3QGQ5Ny+6/dK8g/ALq3/ef2DJ9kROBg4u7fbGoA5YxXaVlSeBDBr513X/w4lSZIkSZK0wQwWdS9JjgCOBA6qqjuSXAhsO6rb7f2XAG+vqg+OGufVQI0zzZnA0VV1fZITgSNGnb8P8LOqWjhZvVW1lN7qRubMWzDefJIkSZIkSZpCboXWWOYCP22h4h7A4yfpfx7wwrbKkCS7JXkgcDFwTJLtkuwEPK3vmp2AHyTZBjh+9IBV9XPg5iTPamMmyb4bfWeSJEmSJEmaEq5Y1Fi+Arw0yUrgW8CVE3WuqvOTPBq4om1bvg14XlVdm+QzwArgu8AlfZf9HXBVa19FL2gc7Xjg/UneAGwDfBq4fiPuS5IkSZIkSVMkVe4c1ZZjzrwFNe+E0wZdhiRJkiRpQNYsWTToEqQtTpLlVTU0ut0Vi9qi7L3bXIb9R0SSJEmSJGna+YxFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZ7MHXYA0lVbdspb5i5cNugxJkiRJ0oCsWbJo0CVIWw1XLEqSJEmSJEnqzGBRkiRJkiRJUmcGizNQkl2SvLwdPzjJ59rxiUlO7zjW305DfUcn2XMKxnl6ksVTUZMkSZIkSZI2LYPFmWkX4OUAVfX9qjp2I8aa8mAROBroFCwmmT36c1WdW1VLNnQMSZIkSZIkDY5Bzcy0BHhEkhXATcCjq2qvdu4hSb4CPBz4t6p6M0CS5wEnA/cFrqIXTL4V2K6Nc0NVHZ/ki8BDgG2B91TV0nb9bcB7gKcCdwLPqKofji4sycHA04EnJHkD8Mx26l+AXYE7gBdX1TeTnAn8BNgPuDbJ/Ud9XgUMVdUrk+wKfAB4aBvv1VV1WZJTgQcD84FbgeeOUdNJwEkAs3bedX1+vpIkSZIkSdpIBosz02Jgr6pamGQ+8OW+cwcCe9EL8K5Jsgy4HTgOOKSqfp3kDOD4qlqc5JVVtbDv+hdW1U+SbNeu/3xV/Q+wA3BlVb0+yT8CLwb+YXRhVXV5knOBL1fVyBbtC4CXVtVNSR4HnAE8qV3yKODIqlrXgsb+zyf2Df0e4N1VdWmShwLnAY9u5/YHDq2qO8f6YbVwdCnAnHkLaoKfqyRJkiRJkqaIweLm56stCCTJOcChwG/ohW/XJAHYDvjRONefnOSYdvwQYAHwP8CvuCfAXA784foUk2RH4GDg7DY3wJy+LmdX1boJPo84Etizb4ydk+zUjs8dL1SUJEmSJEnSYBgsbn5Gr8grIMBZVfU3E12Y5Ah6Ad5BVXVHkgvpbYkG+HVVjYy9jvX/27gP8LNRqyL73T7J5/5xDhodILagcbxrJEmSJEmSNCC+vGVm+gWw0zjn/jDJ/dpW5qOBy4ALgGOTPBCgnX9Y6//rJNu047nAT1uouAfw+I2tr6p+Dtyc5Flt7iTZdwPGPB945ciHJAs3sDZJkiRJkiRtAgaLM1Db6nxZktXAO0edvhT4OLAC+HxVDVfVjcAbgPOTrAS+Csxr/ZcCK5N8EvgKMLv1+Xvgyg0s8dPAa5Ncl+QRwPHAi5JcD9wAPGMDxjwZGEqyMsmNwEs3sDZJkiRJkiRtArln96u0+RsaGqrh4eFBlyFJkiRJkrTFSLK8qoZGt7tiUZIkSZIkSVJnvrxF40ryeuBZo5rPrqq3DqIeSZIkSZIkzRwGixpXCxANESVJkiRJknQvboWWJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZ7MHXYA0lVbdspb5i5cNugxJkiRJ0jRZs2TRoEuQ1LhiUZIkSZIkSVJnBosCIMlt0zDmhUmGpnpcSZIkSZIkDZ7BomakJG7TlyRJkiRJmsEMFnUvSV6b5JokK5O8ua/9NUlWt69Xt7b5Sb6R5ENJbkhyfpLt+oZ7XpLL2zUHtmt2SPKRNsd1SZ7R2k9McnaSLwHnJ9k+yWdbHZ9JcpUrICVJkiRJkmYGV4XpdyQ5ClgAHAgEODfJ4cDtwAuAx7X2q5JcBPy09X9OVb04yWeBZwKfaEPuUFUHtzE+AuwFvB74r6p6YZJdgKuTfK31PwjYp6p+kuQU4KdVtU+SvYAV033/kiRJkiRJWj8GixrtqPZ1Xfu8I73gcEfgC1V1O0CSc4DDgHOBm6tqReu/HJjfN96nAKrq4iQ7tyDxKODpLTgE2BZ4aDv+alX9pB0fCrynXb86ycqxCk5yEnASwKydd92gm5YkSZIkSVI3BosaLcDbq+qDv9PYtj6P466+43VA/1boGtW32hzPrKpvjZrjcfRWRvbXMqmqWgosBZgzb8Ho+SRJkiRJkjQNfMaiRjsPeGGSHQGS7JbkgcDFwNHtuYc7AMcAl6zHeMe1cQ4F1lbV2jbHq5KkndtvnGsvBf6s9dkT2HvDb0uSJEmSJElTyRWL+h1VdX6SRwNXtNzvNuB5VXVtkjOBq1vXD1fVdUnmTzLkT5NcDuwMvLC1/T1wGrCyhYtrgKeOce0ZwFltC/R1wEpg7QbemiRJkiRJkqZQqtw5qpkpySxgm6r6ZZJHABcAj6qqX413zZx5C2reCadtqhIlSZIkSZvYmiWLBl2CtNVJsryqhka3u2JRM9n2wNeTbEPveYsvmyhUlCRJkiRJ0qZjsKgZq6p+AdwrDZ/I3rvNZdj/90qSJEmSJGna+fIWSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSeps9qALkKbSqlvWMn/xskGXIUmSJEmaJmuWLBp0CZIaVyxKkiRJkiRJ6sxgUQOT5OlJFg+6DkmSJEmSJHXnVmgNTFWdC5w7uj3J7Kr6zQBKkiRJkiRJ0noyWNSUS/LnwClAASuBzwJvAO4L/A9wfFX9MMmJwFBVvTLJmcBPgP2Aa5PcH/g5MAT8HvC6qvrcpr4XSZIkSZIkjc1gUVMqyWOA1wOHVNWtSe5HL2B8fFVVkr8AXgf8f2Nc/ijgyKpa14LGecChwB70VjYaLEqSJEmSJM0QBouaak8CPldVtwJU1U+S7A18Jsk8eqsWbx7n2rOral3f5y9W1d3AjUkeNN6ESU4CTgKYtfOuU3EPkiRJkiRJmoQvb9FUC70Viv3eB5xeVXsDLwG2Hefa20d9vmvUuGOqqqVVNVRVQ7O2n9u1XkmSJEmSJG0Ag0VNtQuAP2vPSKRthZ4L3NLOnzCowiRJkiRJkjR13AqtKVVVNyR5K3BRknXAdcCpwNlJbgGuBB4+wBIlSZIkSZI0BVI1eteqtPmaM29BzTvhtEGXIUmSJEmaJmuWLBp0CdJWJ8nyqhoa3e6KRW1R9t5tLsP+IyNJkiRJkjTtfMaiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSps9mDLkCaSqtuWcv8xcsGXYYkSZIkaQOsWbJo0CVI6sAVi5IkSZIkSZI6M1hUJ0nmJ1m9uY4vSZIkSZKkqWGwKEmSJEmSJKkzg0VtiNlJzkqyMsnnkmyfZP8kFyVZnuS8JPMAkrw4yTVJrk/y+STbt/ZHJLmynXtLkttGT5JkVpJ3tj4rk7xkU9+oJEmSJEmSxmawqA2xO7C0qvYBfg68AngfcGxV7Q98BHhr63tOVR1QVfsC3wBe1NrfA7ynqg4Avj/OPC8C1rY+BwAvTvLw0Z2SnJRkOMnwujvWTtEtSpIkSZIkaSK+FVob4ntVdVk7/gTwt8BewFeTAMwCftDO75XkH4BdgB2B81r7QcDR7fjfgHeNMc9RwD5Jjm2f5wILgJv7O1XVUmApwJx5C2oj7kuSJEmSJEnryWBRG2J0ePcL4IaqOmiMvmcCR1fV9UlOBI7oME+AV1XVeZP2lCRJkiRJ0iblVmhtiIcmGQkRnwNcCew60pZkmySPaed3An6QZBvg+L4xrgSe2Y6fPc485wEva9eS5FFJdpjC+5AkSZIkSdIGMljUhvgGcEKSlcD9aM9XBN6R5HpgBXBw6/t3wFXAV4Fv9o3xauA1Sa4G5gFjPRzxw8CNwLVJVgMfxFW2kiRJkiRJM0KqfCSdNr32dug7q6qSPBt4TlU9Y2PHnTNvQc074bSNrk+SJEmStOmtWbJo0CVIGkOS5VU1NLrd1V8alP2B09N728vPgBdOxaB77zaXYf8hkiRJkiRJmnYGixqIqroE2HfQdUiSJEmSJGnD+IxFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnc0edAHSVFp1y1rmL1426DIkSZIkSRtgzZJFgy5BUgeuWJQkSZIkSZLUmcGiJEmSJEmSpM4MFqdZkssHXcNMl+TDSfacpM+FSYY2VU2SJEmSJEmamM9YnGZVdfCga5jpquovBl2DJEmSJEmSunHF4jRLcluSHZNckOTaJKuSPKOdm5/km0nOSrIyyeeSbN/OvTHJNUlWJ1maJK39wiTvSHJ1km8nOay1z0ryznbNyiQvae3zklycZEUba6T/UUmuaDWdnWTHCe5hSZIb27jvam1nJvlAkktaHU/tu6dL2rjXJjm4tR/Rav9cu+dPjrqnoa51SZIkSZIkaXAMFjeNXwLHVNVjgScC/zQSqgG7A0urah/g58DLW/vpVXVAVe0FbAc8tW+82VV1IPBq4E2t7UXA2qo6ADgAeHGShwPPBc6rqoXAvsCKJA8A3gAc2WoaBl4zVuFJ7gccAzym1fgPfafnA08AFgEfSLIt8CPgD9u4xwHv7eu/X6t5T+APgENGzbXedY267qQkw0mG192xdrLukiRJkiRJmgJuhd40ArwtyeHA3cBuwIPaue9V1WXt+BPAycC7gCcmeR2wPXA/4AbgS63fOe37cnrhHsBRwD5Jjm2f5wILgGuAjyTZBvhiVa1I8gR64d5lLd+8L3DFOLX/nF4w+uEky4Av9537bFXdDdyU5DvAHsDNwOlJFgLrgEf19b+6qv4bIMmKVvulfecf36Gu36qqpcBSgDnzFtRk/SVJkiRJkrTxDBY3jeOBXYH9q+rXSdYA27Zzo4Owaiv/zgCGqup7SU7t6w9wV/u+jnt+hwFeVVXnjZ68BZqLgI8neSfwU+CrVfWcyQqvqt8kORB4MvBs4JXAk8arHfgr4If0Vkfeh14oObru0bX/ttT1rUuSJEmSJEmD5VboTWMu8KMWKj4ReFjfuYcmOagdP4feCr6REPHW9ozBY5ncecDL2spEkjwqyQ5JHtbm/hDwr8BjgSuBQ5I8svXdPsmjxhq0zT+3qv6D3jbmhX2nn5XkPkkeQW9r87favf6grWR8PjBrPWofsd51SZIkSZIkabBcsTj9Cvgk8KUkw8AK4Jt9578BnJDkg8BNwPur6o4kHwJWAWvobWeezIfpbS2+tj2/8cfA0cARwGuT/Bq4DfjzqvpxkhOBTyWZ065/A/DtMcbdCfj3tooy9FYkjvgWcBG9bd0vrapfJjkD+HySZwFfB25fj9oB6FiXJEmSJEmSBihVPpJuuiS5P3BtVT1snPPzgS+3F7RsVpKcSa/2zw26ln5z5i2oeSecNugyJEmSJEkbYM2SRYMuQdIYkiyvqqHR7a5YnCZJHgxcSO9FLNpE9t5tLsP+QyRJkiRJkjTtDBanSVV9n999I/JYfdYAM2a1YpIvAA8f1fzXY70QpqpO3CRFSZIkSZIkaUYyWNRvVdUxg65BkiRJkiRJmwffCi1JkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdTZ70AVIU2nVLWuZv3jZoMuQJEmSpC3OmiWLBl2CpBnGFYuSJEmSJEmSOjNYlCRJkiRJktSZweIMl2RhkqdswHXzk6xux0NJ3jvFdf3tFI3z4SR7TsVYkiRJkiRJ2nQMFme+hcCYwWKS9XpGZlUNV9XJU1kU0DlYTDJr9Oeq+ouqunFDx5AkSZIkSdJgGCxOsyRfTLI8yQ1JTmptt/WdPzbJme34WUlWJ7k+ycVJ7gu8BTguyYokxyU5NcnSJOcDH2srEy9Jcm37OniMGo5I8uV2fGCSy5Nc177v3tpPTHJOkq8kuSnJP05wT0uA7VpNn2xtz0tydWv74EgAmOS2JG9JchVw0BifL0wy1PoeleSKdh9nJ9mxta9J8sYklwLP2tjfiSRJkiRJkjaeb4Wefi+sqp8k2Q64JsnnJ+j7RuCPquqWJLtU1a+SvBEYqqpXAiQ5FdgfOLSq7kyyPfCHVfXLJAuATwFDE8zxTeDwqvpNkiOBtwHPbOcWAvsBdwHfSvK+qvre6AGqanGSV1bVwlbTo4HjgEOq6tdJzgCOBz4G7ACsrqo3tr6jP9O+PwB4A3BkVd2e5K+B19ALVgF+WVWHjnVDLbA9CWDWzrtOcOuSJEmSJEmaKgaL0+/kJMe044cACyboexlwZpLPAudM0O/cqrqzHW8DnJ5kIbAOeNQk9cwFzmohZLXrR1xQVWsBktwIPAy4V7A4hifTCzuvaUHhdsCP2rl1QH+YOvrziMcDewKXtTHuC1zRd/4z401eVUuBpQBz5i2o9ahXkiRJkiRJG8lgcRolOQI4Ejioqu5IciGwLb1Ab8S2IwdV9dIkjwMWAStaWDiW2/uO/wr4IbAvva3tv5ykrL8Hvl5VxySZD1zYd+6uvuN1rP/fR4Czqupvxjj3y6paN8Hn/jG+WlXPGWeO28dplyRJkiRJ0gD4jMXpNRf4aQsV96C3Kg/gh0keneQ+wMhqRpI8oqquatuEb6W3wvEXwE6TzPGDqrobeD4w2ctN5gK3tOMTu95Qn18nGVnteAFwbJIHAiS5X5KHdRzvSuCQJI9sY2yfZLLVl5IkSZIkSRoQg8Xp9RVgdpKV9FYKXtnaFwNfBv4L+EFf/3cmWZVkNXAxcD3wdWDPkZe3jDHHGcAJSa6ktw16spV9/wi8PcllTB5CTmQpsDLJJ9tbnd8AnN/u9avAvC6DVdWP6QWdn2pjXAnssRH1SZIkSZIkaRqlykfSacsxNDRUw8PDgy5DkiRJkiRpi5FkeVXd62XBrliUJEmSJEmS1Jkvb9GEklwFzBnV/PyqWjWIeiRJkiRJkjQzGCxqQlX1uEHXIEmSJEmSpJnHrdCSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmezB12ANJVW3bKW+YuXDboMSZIkSdrirFmyaNAlSJphXLEoSZIkSZIkqTODxWmSZH6S1WO0X5hkaAPHPDXJKR2v+Y8ku2zIfJtKkqcnWTxJnxOTnL6papIkSZIkSdLE3Aq9hauqpwy6hslU1bnAuYOuQ5IkSZIkSevPFYvTa3aSs5KsTPK5JNv3n0xyVJIrklyb5OwkO7b2NUne3NpXJdmj77I926rH7yQ5uW+s5yW5OsmKJB9MMqtvrAe0FZTfTPLhJKuTfDLJkUkuS3JTkgPHu4kkT2jjrkhyXZKdkhyR5OIkX0hyY5IPJLlP6//+JMNJbkjy5r5xxryv/tWISXZN8vkk17SvQ6bg9yBJkiRJkqQpZrA4vXYHllbVPsDPgZePnEjyAOANwJFV9VhgGHhN37W3tvb3A/3bn/cA/gg4EHhTkm2SPBo4DjikqhYC64Djx6jnkcB7gH3aOM8FDm3j/+0E93EK8Io29mHAna39QOD/A/YGHgH8aWt/fVUNtXmekGSf9bivEe8B3l1VBwDPBD48QV0AJDmpBZnD6+5YO1l3SZIkSZIkTQG3Qk+v71XVZe34E8DJfeceD+wJXJYE4L7AFX3nz2nfl3NPYAewrKruAu5K8iPgQcCTgf2Ba9pY2wE/GqOem6tqFUCSG4ALqqqSrALmT3AflwH/nOSTwDlV9d9tnqur6jttvE/RCyk/B/xZkpPo/X3Na/e5cpL7GnEkvVWZI593TrLTBLVRVUuBpQBz5i2oifpKkiRJkiRpahgsTq/RIVf/5wBfrarnjHPtXe37On7393RX3/HIuQBnVdXfTFJP/7V3932+mwn+FqpqSZJlwFOAK5McOXJqdNckD6e3EvGAqvppkjOBbdfjvkbcBzioqu7sb+wLGiVJkiRJkjQDuBV6ej00yUHt+DnApX3nrgQOSfJIgCTbJ3nUBs5zAXBskge2se6X5GEbWvRoSR5RVauq6h30tmyPPPPxwCQPb89WPI7e/e0M3A6sTfIg4E86Tnc+8Mq+uRdubP2SJEmSJEmaegaL0+sbwAlJVgL3o/dcQQCq6sfAicCn2vkruSew66SqbqT3vMbz21hfpbcFeaq8ur3w5Xp6z1f8z9Z+BbAEWA3cDHyhqq4HrgNuAD5Cbxt1FycDQ+2FNzcCL52KG5AkSZIkSdLUSpWPpFN3SY4ATqmqpw64lN8xZ96CmnfCaYMuQ5IkSZK2OGuWLBp0CZIGJMny9qLe3+EzFrVF2Xu3uQz7j50kSZIkSdK0M1jUbyV5AfCXo5ovq6pXjO5bVRcCF26CsiRJkiRJkjQDGSzqt6rqo8BHB12HJEmSJEmSZj5f3iJJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdTZ70AVIU2nVLWuZv3jZoMuQJEmSpC3OmiWLBl2CpBnGFYuSJEmSJEmSOjNYlCRJkiRJktSZweI0SvL0JIsn6fPgJJ+bpM/8JM+d2urWX5K3JDlyCse7MMnQVI0nSZIkSZKkTc9nLE6jqjoXOHeSPt8Hjp1kqPnAc4F/6zJ/kllVta7LNWOpqjdu7BhTZaruSZIkSZIkSRvHFYsbqK0i/GaSDydZneSTSY5MclmSm5IcmOTEJKe3/mcmeW+Sy5N8J8mxfeOs7ju+JMm17evgNt0S4LAkK5L8Vf+47bovJzmiHd/WVhheBRyU5HlJrm7XfjDJrAnu6bYk/9TmviDJrn21j9S7JsmbW59VSfZo7U9oc6xIcl2SnVr761q/65Ms6ZvuWa2ubyc5rPWdleSdSa5JsjLJS1r7EUm+nuTfgFUb+auTJEmSJEnSFDBY3DiPBN4D7APsQW9V4aHAKcDfjtF/Xjv/VHph4Wg/Av6wqh4LHAe8t7UvBi6pqoVV9e5JatoBWF1VjwP+p41zSFUtBNYBx09y7bVt/ouAN43T79bW5/307pX2/RVtnsOAO5P8CXA08Liq2hf4x74xZlfVgcCr++Z5EbC2qg4ADgBenOTh7dyBwOuras/RxSQ5KclwkuF1d6yd4PYkSZIkSZI0VdwKvXFurqpVAEluAC6oqkqyit725dG+WFV3AzcmedAY57cBTk+ykF4I+KgNqGkd8Pl2/GRgf+CaJADb0Qsvx3M38Jl2/AngnHH6jbQvB/60HV8G/HOSTwLnVNV/t+cyfrSq7gCoqp+MM8b8dnwUsM/I6khgLrAA+BVwdVXdPFYxVbUUWAowZ96CmuD+JEmSJEmSNEUMFjfOXX3Hd/d9vpuxf7b9/TPG+b8CfgjsS2816S/Hmfc3/O5q0237jn/Z9wzCAGdV1d+MM85kxgvpRu5jHe0+q2pJkmXAU4ArW6iYLmO0/q+qqvP6O7Zt3rdvQP2SJEmSJEmaJm6FnlnmAj9oqxqfD4w8D/EXwE59/dYAC5PcJ8lD6G0THssFwLFJHgiQ5H5JHjbB/PfhnhfJPBe4dH0LT/KIqlpVVe8AhultDT8feGGS7Ufmn2SY84CXJdmm9X9Ukh3WtwZJkiRJkiRtOq5YnFnOAD6f5FnA17lnld5K4DdJrgfOBE4Dbqb3IpPVwLVjDVZVNyZ5A3B+kvsAvwZeAXx3nPlvBx6TZDmwlt7zGdfXq5M8kd4KxBuB/6yqu9q27uEkvwL+g7GfPTniw/S2RV+b3t7tH9N7RqMkSZIkSZJmmFT5SDr1JLmtqnYcdB0bY2hoqIaHhwddhiRJkiRJ0hYjyfKqGhrd7lZoSZIkSZIkSZ25FXorlOQqYM6o5udv7qsVJUmSJEmStOkYLG6Fqupxg65BkiRJkiRJmze3QkuSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnc0edAHSVFp1y1rmL1426DIkSZIkabOzZsmiQZcgaTPjikVJkiRJkiRJnRksSpIkSZIkSerMYHGAkly+Iefa+dumvqJ7zXFiktPb8a5JrkpyXZLDNsX8o2o5IsmXN+WckiRJkiRJGp/PWBygqjp4dFuSWVW1bqxzA/Zk4JtVdQJAkgGXI0mSJEmSpEFyxeIAjaz6a6vxvp7k34BVo87NS3JxkhVJVic5rO/6tya5PsmVSR40zhyzknwnPbskuTvJ4e3cJUkemeR+Sb6YZGUba59RYywE/hF4Sqtju/HmT/KwJBe0sS5I8tDWfmaSY8e59wuTfC7JN5N8Mi21TPLHre1S4E8n+DmelGQ4yfC6O9Z2+h1IkiRJkiRpwxgszhwHAq+vqj1HtT8XOK+qFgL7Aita+w7AlVW1L3Ax8OKxBq2qdcC3gT2BQ4HlwGFJ5gC/X1X/G3gzcF1V7QP8LfCxUWOsAN4IfKaqFlbVnRPMfzrwsTbWJ4H3rse97we8utX4B8AhSbYFPgQ8DTgM+L3xLq6qpVU1VFVDs7afux7TSZIkSZIkaWMZLM4cV1fVzWO0XwO8IMmpwN5V9YvW/itg5JmDy4H5E4x9CXB4+3o7vYDxgDY27fPHAarqv4D7J5ksoRtv/oOAf2vHH29jT+bqqvrvqrqbXnA6H9gDuLmqbqqqAj6xHuNIkiRJkiRpEzFYnDluH6uxqi6mFwjeAnw8yZ+3U79ugRvAOiZ+XuYl9Fb9HQj8B7ALcAS9lYYAYz0wscZo67e+84/0+Q3t761tdb5vX5+7+o77x5qsBkmSJEmSJA2IweIMl+RhwI+q6kPAvwKP3YBhrgIOBu6uql/SWxX4EnqBI/QCxuPbfEcAt1bVzzew5MuBZ7fj44FL2/EaYP92/Axgm0nG+Sbw8CSPaJ+fs4H1SJIkSZIkaRoYLM58RwArklwHPBN4T9cBquou4HvAla3pEmAn2otigFOBoSQrgSXACRtR78n0tm6vBJ4P/GVr/xDwhCRXA49jnBWafTX/EjgJWNZe3vLdjahJkiRJkiRJUyz37GaVNn9DQ0M1PDw86DIkSZIkSZK2GEmWV9XQ6HZXLEqSJEmSJEnqbKIXfmgzk+T1wLNGNZ9dVW8dRD2SJEmSJEnachksbkFagGiIKEmSJEmSpGnnVmhJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1NnvQBUhTadUta5m/eNmgy5AkSZKkTWrNkkWDLkHSVsgVi5IkSZIkSZI6M1iUJEmSJEmS1JnB4gAluW2S8/OTrO4w3qlJTtn4yiDJmUmOneD8q5NsPwXzvCXJkRs7jiRJkiRJkjYtg0VtqFcDnYLFJLNGf66qN1bV1zqM4XNBJUmSJEmSZgCDxRkgyY5JLkhybZJVSZ4xRp8/SHJdkgOSPCLJV5IsT3JJkj3G6P/iJNckuT7J50dWF7aViO9NcnmS74ysSkzP6UluTLIMeOAE9Z4MPBj4epKvt7ajklzR7uHsJDu29jVJ3pjkUuBZY3w+s6+G/ZNc1O7rvCTzWvuFSd6W5CLgLzfupy1JkiRJkqSpYLA4M/wSOKaqHgs8EfinJBk5mWR34PPAC6rqGmAp8Kqq2h84BThjjDHPqaoDqmpf4BvAi/rOzQMOBZ4KLGltxwC7A3sDLwYOHq/Yqnov8H3giVX1xCQPAN4AHNnuYRh4Tf/9VdWhVfXpcT6TZBvgfcCx7b4+Ary1b4xdquoJVfVPo+tJclKS4STD6+5YO17ZkiRJkiRJmkJuK50ZArwtyeHA3cBuwIPauV2BfweeWVU3tJWABwNn92WPc8YYc68k/wDsAuwInNd37otVdTdwY5KReQ4HPlVV64DvJ/mvDvU/HtgTuKzVdF/gir7znxnVf/Rn6IWaewFfbWPMAn4wyTUAVNVSemErc+YtqA51S5IkSZIkaQMZLM4Mx9MLEPevql8nWQNs286tBb4HHALcQG+V6c+qauEkY54JHF1V1yc5ETii79xdfcfpO97QUC7AV6vqOeOcv32SzyNj3FBVB63nGJIkSZIkSRogt0LPDHOBH7VQ8YnAw/rO/Qo4GvjzJM+tqp8DNyd5Fvz22Yj7jjHmTsAP2hbj49ejhouBZyeZ1Z5t+MRJ+v+izQFwJXBIkke2mrZP8qj1mLPft4BdkxzUxtgmyWM6jiFJkiRJkqRNxBWLM8MngS8lGQZWAN/sP1lVtyd5Kr1twrfTCwrfn+QNwDbAp4HrR435d8BVwHeBVdwTAo7nC8CTWt9vAxdN0n8p8J9JftCes3gi8KkkI9uy39DGWS9V9av2Epf3JplL72/zNHqrNCVJkiRJkjTDpMpH0mnLMWfegpp3wmmDLkOSJEmSNqk1SxYNugRJW7Aky6tqaHS7Kxa1Rdl7t7kM+w+qJEmSJEnStDNY1ISSfAF4+Kjmv66q88bqL0mSJEmSpK2DwaImVFXHDLoGSZIkSZIkzTy+FVqSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6mz2oAuQptKqW9Yyf/GyQZchSZIkSZvUmiWLBl2CpK2QKxYlSZIkSZIkdWawqE0myZlJjp2kz6lJThmj/S1Jjpy+6iRJkiRJktSFW6G1WaiqNw66BkmSJEmSJN3DFYvaKEl2SLIsyfVJVic5Lskbk1zTPi9NkjGuW5PkAe14KMmFY/R5cZL/TLLd+qx2lCRJkiRJ0qZjsKiN9cfA96tq36raC/gKcHpVHdA+bwc8teugSV4JPA04uqrunNKKJUmSJEmStNEMFrWxVgFHJnlHksOqai3wxCRXJVkFPAl4TMcxnw/8CfDMqrprss5JTkoynGR43R1rO9+AJEmSJEmSujNY1Eapqm8D+9MLGN+e5I3AGcCxVbU38CFg2zEu/Q33/P2NPr8amA/8/nrWsLSqhqpqaNb2c7vfhCRJkiRJkjozWNRGSfJg4I6q+gTwLuCx7dStSXYExnsu4hp6gSTAM0eduw54CXBuG1+SJEmSJEkzjG+F1sbaG3hnkruBXwMvA46mt4JxDXDNONe9GfjXJH8LXDX6ZFVdmuQUYFmSP5yGuiVJkiRJkrQRUlWDrkGaMnPmLah5J5w26DIkSZIkaZNas2TRoEuQtAVLsryqhka3u2JRW5S9d5vLsP+gSpIkSZIkTTufsShJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSeps9qALkKbSqlvWMn/xskGXIUmSJEkArFmyaNAlSNK0ccWiJEmSJEmSpM4MFjWtkjw9yeJ2fGqSU9rxmUmOHWx1kiRJkiRJ2lBuhda0qqpzgXMHXYckSZIkSZKmlisWNaYk85N8M8lZSVYm+VyS7ZO8Mck1SVYnWZokrf+FSU5Lcnk7d2BrPzHJ6ZPM9eQk1yVZleQjSea09jVJ3pzk2nZuj+m/c0mSJEmSJK0Pg0VNZHdgaVXtA/wceDlwelUdUFV7AdsBT+3rv0NVHdz6fWR9JkiyLXAmcFxV7U1vFe3L+rrcWlWPBd4PnDLOGCclGU4yvO6OtZ1uUJIkSZIkSRvGYFET+V5VXdaOPwEcCjwxyVVJVgFPAh7T1/9TAFV1MbBzkl3WY47dgZur6tvt81nA4X3nz2nflwPzxxqgqpZW1VBVDc3afu56TClJkiRJkqSN5TMWNZEa4/MZwFBVfS/JqcC2k/SfTCY5f1f7vg7/XiVJkiRJkmYMVyxqIg9NclA7fg5waTu+NcmOwOi3Oh8HkORQYG1Vrc++5G8C85M8sn1+PnDRxpUtSZIkSZKk6eYKME3kG8AJST4I3ETvOYf/C1gFrAGuGdX/p0kuB3YGXrg+E1TVL5O8ADg7yew25gempnxJkiRJkiRNl1Stz25VbW2SzAe+3F7Ssj79LwROqarh6axrMnPmLah5J5w2yBIkSZIk6bfWLFk06BIkaaMlWV5VQ6PbXbGoLcreu81l2H+4JUmSJEmSpp3BosZUVWuA9Vqt2PofMW3FSJIkSZIkacbx5S2SJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6mz3oAqSptOqWtcxfvGzQZUiSJEnaSqxZsmjQJUjSwLhiUZIkSZIkSVJnBouSJEmSJEmSOjNYnOGSfDjJnu34to0c6+lJFk9NZZBkfpLVM2UcSZIkSZIkbTo+Y3GGq6q/mIpxksyuqnOBc6diPEmSJEmSJG3dXLE4gyTZIcmyJNcnWZ3kuCQXJhnq6/NPSa5NckGSXVvbI5J8JcnyJJck2aO1n5nkn5N8HXhHkhOTnN7OPS3JVUmuS/K1JA9q7acm+Uib9ztJTp6k7FlJPpTkhiTnJ9mujfPbupM8IMmadvyYJFcnWZFkZZIFo34Gf9BqelySa/vaFyRZvpE/YkmSJEmSJE0Rg8WZ5Y+B71fVvlW1F/CVUed3AK6tqscCFwFvau1LgVdV1f7AKcAZfdc8Cjiyqv6/UWNdCjy+qvYDPg28ru/cHsAfAQcCb0qyzQQ1LwD+paoeA/wMeOYk9/hS4D1VtRAYAv575ESS3YHPAy+oqquAtUkWttMvAM4ca8AkJyUZTjK87o61k0wvSZIkSZKkqeBW6JllFfCuJO8AvlxVlyTpP3838Jl2/AngnCQ7AgcDZ/f1ndN3zdlVtW6MuX4f+EySecB9gZv7zi2rqruAu5L8CHgQfQHgKDdX1Yp2vByYP8k9XgG8PsnvA+dU1U2t7l2BfweeWVU3tL4fBl6Q5DXAcfSCznupqqX0wlXmzFtQk8wvSZIkSZKkKeCKxRmkqr4N7E8vYHx7kjdOdgm93+HPqmph39ej+/rcPs617wNOr6q9gZcA2/adu6vveB0TB9Dj9f0N9/x9/Xbsqvo34OnAncB5SZ7UTq0Fvgcc0jfe54E/AZ4KLK+q/5mgDkmSJEmSJG1CBoszSJIHA3dU1SeAdwGPHdXlPsCx7fi5wKVV9XPg5iTPamMkyb7rMd1c4JZ2fMJGF39va+iFpHBPzST5A+A7VfVeei+S2aed+hVwNPDnSZ4LUFW/BM4D3g98dBpqlCRJkiRJ0gYyWJxZ9gauTrICeD3wD6PO3w48pr3E5EnAW1r78cCLklwP3AA8Yz3mOpXe9ulLgFs3vvR7eRfwsiSXAw/oaz8OWN3ucQ/gYyMnqup2eqsT/yrJyD18kt7KzPOnoUZJkiRJkiRtoFT5SDrNXElOAeZW1d+tT/858xbUvBNOm96iJEmSJKlZs2TRoEuQpGmXZHlVDY1u9+UtmrGSfAF4BL3Vmetl793mMuw/7JIkSZIkSdPOYFGTSnJ/4IIxTj15Ol+oUlXHTNfYkiRJkiRJ2jgGi5pUCw8XDroOSZIkSZIkzRy+vEWSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6mz2oAuQptKqW9Yyf/GyQZchSZIkaSuxZsmiQZcgSQPjikVJkiRJkiRJnRksqrMkt43T/tIkfz7Fc+2S5OVTOaYkSZIkSZI2nsGipkxVfaCqPjbFw+4CGCxKkiRJkiTNMAaLupckr0tycjt+d5L/asdPTvKJdvzWJNcnuTLJg1rbqUlOaccXJjktyeVJVic5sK/Px5P8/+zdebhdZX33//fHhAYZDFWpT/QnxiJDkSHIAWUUFG1rbBXBolIFHKgjDsWa59E61FKD2iqKU/RBcKhaVJRCHwGVeT6BkAAithJr0dpaNYIoSvj+/tj3ke3xTCs5Jzs5eb+uK9de6173+q7v2skfXB/utfbXk3wryUv6rvv6JNclWZnkbW14KbBjkhVJ3rXhvgVJkiRJkiRNxGBRY7kUOLhtDwHbJNkCOAi4DNgauLqq9mpzXzJmFdi6qg6gt+Lw9L7xPYHFwP7Am5M8PMlTgZ2A/YBFwD5JDgGWAP9WVYuq6vXTeI+SJEmSJElaDwaLGstyesHetsA9wFX0AsaD6QWLvwTO7Zu7cJw6nwGoqkuBByXZro1/uap+XlU/BC6iFyY+tf25Abge2JVe0DipJCckGU4yvPbuNR1uU5IkSZIkSetq7qAb0Manqn6VZDVwPHAlsBI4DNgR+Abwq6qqNn0t4/87qnH2xxoP8I6q+kj/gSQLp9DvMmAZwLwFO42uLUmSJEmSpBngikWN51LgpPZ5GfBSYEVfoDgVRwMkOQhYU1UjywmfkWTLJA8BDgWuA84HXphkm3bOI5L8HnAnsO003I8kSZIkSZKmkSsWNZ7LgDcCV1XVz5L8oo118eMkVwIPAl7YN34tcB6wA/D2qvoe8L0kfwBclQTgLuDPq+rfklyR5Cbg//meRUmSJEmSpI2DwaLGVFVfA7bo29+5b3ubvu3PA59v228dVeYLVfW/xyh/W1WdMMY1TwVOHWP8eV37lyRJkiRJ0swyWNSssscj5jO8dPGg25AkSZIkSZr1DBY1I6rq0HHG37phO5EkSZIkSdJM8MdbJEmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKmzuYNuQJpOq+5Yw8Il5w26DUmSJEmbidVLFw+6BUkaGFcsSpIkSZIkSerMYFGSJEmSJElSZwaLm5Ak/5Jkuw1wneOSnNa2z0hy1BhzVid56Ez30ne9hUlu2lDXkyRJkiRJ0sR8x+IMSDK3qu6d7rpV9bTprilJkiRJkiStC1csjqOtkPtGko8muTnJBUkemGRRkquTrExydpLfbfMvTvJ3SS4BXp3k2+nZLsl9SQ5p8y5L8pgkWyc5Pcl1SW5I8ox2fKsk/9Tqfy7JNUmG2rFfrxJM8qUky1tvJ/T1fVeSk5Pc2Pp82AT3uH2SL7Qerkty4CTfydvbCsaRfzevSnJ9klVJdm1zHtx6W9muv2cbf2uSk/pq3dS+4zG/5zZnn3YfVwGvmKCvE5IMJxlee/eaiW5BkiRJkiRJ08RgcWI7AR+oqscCPwGOBD4BvKGq9gRWAW/pm79dVT2xqv4euA3YDTgIWA4cnGQe8P9V1b8CbwS+XlX7AocB70qyNfBy4Met/tuBfcbp7YVVtQ8wBJyY5CFtfGvg6qraC7gUeMkE93cq8J7Ww5HAx8abmOSdwO8Bx1fVfW34h1X1OOBDwEho+Dbghtb//2nf12TG+p4BPg6cWFX7T3RyVS2rqqGqGpqz1fwpXE6SJEmSJEnry2BxYrdX1Yq2vRzYkV54eEkbOxM4pG/+5/q2L2vHDgHeQS9g3Be4rh1/KrAkyQrgYmBLYIc277MAVXUTsHKc3k5MciNwNfBIeuEcwC+Bc/t6XjjB/R0OnNZ6OAd4UJJtx5j31/Tu+y+qqvrGvzjGdQ4CPtn6/zrwkCSTpX2jv+eF7Zz+7/qTk9SQJEmSJEnSBuQ7Fid2T9/2WmC7Seb/rG/7MuClwMOBNwOvBw6lt4oQIMCRVfXN/gJJMllTSQ6lFwruX1V3J7mYXjAJ8Ku+8G8tE/8dP6DV+Pmo+qPnXQfsk+TBVfWjvvGR76f/OmP1X8C9/GaQvWXf9ujv+YGtTn+IKUmSJEmSpI2IKxa7WQP8OMnBbf/5wCXjzL0GOAC4r6p+AawA/oJe4AhwPr13FAYgyd5t/HLgz9rYbsAeY9SeT+9x6bvbuw2fsI73cwHwypGdJIvGmfcVYClw3jgrGvtdChzT6h1K73HpnwKrgce18ccBj56oSFX9BFiT5KA2dMwk15UkSZIkSdIGZLDY3bH03oe4ElgE/M1Yk6rqHuC79B5Vhl6guC299zJC7/2JWwArk9zU9gE+CGzf6r+B3qPQo3+R5CvA3Dbn7X3X6OpEYKj90Mot9FZYjqmqzgI+Cpwz8uMq43jrSE16YeSxbfwLwIPbY9cvo/cOyskcD3yg/XjLzyebLEmSJEmSpA0nv/nKPA1akjnAFlX1iyQ7Al8Ddq6qXw64tU3C0NBQDQ8PD7oNSZIkSZKkWSPJ8qoaGj3uOxY3PlsBFyXZgt57Bl9mqChJkiRJkqSNjcHiRqaq7gR+KwFeH0neCDx71PBZVXXydF5HkiRJkiRJmw+Dxc1ACxANESVJkiRJkjRt/PEWSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdTZ30A1I02nVHWtYuOS8QbchSZIkaZZYvXTxoFuQpI2WKxYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksaoNJsjDJrUnOTLIyyeeTbJVkdZKHtjlDSS5u29snuTDJ9Uk+kuQ7I/MkSZIkSZI0WAaL2tB2AZZV1Z7AT4GXTzD3LcDXq+pxwNnADhugP0mSJEmSJE2BwaI2tO9W1RVt+1PAQRPMPQj4LEBVfQX48ViTkpyQZDjJ8Nq710xrs5IkSZIkSRqbwaI2tBpj/17u/7e4Zd+xTKlg1bKqGqqqoTlbzZ+GFiVJkiRJkjQZg0VtaDsk2b9tPxe4HFgN7NPGjuybeznwZwBJngr87gbqUZIkSZIkSZMwWNSG9g3g2CQrgQcDHwLeBpya5DJgbd/ctwFPTXI98MfA94E7N3C/kiRJkiRJGsPcQTegzc59VfXSUWOXATuPMXcN8IdVdW9b5XhYVd0z4x1KkiRJkiRpUgaL2pjtAPxTkgcAvwReMuB+JEmSJEmS1KRq9G9pSJuuoaGhGh4eHnQbkiRJkiRJs0aS5VU1NHrcdyxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmdzB92ANJ1W3bGGhUvOG3QbkiRJkjYBq5cuHnQLkrRJc8WiJEmSJEmSpM4MFjWjkpyR5KhB9yFJkiRJkqTpZbAoSZIkSZIkqTODRU2rJC9IsjLJjUk+2YYPSXJlkm+PrF5Mz7uS3JRkVZKj2/gHk/xp2z47yelt+0VJ/nYgNyVJkiRJkqTfYrCoaZPkscAbgSdV1V7Aq9uhBcBBwNOBpW3sWcAiYC/gcOBdSRYAlwIHtzmPAHZr2wcBl83wLUiSJEmSJGmKDBY1nZ4EfL6qfghQVT9q41+qqvuq6hbgYW3sIOAzVbW2qn4AXALsSy88PDjJbsAtwA9a4Lg/cOVYF01yQpLhJMNr714zYzcnSZIkSZKk+80ddAOaVQLUGOP3jJrT//kbquqOJL8L/BG91YsPBv4MuKuq7hznnGXAMoB5C3Ya6/qSJEmSJEmaZq5Y1HT6GvBnSR4CkOTBE8y9FDg6yZwk2wOHANe2Y1cBr2lzLgNOwsegJUmSJEmSNiquWNS0qaqbk5wMXJJkLXDDBNPPpvd48430Vjn+VVX9Zzt2GfDUqvrXJN+ht2rRYFGSJEmSJGkjkiqfHNXsMW/BTrXg2PcOug1JkiRJm4DVSxcPugVJ2iQkWV5VQ6PHXbGoWWWPR8xn2P84kCRJkiRJmnG+Y1GSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktTZ3EE3IE2nVXesYeGS8wbdhiRJkqSNwOqliwfdgiTNaq5YlCRJkiRJktSZwaIkSZIkSZKkzgwWp1mSK9vnwiTPm8L8hUluattDSd430z1OhyQXJxnawNe8a0NeT5IkSZIkSeMzWJxmVXVA21wITBosjjp3uKpOnPamJpHEd21KkiRJkiSpE4PFada3qm4pcHCSFUle21YmXpbk+vbngDHOPTTJuW17vyRXJrmhfe7Sxo9L8sUkX0nyrSTvnKSfFyW5ra0w/GiS09r4GUn+IclFwClJdmw1l7c+d02ybZLbk2zRznlQktUj+8Czk1zb6h/c5myZ5ONJVrXeD+vr+7S+vs5NcujId5bk5CQ3Jrk6ycPa+KOTXJXkuiRvn+AeT0gynGR47d1rJvsrkiRJkiRJ0jQwWJw5S4DLqmpRVb0H+C/gKVX1OOBoYLJHnm8FDqmqvYE3A3/Xd2xRq7EHcHSSR45VIMnDgb8GngA8Bdh11JSdgcOr6i+BZcCrqmof4CTgg1V1J3AxMPJTas8BvlBVv2r7c6tqP+A1wFva2CsAqmoP4LnAmUm2nORetwaurqq9gEuBl7TxU4EPVdW+wH+Od3JVLauqoaoamrPV/EkuJUmSJEmSpOngI7AbzhbAaUkWAWvphXoTmU8vlNsJqHb+iK9V1RqAJLcAjwK+O0aN/YBLqupHbe5Zo657VlWtTbINcABwVpKRY/Pa58eAvwK+BBzP/aEfwBfb53J6j34DHAS8H6Cqbk3ynSnc6y+Bc/tqPaVtHwgc2bY/CZwySR1JkiRJkiRtIAaLG85rgR8Ae9FbKfqLSea/Hbioqo5IspDeysER9/Rtr2X8v8eMMz7iZ+3zAcBPqmrR6AlVdUV7jPuJwJyqummMPvp7GO+a9/KbK2T7VzH+qqpqjFrQC1UlSZIkSZK0kfFR6JlzJ7Bt3/584PtVdR/wfGDOJOfPB+5o28etYw/XAk9M8rvtB1qOHGtSVf0UuD3JswHSs1fflE8AnwE+PoVrXgoc0+rsDOwAfBNYDSxK8oD26PZ+U6h1Bb3HrxmpKUmSJEmSpI2DweLMWQnc236Q5LXAB4Fjk1xN79Hgn014NrwTeEeSK5g8hBxTVd1B792M1wBfBW4Bxvt1k2OAFyW5EbgZeEbfsU8Dv0svXJzMB4E5SVYBnwOOq6p76IWEtwOrgHcD10+h1quBVyS5jl7QKkmSJEmSpI1E7n8CVbNRkm2q6q62YvFs4PSqOrtjjaOAZ1TV82ekyWk0NDRUw8PDg25DkiRJkiRp1kiyvKqGRo/7jsXZ761JDqf3TsML6P0Iy5QleT/wx8DTpr81SZIkSZIkbaoMFmeJJNdw/y85j3h+VZ20PnWr6lXrc74kSZIkSZJmJ4PFWaKqHj/oHiRJkiRJkrT58MdbJEmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1NncQTcgTadVd6xh4ZLzBt2GJEmSpI3A6qWLB92CJM1qrliUJEmSJEmS1JnBotZbkoVJblrPGndNVz+SJEmSJEmaeQaL2mCSzBl0D5IkSZIkSZoeBoubmba68NYkZyZZmeTzSbZKsk+SS5IsT3J+kgVt/sVJ3pPk0iTfSLJvki8m+VaSv+0rPXd0zXb+6iRvTnI58Owkz02yKslNSU4Zo7+HJrkqyeIk2yf5QpLr2p8DN8y3JEmSJEmSpMkYLG6edgGWVdWewE+BVwDvB46qqn2A04GT++b/sqoOAT4MfLnN3x04LslDxqn58r7zf1FVBwGXAqcATwIWAfsmeebIpCQPA84D3lxV5wGnAu+pqn2BI4GPTds3IEmSJEmSpPXir0Jvnr5bVVe07U8B/4deUHhhEoA5wPf75p/TPlcBN1fV9wGSfBt4JPCTMWqeCLy77X+ufe4LXFxV/93O/zRwCPAlYAvga8ArquqSNv9wYLfWE8CDkmxbVXf230ySE4ATAOY8aPuOX4UkSZIkSZLWhcHi5qlG7d9JLzDcf5z597TP+/q2R/ZH/g2Nrtm//7P2GcZ3L7Ac+ENgJFh8ALB/Vf18gvOoqmXAMoB5C3Ya3YckSZIkSZJmgI9Cb552SDISIj4XuBrYfmQsyRZJHrueNS8fY841wBPbexTntHkjIWIBLwR2TbKkjV0AvHLk5CSLOvYkSZIkSZKkGWKwuHn6BnBskpXAg2nvVwROSXIjsAI4YD1rfmj0hPYI9f8GLgJuBK6vqi/3HV8LPAc4LMnL6T1OPdR+EOYW4KUde5IkSZIkSdIMSZVPjm5OkiwEzq2q3Qfdy0yYt2CnWnDsewfdhiRJkqSNwOqliwfdgiTNCkmWV9XQ6HFXLEqSJEmSJEnqzB9v2cxU1Wp6vwA9K+3xiPkM+38lJUmSJEmSZpwrFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSps7mDbkCaTqvuWMPCJecNug1JkiRJM2z10sWDbkGSNnuuWJQkSZIkSZLUmcGiJEmSJEmSpM4MFjcxSa5sn4cmOXecOf+SZLsZ7uOtSU6ayWuMcc2LkwxtyGtKkiRJkiRpbL5jcRNTVQdMYc7TNkQvkiRJkiRJ2ny5YnETk+Suvt0HJTk7yS1JPpzkAW3O6iQPTfLSJCvan9uTXNSOfyjJcJKbk7ytr/bqJG9Lcn2SVUl2naSd3doqwm8nObGvzuuS3NT+vKaNLUxyU9+ck5K8tW1fnOSUJNcmuS3JwW38gUk+m2Rlks8BD1yvL0+SJEmSJEnTxmBx07Yf8JfAHsCOwLP6D1bVh6tqEbAv8B/AP7RDb6yqIWBP4IlJ9uw77YdV9TjgQ8BkjzrvCvxh6+MtSbZIsg9wPPB44AnAS5LsPYV7mVtV+wGvAd7Sxl4G3F1VewInA/uMdWKSE1pQOrz27jVTuJQkSZIkSZLWl8Hipu3aqvp2Va0FPgMcNM68U4GvV9U/t/0/S3I9cAPwWGC3vrlfbJ/LgYWTXP+8qrqnqn4I/BfwsNbD2VX1s6q6q9U7eAr3MtZ1DwE+BVBVK4GVY51YVcuqaqiqhuZsNX8Kl5IkSZIkSdL68h2Lm7aaZJ8kxwGPAl7Z9h9NbyXivlX14yRnAFv2nXJP+1zL5P8+7unbHpmfcebey28G2VuOOj7edX/rniRJkiRJkjR4rljctO2X5NHt3YpHA5f3H2yPJZ8E/HlV3deGHwT8DFiT5GHAH09zT5cCz0yyVZKtgSOAy4AfAL+X5CFJ5gFPn2KtYwCS7E7v0W1JkiRJkiRtBFyxuGm7ClhK7x2LlwJnjzr+SuDBwEVJAIar6sVJbgBuBr4NXDGdDVXV9W0V5LVt6GNVdQNAkr8BrgFuB26dQrkPAR9PshJY0VdTkiRJkiRJA5YqnzTV7DE0NFTDw8ODbkOSJEmSJGnWSLK8/RDwb/BRaEmSJEmSJEmd+Si0JpTkeODVo4avqKpXDKIfSZIkSZIkbRwMFjWhqvo48PFB9yFJkiRJkqSNi49CS5IkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdzR10A9J0WnXHGhYuOW/QbUiSJEmaYauXLh50C5K02XPFoiRJkiRJkqTODBY3E0nmJflqkhVJjp7B67w1yUlt+4wkR01T3YuTDE1HLUmSJEmSJK0/H4XefOwNbFFViwbdiCRJkiRJkjZ9rljcSCVZmOQbST6a5OYkFyR5YJIdk3wlyfIklyXZNcmcJN9Oz3ZJ7ktySKtzWZL9gE8Bi9qKxR2TPDnJDUlWJTk9ybw2f3WSh7btoSQXt+23tnkXt2ud2NfrG5N8M8lXgV3GuZ83J7kuyU1JliVJG784ySlJrk1yW5KD2/gDk3w2ycoknwMeOGNftiRJkiRJkjozWNy47QR8oKoeC/wEOBJYBryqqvYBTgI+WFVrgduA3YCDgOXAwS0s/P+q6lrgxcBlbcXiHcAZwNFVtQe9lasvm0I/uwJ/COwHvCXJFkn2AZ5Db0Xks4B9xzn3tKrat6p2pxcSPr3v2Nyq2g94DfCWNvYy4O6q2hM4GdhnvKaSnJBkOMnw2rvXTOE2JEmSJEmStL4MFjdut1fVira9HFgIHACclWQF8BFgQTt+GXBI+/MOegHjvsB1Y9TdpdW+re2f2c6bzHlVdU9V/RD4L+BhwMHA2VV1d1X9FDhnnHMPS3JNklXAk4DH9h374qh7pPXzKYCqWgmsHK+pqlpWVUNVNTRnq/lTuA1JkiRJkiStL4PFjds9fdtrgQcDP6mqRX1//qAdv4xeyLcf8C/AdsChwKVj1M0E17yX+/9dbDlJPyPv6KyJbiLJlsAHgaPaCsmPjqo9Ure/5qR1JUmSJEmSNDgGi5uWnwK3J3k2QHun4l7t2DX0VjPeV1W/AFYAf0EvcBztVmBhkse0/ecDl7Tt1dz/2PGRU+jpUuCI9k7EbYE/GWPOSIj4wyTbAFP5pehLgWMAkuwO7DmFcyRJkiRJkrSBGCxueo4BXpTkRuBm4BkAVXUP8F3g6jbvMmBbYNXoAi14PJ7eI9WrgPuAD7fDbwNOTXIZvRWEE6qq64HP0Qsyv8AYQWZV/YTeKsVVwJcY+/Hs0T4EbJNkJfBXwLVTOEeSJEmSJEkbSKp82lSzx7wFO9WCY9876DYkSZIkzbDVSxcPugVJ2mwkWV5VQ6PH5441WdpU7fGI+Qz7HxiSJEmSJEkzzkehJUmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKmzuYNuQJpOq+5Yw8Il5w26DUmSJEkzbPXSxYNuQZI2e65YlCRJkiRJktSZwaIkSZIkSZKkzgwWN3JJFia5aZpqHZrk3Gnq6XnT1NOV01FHkiRJkiRJG5bB4iyWZM56nj/eOzgXAp2CxdG9jOxX1QEdaiSJ/2YlSZIkSZI2AoY0m4a5Sc5MsjLJ55NsleTJSW5IsirJ6UnmASRZneTNSS4Hnp3kj5Lc2vafNVIwydbtvOtanWe08eOSnJXkn4ELxulnKXBwkhVJXptkTpJ3tVork/xFq3VokouS/COwavR+m3NXX0+v76vxtja2MMk3knwQuB545DR/t5IkSZIkSVoH/ir0pmEX4EVVdUWS04HXAX8BPLmqbkvyCeBlwHvb/F9U1UFJtgS+BTwJ+Ffgc3013wh8vapemGQ74NokX23H9gf2rKofjdPPEuCkqno6QJITgDVVtW8LOK9IMhJK7gfsXlW3Jzm0f7+/YJKnAju14wHOSXII8O/t/o+vqpeP1Uy7/gkAcx60/TgtS5IkSZIkaTq5YnHT8N2quqJtfwp4MnB7Vd3Wxs4EDumbPxIg7trmfauqqp074qnAkiQrgIuBLYEd2rELJwgVx/JU4AWt1jXAQ+iFhADXjgoRR+/313gqcAO9lYm79tX4TlVdPd7Fq2pZVQ1V1dCcreZ3aFuSJEmSJEnryhWLm4bqOP9nUzg3wJFV9c3fGEweP+r8qQjwqqo6f1StQ8eoNV7tAO+oqo+MqrFwHfqRJEmSJEnSDHPF4qZhhyT7t+3nAl8FFiZ5TBt7PnDJGOfdCjw6yY595444H3hVkgAk2btDP3cC246q9bIkW7RaOyfZukO9kRovTLJNq/GIJL/XsYYkSZIkSZI2EFcsbhq+ARyb5CP03pn4auBq4Kz2y83XAR8efVJV/aK9f/C8JD8ELgd2b4ffTu+djCtbuLgaePoU+1kJ3JvkRuAM4FR6vxR9fav138Azu9xgVV2Q5A+Aq1rWeRfw58DaLnUkSZIkSZK0YaT36j1pdpi3YKdacOx7B92GJEmSpBm2euniQbcgSZuNJMuramj0uCsWNavs8Yj5DPsfGJIkSZIkSTPOYFHjSrIH8MlRw/dU1eMH0Y8kSZIkSZI2HgaLGldVrQIWDboPSZIkSZIkbXz8VWhJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqbO5g25Amk6r7ljDwiXnDboNSZIkSetp9dLFg25BkjQJVyxKkiRJkiRJ6sxgUdMmyV3t89Ak5w66H0mSJEmSJM0cg0VJkiRJkiRJnRksaqZsk+TzSW5N8ukkAUjy5iTXJbkpybK+8ROT3JJkZZLPtrH9klyZ5Ib2ucsgb0iSJEmSJEn3M1jUTNkbeA2wG/D7wIFt/LSq2reqdgceCDy9jS8B9q6qPYGXtrFbgUOqam/gzcDfbaDeJUmSJEmSNAmDRc2Ua6vqP6rqPmAFsLCNH5bkmiSrgCcBj23jK4FPJ/lz4N42Nh84K8lNwHv65v6GJCckGU4yvPbuNTNzN5IkSZIkSfoNBouaKff0ba8F5ibZEvggcFRV7QF8FNiyzVkMfADYB1ieZC7wduCitrrxT/rm/oaqWlZVQ1U1NGer+TNzN5IkSZIkSfoNBovakEaCwR8m2QY4CiDJA4BHVtVFwF8B2wHb0FuxeEc757gN2qkkSZIkSZImNHfQDWjzUVU/SfJRYBWwGriuHZoDfCrJfCDAe9rcdwJnJnkd8PVB9CxJkiRJkqSxpaoG3YM0beYt2KkWHPveQbchSZIkaT2tXrp40C1Ikpoky6tqaPS4KxY1q+zxiPkM+x8gkiRJkiRJM853LEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjqbO+gGpOm06o41LFxy3qDbkCRJkrSeVi9dPOgWJEmTcMWiJEmSJEmSpM4MFiVJkiRJkiR1ZrA4yyX5WJLd2vbqJA9NsjDJTetZ9zVJtpqG/v4myeHrW0eSJEmSJEkblu9YnOWq6sUzVPo1wKeAu6d6QpI5VbV21P6bu1w0ydyqurfLOZIkSZIkSZp+rlicRZJsneS8JDcmuSnJ0UkuTjI0wTm/n+SGJI9Pcn3f+E5Jlo9zzonAw4GLklzUxp6a5Kok1yc5K8k2bXx1kjcnuRx49hj7ZyQ5qs3dJ8klSZYnOT/JgjZ+cZK/S3IJ8Oox+jkhyXCS4bV3r1nn70+SJEmSJElTZ7A4u/wR8L2q2quqdge+MtHkJLsAXwCOr6prgDVJFrXDxwNnjHVeVb0P+B5wWFUdluShwJuAw6vqccAw8Lq+U35RVQdV1WfH2SfJFsD7gaOqah/gdODkvhrbVdUTq+rvx+hnWVUNVdXQnK3mT3TLkiRJkiRJmiY+Cj27rALeneQU4NyquizJeHO3B74MHFlVN7exjwHHJ3kdcDSw3xSv+wRgN+CKdr3fAa7qO/65UfNH7wPsAuwOXNhqzAG+P8k5kiRJkiRJGhCDxVmkqm5Lsg/wNOAdSS6YYPoa4LvAgcBIsPgF4C3A14HlVfU/U7x0gAur6rnjHP/ZJPsjNW6uqv2nWEOSJEmSJEkD5KPQs0iShwN3V9WngHcDj5tg+i+BZwIvSPI8gKr6BXA+8CHg45Nc7k5g27Z9NXBgkse0PrZKsnPH9r8JbJ9k/1ZjiySP7VhDkiRJkiRJG4jB4uyyB3BtkhXAG4G/nWhyVf0MeDrw2iTPaMOfBgqYaLUjwDLg/yW5qKr+GzgO+EySlfSCxl27NF5VvwSOAk5JciOwAjigSw1JkiRJkiRtOKmqQfegjUiSk4D5VfXXg+5lXQwNDdXw8PCg25AkSZIkSZo1kiyvqqHR475jUb+W5GxgR+BJg+5FkiRJkiRJGzeDRf1aVR0xeqyFjY8eNfyGqjp/w3QlSZIkSZKkjZHBoiY0VtgoSZIkSZIk+eMtkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6mzuoBuQptOqO9awcMl5g25DkiRJ0gRWL1086BYkSdPAFYuSJEmSJEmSOjNYlCRJkiRJktSZweI0S7IwyU3re26SQ5Oc27b/NMmS9ejpNUm2Wtfzx6n5zCS7TUOd9bo3SZIkSZIkDYbB4iagqs6pqqXrUeI1wLQGi8AzgU7BYpK5o/e73tvoGpIkSZIkSRoMQ5qZMTfJmcDewG3AC4A/AP4B2Ab4IXBcVX0/yT7A6cDdwOVjFUtyHDBUVa9McgbwU2AI+F/AX1XV55M8ADgNeCJwO73Q+HTg4e3PRUl+WFWHJXku8H+AAOdV1Rvade4CTgWeDvwceEZV/WCMfg4A/hR4YpI3AUe2Qx8Atm/38pKqurX1+6P2XVyf5CGj9lf13dv2wIeBHVq911TVFUne2u5hYfvunjfJ9y9JkiRJkqQZ5orFmbELsKyq9qQXAr4CeD9wVFWNBIknt7kfB06sqv071F8AHEQvABxZ7fcsesHbHsCLgf0Bqup9wPeAw1qo+HDgFOBJwCJg3yTPbDW2Bq6uqr2AS4GXjHXxqroSOAd4fVUtqqp/A5YBr2r3dxLwwb5TdgYOr6q/HGd/xKnAe6pqX3ph5cf6ju1DL+j8rVAxyQlJhpMMr717zVgtS5IkSZIkaZq5YnFmfLeqrmjbn6K3OnB34MIkAHOA7yeZD2xXVZe0uZ8E/ngK9b9UVfcBtyR5WBs7CDirjf9nkovGOXdf4OKq+m+AJJ8GDgG+BPwSOLfNWw48ZSo3m2Qb4ADgrHZ/APP6ppxVVWsn2B9xOLBbX40HJdm2bZ9TVT8f6/pVtYxesMm8BTvVVHqWJEmSJEnS+jFYnBmjw607gZtHr0pMst0Yc6finv4yoz4nM9G8X1XVSD9rmfq/jwcAP6mqReMc/9kk+/119h8dILagcbxzJEmSJEmSNAA+Cj0zdkgyEiI+F7ga2H5kLMkWSR5bVT8B1iQ5qM09Zj2ueTlwZJIHtFWMh/YduxMYWfl3Db13Iz40yZzW3yV09+uaVfVT4PYkzwZIz17rUPMC4JUjO0kWrUMNSZIkSZIkbQAGizPjG8CxSVYCD6a9XxE4JcmNwAp6jw4DHA98IMlV9H4wZV19AfgP4CbgI/QCxJEXDi4D/l+Si6rq+8D/Bi4CbgSur6ovr8P1Pgu8PskNSXakF4q+qN3fzcAz1qHmicBQkpVJbgFeug41JEmSJEmStAHk/idftalLsk1V3dV+efla4MCq+s9B97UhzVuwUy049r2DbkOSJEnSBFYvXTzoFiRJHSRZXlVDo8d9x+Lscm57b+PvAG/f3EJFgD0eMZ9h/yNFkiRJkiRpxhksziJVdeh010zyRuDZo4bPqqqTp/takiRJkiRJ2nQYLGpCLUA0RJQkSZIkSdJv8MdbJEmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTO5g66AWk6rbpjDQuXnDfoNiRJkiRNYPXSxYNuQZI0DVyxKEmSJEmSJKkzg0VJkiRJkiRJnRksDliStyY5aRrqnJHkqLb9sSS7rWe9Q5Oc27b/NMmS9e1xHftYmOR5g7i2JEmSJEmSxmewOAtV1Yur6pZprHdOVS2drnodLQQMFiVJkiRJkjYyBosDkOSNSb6Z5KvALm3sJUmuS3Jjki8k2aqNn5HkfUmuTPLtvlWJSXJakluSnAf8Xl/9i5MMte2nJrkqyfVJzkqyzQR9/VGSW5NcDjyrb/y4JKdN0s+hSS5J8k9JbkuyNMkxSa5NsirJjm3eo5J8LcnK9rnDRHWBpcDBSVYkee00/RVIkiRJkiRpPRksbmBJ9gGeA+xNL7zbtx36YlXtW1V7Ad8AXtR32gLgIODp9II2gCPohZJ7AC8BDhjjWg8F3gQcXlWPA4aB143T15bAR4E/AQ4G/tcEtzFWPwB7Aa9uPT0f2Lmq9gM+BryqzTkN+ERV7Ql8GnjfJHWXAJdV1aKqes84vZ+QZDjJ8Nq710zQtiRJkiRJkqaLweKGdzBwdlXdXVU/Bc5p47snuSzJKuAY4LF953ypqu5rjzc/rI0dAnymqtZW1feAr49xrScAuwFXJFkBHAs8apy+dgVur6pvVVUBn5rgHsbqB+C6qvp+Vd0D/BtwQRtfRe+RZoD9gX9s25+kFyROVndCVbWsqoaqamjOVvOnepokSZIkSZLWw9xBN7CZqjHGzgCeWVU3JjkOOLTv2D1925mkTr8AF1bVc9ejr7GM10//+H19+/cx/r+1/muOV1eSJEmSJEkbGVcsbniXAkckeWCSbek9egywLfD9JFvQW7E4lTrPSTInyQLgsDHmXA0cmOQxAEm2SrLzOPVuBR498i5EYKphZFdX0nsUHHr3efkk8++k991IkiRJkiRpI2KwuIFV1fXA54AVwBeAy9qhvwauAS6kF/JN5mzgW/QeM/4QcMkY1/pv4DjgM0lW0gsadx2nr18AJwDntR9v+c5U76mjE4HjWz/Pp/dOxomsBO5tP2rjj7dIkiRJkiRtJNJ7nZ40OwwNDdXw8PCg25AkSZIkSZo1kiyvqqHR465YlCRJkiRJktSZP96yGUpyNvDoUcNvqKrzB9GPJEmSJEmSNj0Gi5uhqjpi0D1IkiRJkiRp0+aj0JIkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZ3MH3YA0nVbdsYaFS84bdBuSJEnSZm310sWDbkGStAG4YlGSJEmSJElSZwaLU5BkYZKbBnF+kn9Jst26XnsK9f80yZJxjt21HnUvTjK07p39us7qJA9d3zqSJEmSJEmaXj4KPTVhQCFsVT1tpmonmVtV5wDnzNQ1JEmSJEmSNDu5YnEcbZXhN5J8ELgeeGCSjya5OckFSR7Y5i1KcnWSlUnOTvK7bXyfJDcmuQp4RV/dOUneleS6ds5ftPEFSS5NsiLJTUkObuO/XrGX5EtJlrceTuireVeSk9v1rk7ysAnu64wk/5DkIuCUJMclOa0de3SSq1pvb+875wFJPtiue25bRXlU331e0vo6P8mCvsv9eZIr2/3s1+bv18ZuaJ+79H0v706yqn0vrxrV9wOTfCXJSzr/ZUqSJEmSJGnaGSxObBfgE8DewCOBD1TVY4GfAEe2OZ8A3lBVewKrgLe08Y8DJ1bV/qNqvghYU1X7AvsCL0nyaOB5wPlVtQjYC1gxRj8vrKp9gCHgxCQPaeNbA1dX1V7ApcBk4dvOwOFV9Zejxk8FPtR6+8++8WcBC4E9gBcD+wMk2QJ4P3BU6+t04OS+87auqgOAl7djALcCh1TV3sCbgb9r4ycAjwb2bt/lp/vqbAP8M/CPVfXR0TeT5IQkw0mG1969ZpJblyRJkiRJ0nTwUeiJfaeqrk6yELi9qla08eXAwiTzge2q6pI2fiZw1hjjnwT+uG0/FdhzZMUfMB/YCbgOOL2FdV/qu1a/E5Mc0bYf2c77H+CXwLl9vT1lkvs6q6rWjjF+IPcHpp8ETmnbB7Vz7gP+s612hF7wujtwYRKAOcD3++p9BqCqLk3yoPauyG2BM5PsBBSwRZt7OPDhqrq3nfOjvjpfBt5ZVf1h469V1TJgGcC8BTvVJPcuSZIkSZKkaWCwOLGf9W3f07e9FnjgBOeFXmg23rFXVdX5v3UgOQRYDHwyybuq6hN9xw6lF77tX1V3J7kY2LId/lVVjVxvLZP/vf5sgmNj9Z1x5ga4eYxVmePVKuDtwEVVdUQLbC/uqzXed3YF8MdJ/rHvPiVJkiRJkjRAPgq9HqpqDfDjkfchAs8HLqmqnwBrkhzUxo/pO+184GVtZSJJdk6ydZJHAf/VHvX9v8DjRl1uPvDjFiruCjxhBm7pCuA5Y/R8OXBke9fiw4BD2/g3ge2T/PrR6CSP7Tvv6DZ+EL3Hv9e0+7ijHT+ub+4FwEuTzG3nPLjv2Jvprcz84HrdnSRJkiRJkqaNweL6OxZ4V5KVwCLgb9r48cAH2o+3/Lxv/seAW4Drk9wEfITeCsNDgRVJbqD3OPKpo67zFWBuu87bgatn4F5eDbwiyXX0AsARXwD+Axjp9xp6QeEvgaPo/QjMjfTeC3lA33k/TnIl8GF675YEeCfwjiRX0Ht0esTHgH8HVrZazxvV22uALZO8c31vUpIkSZIkSesvPlmqqUiyTVXd1X4w5lrgwKr6z8nO29DmLdipFhz73kG3IUmSJG3WVi9dPOgWJEnTKMnyqhoaPe47FjVV57YfX/kd4O0bY6gIsMcj5jPsf8RIkiRJkiTNOIPFWSrJG4Fnjxo+q6pOXpd6VXXoejclSZIkSZKkWcNgcZZqAeI6hYiSJEmSJEnSZPzxFkmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSps7mDbkCaTqvuWMPCJecNug1JkiRps7Z66eJBtyBJ2gBcsShJkiRJkiSpM4NFSZIkSZIkSZ0ZLG4ikrw1yUmTzFmd5KEbqJ/jkjx8Guq8NMkLpqMnSZIkSZIkbTi+Y1Hr6jjgJuB7Uz0hydyqunfU/oe7XHR0DUmSJEmSJA2GweIGkGRr4J+A/w+YA7wd+FfgH4BtgB8Cx1XV95O8BDgB+J025/lVdXdfrR2Bs6rqcW1/J+CzVbVPm/KqJH8CbAE8u6puTbIf8F7ggcDPgeOr6ptJjgOe2XraHfj7dt3nA/cAT6uqH41xP0cBQ8Cnk/wc2B/YbZz7uRi4EjgQOKf11r+/LXBXVb273dsHgO2Bu4GXtP7PAH4E7A1cD/xlt78BSZIkSZIkTTcfhd4w/gj4XlXtVVW7A18B3g8c1QLB04GT29wvVtW+VbUX8A3gRf2FqurfgDVJFrWh44Ez+qb8sIWOHwJGHp2+FTikqvYG3gz8Xd/83YHnAfu1Hu5u864CxnxEuao+DwwDx1TVIuDeCe4HYLuqemJV/f04+yOWAa9qNU4CPth3bGfg8Kr6rVAxyQlJhpMMr717zVgtS5IkSZIkaZq5YnHDWAW8O8kpwLnAj+kFehcmgd6Kwe+3ubsn+VtgO3qr/84fo97HgOOTvA44ml4oOOKL7XM58Ky2PR84s61uLHqrGUdcVFV3AncmWQP8c1/Pe07x/naZ4H4APjdq/uh9kmwDHACc1WoAzOubclZVrR3r4lW1jF4oybwFO9UUe5YkSZIkSdJ6MFjcAKrqtiT7AE8D3gFcCNxcVfuPMf0M4JlVdWN7VPnQMeZ8AXgL8HVgeVX9T9+xe9rnWu7/+307vQDxiCQLgYvHmA9wX9/+fUz930cY/34AfjbJPvRWz/6krYCcSg1JkiRJkiQNkI9CbwDt15PvrqpPAe8GHg9sn2T/dnyLJI9t07cFvp9kC+CYsepV1S/orWT8EPDxKbQwH7ijbR+3rvcxyp30egX4JuPfz5RU1U+B25M8u9VIkr2mqVdJkiRJkiRNM4PFDWMP4NokK4A30nvP4VHAKUluBFbQewwY4K+Ba+itarx1gpqfpvdY8wVTuP47gXckuYLeY8rT4Qzgw+2e5jD+/XRxDPCiVuNm4BnT0qkkSZIkSZKmXap8Jd2mKMlJwPyq+utB97IxGRoaquHh4UG3IUmSJEmSNGskWV5VQ6PHfcfiJijJ2cCOwJMG3YskSZIkSZI2TwaLm6CqOmJDXSvJB4ADRw2fWlVTebejJEmSJEmSZimDRU2oql4x6B4kSZIkSZK08fHHWyRJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzuYOugFpOq26Yw0Ll5w36DYkSZKkzdrqpYsH3YIkaQNwxaIkSZIkSZKkzgwWJUmSJEmSJHVmsDhLJblyXY6143dNf0eQZGGS5/XtL0rytJm4liRJkiRJkmaWweIsVVUHjB5LMme8YxvIQuB5ffuLgE7BYhLfCypJkiRJkrQRMFicpUZWHSY5NMlFSf4RWDXq2IIklyZZkeSmJAf3nX9ykhuTXJ3kYRNc59nt3BuTXNrG5iR5V5LrkqxM8hdt+lLg4Ha9NwB/Axzd9o9OsnWS09t5NyR5Rqt3XJKzkvwzcMEYPZyQZDjJ8Nq710zH1ydJkiRJkqRJuPpr87AfsHtV3T5q/HnA+VV1clvNuFUb3xq4uqremOSdwEuAvx2n9puBP6yqO5Js18ZeBKypqn2TzAOuSHIBsAQ4qaqeDpDkB8BQVb2y7f8d8PWqemGrdW2Sr7aa+wN7VtWPRjdQVcuAZQDzFuxUHb4XSZIkSZIkrSODxc3DtWOEigDXAacn2QL4UlWtaOO/BM5t28uBp0xQ+wrgjCT/BHyxjT0V2DPJUW1/PrBTqzuRpwJ/muSktr8lsEPbvnCsUFGSJEmSJEmD4aPQm4efjTVYVZcChwB3AJ9M8oJ26FdVNbLyby0TBNBV9VLgTcAjgRVJHgIEeFVVLWp/Hl1Vv/UI8xgCHNl33g5V9Y2J7kGSJEmSJEmDYbC4GUvyKOC/quqjwP8FHrcONXasqmuq6s3AD+kFjOcDL2srIUmyc5KtgTuBbftOH71/PvCqJGnn7b0OtyVJkiRJkqQNwEehN2+HAq9P8ivgLuAFE08f07uS7ERvteHXgBuBlfR+Afr6FhL+N/DMNn5vkhuBM4AzgSVJVgDvAN4OvBdY2c5bDTx9XW5MkiRJkiRJMyv3P/EqbfqGhoZqeHh40G1IkiRJkiTNGkmWV9XQ6HEfhZYkSZIkSZLUmY9Ca0qSvBF49qjhs6rq5EH0I0mSJEmSpMEyWNSUtADREFGSJEmSJEmAj0JLkiRJkiRJWgcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnc0ddAPSdFp1xxoWLjlv0G1IkiRJs9rqpYsH3YIkaSPgikVJkiRJkiRJnRksSpIkSZIkSerMYHGWSbIwyU3rWeOZSXabrp5azeOSnNbxnDOSHNW2L04yNJ09SZIkSZIkad0ZLGoszwSmNViUJEmSJEnS7GKwODvNTXJmkpVJPp9kqyRPTnJDklVJTk8yDyDJ0iS3tLnvTnIA8KfAu5KsSLJjkkVJrm5zzk7yu+3ci5OckuTaJLclOXiSvh6Z5CtJvpnkLa3Gb6ywTHJSkrfOzNciSZIkSZKk6WKwODvtAiyrqj2BnwKvA84Ajq6qPej9GvjLkjwYOAJ4bJv7t1V1JXAO8PqqWlRV/wZ8AnhDm7MKeEvfteZW1X7Aa0aNj2U/4BhgEfDs6Xq0OckJSYaTDK+9e810lJQkSZIkSdIkDBZnp+9W1RVt+1PAk4Hbq+q2NnYmcAi90PEXwMeSPAu4e3ShJPOB7arqklHnjvhi+1wOLJykrwur6n+q6uftvIM63dU4qmpZVQ1V1dCcreZPR0lJkiRJkiRNwmBxdqopTaq6l94qwi/Qe6/iV9bhWve0z7X0VkJ26auAe/nNf4dbrkMPkiRJkiRJ2sAMFmenHZLs37afC3wVWJjkMW3s+cAlSbYB5lfVv9B7lHlRO34nsC1AVa0Bftz3/sTnAyOrF7t6SpIHJ3kgvSDzCuAHwO8leUh77+PT17G2JEmSJEmSNqDJVphp0/QN4NgkHwG+BbwauBo4K8lc4Drgw8CDgS8n2RII8Np2/meBjyY5ETgKOBb4cJKtgG8Dx69jX5cDnwQeA/xjVQ0DJPkb4BrgduDWdawtSZIkSZKkDShVU3pqVtokzFuwUy049r2DbkOSJEma1VYvXTzoFiRJG1CS5VX1Wz/C64pFzSp7PGI+w/5HjiRJkiRJ0owzWNS0SvKHwCmjhm+vqiMG0Y8kSZIkSZJmhsGiplVVnQ+cP+g+JEmSJEmSNLP8VWhJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqbO5g25Amk6r7ljDwiXnDboNSZIkaVZbvXTxoFuQJG0EXLEoSZIkSZIkqTODRUmSJEmSJEmdGSyOIcld44yfkeSoDdTD6iQPbdtXTjJ3zH47XOu4JKetT411uOav70+SJEmSJEmbHoPFTUBVHTDoHiRJkiRJkqR+m32wmOR1SW5qf14z6liSnJbkliTnAb83Sa19klySZHmS85MsaOMXJzklybVJbktycBvfKsk/JVmZ5HNJrkkyNEbdu9rngiSXJlnR+j24b87JSW5McnWSh03Q47PbuTcmubTv0MOTfCXJt5K8s2/+U5NcleT6JGcl2WYK9/reJFe26+zXxh+S5IIkNyT5CJDJ/g6S/HWSW5NcmOQzSU6a6PuXJEmSJEnShrNZB4tJ9gGOBx4PPAF4SZK9+6YcAewC7AG8BBh35WCSLYD3A0dV1T7A6cDJfVPmVtV+wGuAt7SxlwM/rqo9gbcD+0zS8vOA86tqEbAXsKKNbw1cXVV7AZe2XsfzZuAP29w/7RtfBBxN716PTvLI9qjym4DDq+pxwDDwuinc69ZtleXL2zHaPV9eVXsD5wA7wPh/By1gPRLYG3gW8FuB64gkJyQZTjK89u41E9y6JEmSJEmSpsvcQTcwYAcBZ1fVzwCSfBE4uO/4IcBnqmot8L0kX5+g1i7A7sCFSQDmAN/vO/7F9rkcWNh3/VMBquqmJCsn6fc64PQW7H2pqla08V8C5/bVf8oENa4AzkjyT309AXytqtYAJLkFeBSwHbAbcEW7p98BrprCvX6m3dOlSR6UZDt63+Wz2vh5SX7c9x2M9XfwAODLVfXzNv7P491QVS0DlgHMW7BTTXDvkiRJkiRJmiabe7CYyacw1aAqwM1Vtf84x+9pn2u5/3ufyvXvb6QX1B0CLAY+meRdVfUJ4FdVNdJnf/2xarw0yeNbjRVJFo3qr79GgAur6rn9NZLswcT3Ovo7q3HGYfzvoNN3I0mSJEmSpA1rs34Umt5jw89s7zrcmt6jz5eNOv6cJHPaOwQPm6DWN4Htk+wPvUejkzx2kutfDvxZm78bvceQx5XkUcB/VdVHgf8LPG6S+mPV2LGqrqmqNwM/BB45wfSrgQOTPKadu1WSnZn8Xo9u4wcBa9pKyEuBY9r4HwO/2+aO93dwOfAnSbZs73Vc3PVeJUmSJEmSNHM26xWLVXV9kjOAa9vQx6rqhvZ4L8DZwJOAVcBtwCUT1PplkqOA9yWZT++7fS9w8wQtfBA4sz0CfQOwEpjoJYGHAq9P8ivgLuAFE93fON6VZCd6KwK/BtxI7/2Kv6Wq/jvJccBnksxrw2+qqtsmudcfJ7kSeBDwwjb2tlbnenrf47+3a4z5dwCQ5JzW33fovd/RFyhKkiRJkiRtJHL/E7Ta0JLMAbaoql8k2ZFe0LdzVf1ywK2tsyQXAydV1fA01Nqmqu5KshW9lY0nVNX1E50zNDRUw8PrfWlJkiRJkiQ1SZZX1W/9sO5mvWJxI7AVcFH7MZYAL9uUQ8UZsKw9Ir4lcOZkoaIkSZIkSZI2HIPFdZDkbODRo4bfUFXnd6lTVXcCv5X2TockbwSePWr4rKo6eSauN6KqDp3GWs+brlqSJEmSJEmaXgaL66Cqjhh0D5NpAeKMhoiSJEmSJEnafG3uvwotSZIkSZIkaR0YLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKmzuYNuQJpOq+5Yw8Il5w26DUmSJGlWW7108aBbkCRtBFyxKEmSJEmSJKkzg0UNRJK3JjmpbZ+R5Ki2/bEkuw22O0mSJEmSJE3GR6G1UamqFw+6B0mSJEmSJE3OFYuaVklekGRlkhuTfDLJo5J8rY19LckOk5x/cZKhtv3UJFcluT7JWUm22TB3IUmSJEmSpMkYLGraJHks8EbgSVW1F/Bq4DTgE1W1J/Bp4H1TrPVQ4E3A4VX1OGAYeN04c09IMpxkeO3da6bhTiRJkiRJkjQZH4XWdHoS8Pmq+iFAVf0oyf7As9rxTwLvnGKtJwC7AVckAfgd4KqxJlbVMmAZwLwFO9U6dy9JkiRJkqQpM1jUdAowWbA31eAvwIVV9dz1a0mSJEmSJEkzwUehNZ2+BvxZkocAJHkwcCXwnHb8GODyKda6GjgwyWNara2S7DzN/UqSJEmSJGkduWJR06aqbk5yMnBJkrXADcCJwOlJXg/8N3D8FGv9d5LjgM8kmdeG3wTcNv2dS5IkSZIkqatU+Uo6zR7zFuxUC45976DbkCRJkma11UsXD7oFSdIGlGR5VQ2NHnfFomaVPR4xn2H/I0eSJEmSJGnG+Y5FSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSeps7qAbkKbTqjvWsHDJeYNuQ5IkSdpkrV66eNAtSJI2Ea5YlCRJkiRJktSZwaIkSZIkSZKkzgwWR0myMMlNM1j/pUleMAN1Vyd56DTV2jXJiiQ3JNkxyV3TVHdGv1tJkiRJkiRtOL5jcQOrqg93mZ9kblXdO1P9jOOZwJer6i2thxm92IDuUZIkSZIkSevBFYtjm5vkzCQrk3w+yVZJntxW8K1KcnqSefCbKwWTDCW5OMkD2vh2IwWT/GuShyV5a5KT2tiOSb6SZHmSy5Ls2sbPSPIPSS4CThmrwSQPSXJB6+kjQPqO/XmSa9uqw48kmdP+nJHkpnYPrx2n7tOA1wAvbtfvP7ZNkq8lub7VeEYbX5jkG0k+muTm1tcD27F9ktyY5CrgFX21jktyVpJ/Bi5IsnX7Xq9r9zRS+7F997IyyU5d/iIlSZIkSZI0MwwWx7YLsKyq9gR+CrwOOAM4uqr2oLfS82XjnVxV9wFfBo4ASPJ4YHVV/WDU1GXAq6pqH+Ak4IN9x3YGDq+qvxznMm8BLq+qvYFzgB3atf4AOBo4sKoWAWuBY4BFwCOqavd2Dx8fp/d/AT4MvKeqDht1+BfAEVX1OOAw4O9z/3LGnYAPVNVjgZ8AR7bxjwMnVtX+Y1xuf+DYqnoS8Ebg61W1b6v9riRbAy8FTm33MgT8x+giSU5IMpxkeO3da8b5uiRJkiRJkjSdDBbH9t2quqJtfwp4MnB7Vd3Wxs4EDpmkxufoBXwAz2n7v5ZkG+AA4KwkK4CPAAv6ppxVVWsnqH9I642qOg/4cRt/MrAPcF2r+2Tg94FvA7+f5P1J/oheYNpVgL9LshL4KvAI4GHt2O1VtaJtLwcWJpkPbFdVl7TxT46qd2FV/ahtPxVY0nq+GNiSXlh6FfB/krwBeFRV/Xx0U1W1rKqGqmpozlbz1+G2JEmSJEmS1JXvWBxbdZh7L/cHtFv2jV8FPCbJ9vTeWfi3o857APCTthJvLD+bwrXH6jPAmVX1v3/rQLIX8If0Hkn+M+CFU7hGv2OA7YF9qupXSVZz/z3f0zdvLfDA1stE32X/PQY4sqq+OWrON5JcAywGzk/y4qr6ese+JUmSJEmSNM1csTi2HZKMPLr7XHqr8xYmeUwbez4wsgpvNb0VgnD/479UVQFnA/8AfKOq/qf/AlX1U+D2JM8GSM9eHXq8lF7QR5I/Bn63jX8NOCrJ77VjD07yqPYeyAdU1ReAvwYe1+FaI+YD/9VCxcOAR000uap+AqxJclAbOmaC6ecDrxp5tDrJ3u3z94FvV9X76D3yvec69C1JkiRJkqRpZrA4tm8Ax7ZHfh8MvAc4nt5jy6uA++i9hxDgbcCpSS6jt1Kv3+eAP2fUY9B9jgFelORG4GbgGR16fBtwSJLr6T1G/O8AVXUL8CZ6P4iyEriQ3iPWjwAubo8anwH81orGKfg0MJRkuPV+6xTOOR74QPvxlt96jLnP24EtgJVJbmr70Huc/KbW967AJ9ahb0mSJEmSJE2z9BbWSbPDvAU71YJj3zvoNiRJkqRN1uqliwfdgiRpI5NkeVUNjR73HYuaVfZ4xHyG/Q8hSZIkSZKkGWewuJFLcjzw6lHDV1TVK6ah9geAA0cNn1pVH1/f2pIkSZIkSZrdDBY3ci3km5GgbzrCSUmSJEmSJG2e/PEWSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKmzuYNuQJpOq+5Yw8Il5w26DUmSJGmTtXrp4kG3IEnaRLhiUZIkSZIkSVJnBouSJEmSJEmSOjNY3IglWZjkprY9lOR9E8w9NMm5HWofnOTmJCuSPLBjX2ckOarLOesryeokD92Q15QkSZIkSdL4fMfiJqKqhoHhaSx5DPDuqvr4NNaUJEmSJEnSZsIVizMkyZ8nubatCPxIkjlJ7kpycpIbk1yd5GFt7o5t/7okf5PkrjHq/XpFYpIntrorktyQZNs2bZskn09ya5JPJ8k4vb0Y+DPgzSPzkrwryU1JViU5us17X5I3t+0/THJpkpF/M4ckuTLJt0dWL05Q5zdWUyY5LclxbXt1krclub6ds2sbf0iSC9r9fQQY814kSZIkSZI0GAaLMyDJHwBHAwdW1SJgLb0VglsDV1fVXsClwEvaKacCp1bVvsD3pnCJk4BXtNoHAz9v43sDrwF2A34fOHCsk6vqY8A5wOur6hjgWcAiYC/gcOBdSRYAS4CjkxwGvA84vqrua2UWAAcBTweWtrHx6kzmh1X1OOBD7d4A3gJcXlV7t153GO/kJCckGU4yvPbuNVO4nCRJkiRJktaXweLMeDKwD3BdkhVt//eBXwIjK/eWAwvb9v7AWW37H6dQ/wrgH5KcCGxXVfe28Wur6j9a+Leir/5kDgI+U1Vrq+oHwCXAvlV1N73w80LgtKr6t75zvlRV91XVLcDDJqozhet/sX32fyeHAJ8CqKrzgB+Pd3JVLauqoaoamrPV/ClcTpIkSZIkSevLYHFmBDizqha1P7tU1VuBX1VVtTlrWcd3XFbVUuDFwAOBq0ceHwbu6ZvWpf5EjxnvAfwP8PBR4/3XyqjP0e7lN/+tbTlOrdE9F5IkSZIkSdooGSzOjK8BRyX5PYAkD07yqAnmXw0c2bafM1nxJDtW1aqqOoXeD7rsOtk5k7iU3iPPc5JsT2+14LWt57+k94j1Hyd5/LrUAb4D7JZkXpL59FZwTqWnYwCS/DHwu+tyY5IkSZIkSZoZ/ir0DKiqW5K8Cbig/djJr4BXTHDKa4BPJflL4DxgshcFvqa993AtcAvw/+g9Tr2uzm7n30hvleBfAT+g9wj0SVX1vSQvAs5IMtGjzb9Vp6r+EyDJPwErgW8BN0yhp7cBn0lyPb1Hqv99XW5MkiRJkiRJMyP3P5mrQUmyFfDzqqokzwGeW1XPGHRfm6KhoaEaHh4edBuSJEmSJEmzRpLlVTU0etwVixuHfYDTkgT4CfDCwbYjSZIkSZIkTcxgcSNQVZcBe81E7SRnA48eNfyGqjp/Jq4nSZIkSZKkzYPB4ixXVUcMugdJkiRJkiTNPv4qtCRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLU2dxBNyBNp1V3rGHhkvMG3YYkSZK0yVq9dPGgW5AkbSJcsShJkiRJkiSpM4NFrZckC5PcNMW5b01y0iRz/jTJkunpTpIkSZIkSTPFR6G1Uamqc4BzBt2HJEmSJEmSJuaKRU2bJL+f5IYkj0/ylSTLk1yWZNcx5l6c5L1JrkxyU5L92vhxSU5r29sn+UKS69qfAzf0PUmSJEmSJGlsrljUtEiyC/BZ4Hjg74GXVtW3kjwe+CDwpDFO27qqDkhyCHA6sPuo46cC76mqy5PsAJwP/MEY1z4BOAFgzoO2n65bkiRJkiRJ0gQMFjUdtge+DBwJfAc4ADgrycjxeeOc9xmAqro0yYOSbDfq+OHAbn11HpRk26q6s39SVS0DlgHMW7BTrd+tSJIkSZIkaSoMFjUd1gDfBQ5snz+pqkVTOG90CDh6/wHA/lX18/XuUJIkSZIkSdPKdyxqOvwSeCbwAuDpwO1Jng2Qnr3GOe/oNucgYE1VrRl1/ALglSM7SRZNb9uSJEmSJElaVwaLmhZV9TN6oeJrgc8BL0pyI3Az8IxxTvtxkiuBDwMvGuP4icBQkpVJbgFeOv2dS5IkSZIkaV2kylfSacNLcjFwUlUNT2fdeQt2qgXHvnc6S0qSJEmbldVLFw+6BUnSRibJ8qoaGj3uOxY1q+zxiPkM+x9CkiRJkiRJM85gUQNRVYcOugdJkiRJkiStO9+xKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGSJEmSJElSZwaLkiRJkiRJkjozWJQkSZIkSZLUmcGiJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqbO5g25Amk6r7ljDwiXnDboNSZIkaZO1euniQbcgSdpEuGJRkiRJkiRJUmcGiyLJcUlOG+fYvyTZblDXlyRJkiRJ0sbJR6E1oap62kzWT+K/QUmSJEmSpE2QKxZnsSRbJzkvyY1JbkpydJJ9k1zZxq5Nsm2b/vAkX0nyrSTv7KuxOslDkyxMcmuSM5OsTPL5JFv1zTml1bs2yWPa+PZJvpDkuvbnwDb+1iTLklwAfGJUz4uTXNWu+dS2fX2Ss5Jss2G+OUmSJEmSJE3GYHF2+yPge1W1V1XtDnwF+Bzw6qraCzgc+Hmbuwg4GtgDODrJI8eotwuwrKr2BH4KvLzv2E+raj/gNOC9bexU4D1VtS9wJPCxvvn7AM+oqueNDCQ5AlgCjKySfBNweFU9DhgGXtf5G5AkSZIkSdKM8DHU2W0V8O4kpwDnAj8Bvl9V1wFU1U8BkgB8rarWtP1bgEcB3x1V77tVdUXb/hRwIvDutv+Zvs/3tO3Dgd1afYAH9a2QPKeqRkJNgMOAIeCpVfXTJE8HdgOuaOf/DnDVWDeZ5ATgBIA5D9p+4m9EkiRJkiRJ08JgcRarqtuS7ENvBeA7gAuAGmf6PX3baxn738boc2uS7QcA+48KEEeCzJ+NqvVt4PeBnemtTgxwYVU9d5x+779Y1TJgGcC8BTuNd3+SJEmSJEmaRj4KPYsleThwd1V9it7KwifQe5fivu34th1/PGWHJPu37ecCl/cdO7rvc2Rl4QXAK/v6WTRB7e8AzwI+keSxwNXAgX3va9wqyc4depUkSZIkSdIMcsXi7LYH8K4k9wG/Al5GbyXg+5M8kN77FQ/vUO8bwLFJPgJ8C/hQ37F5Sa6hF1aPrDI8EfhAkpX0/q1dCrx0vOJV9c0kxwBnAX8CHAd8Jsm8NuVNwG0d+pUkSZIkSdIMSZVPjmpySRYC57YfgRl9bDUwVFU/3NB9jTZvwU614Nj3DroNSZIkaZO1euniQbcgSdrIJFleVUOjx30UWpIkSZIkSVJnrljUrDI0NFTDw8ODbkOSJEmSJGnWcMWiJEmSJEmSpGljsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmcGi5IkSZIkSZI6M1iUJEmSJEmS1JnBoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKmzuYNuQJpOq+5Yw8Il5w26DUmSJGmTtXrp4kG3IEnaRLhiUZIkSZIkSVJnBouSJEmSJEmSOjNYXAdJnp3kG0kuGuPYw5N8fgP0cFyS06ap1sIkz+vbH0ryvumoPcH1bpqp+pIkSZIkSZp5Bovr5kXAy6vqsP7BJHOr6ntVddSA+lpXC4FfB4tVNVxVJw6uHUmSJEmSJG3sDBYnkeRLSZYnuTnJCUneDBwEfDjJu9rKwbOS/DNwQf9qvCRzkrw7yaokK5O8qo2/Ocl1SW5KsixJ2vjFSU5Jcm2S25IcPEl7D0/ylSTfSvLOvp7v6ts+KskZbfuMJO9LcmWSbycZCUCXAgcnWZHktUkOTXJuO+etSU5vvX07yYl9tf86ya1JLkzymSQnTfA97pPkxiRXAa/oG98yycfbd3RDksPa+FZJ/ql9b59Lck2Socn+viRJkiRJkrRh+KvQk3thVf0oyQOB64AnAk8CTqqq4STHAfsDe7Z5C/vOPQF4NLB3Vd2b5MFt/LSq+huAJJ8Eng78czs2t6r2S/I04C3A4RP0tgjYG7gH+GaS91fVdye5nwX0gtFdgXOAzwNL2v08vfV06KhzdgUOA7Zt1/kQsBdwZLv+XOB6YPkE1/048KqquiTJu/rGXwFQVXsk2ZVeOLsz8HLgx1W1Z5LdgRXjFU5yAr3vmjkP2n6S25ckSZIkSdJ0cMXi5E5MciNwNfBIYKcx5lxYVT8aY/xw4MNVdS9A35zD2gq8VfRCysf2nfPF9rmc3iPKE/laVa2pql8AtwCPmsL9fKmq7quqW4CHTWE+wHlVdU9V/RD4r3beQcCXq+rnVXUn9wejvyXJfGC7qrqkDX2y7/BBI/tVdSvwHWDnNv7ZNn4TsHK8+lW1rKqGqmpozlbzp3hLkiRJkiRJWh+uWJxAW7l3OLB/Vd2d5GJgyzGm/my8EkCNqrkl8EFgqKq+m+Sto2re0z7XMvnfzz192/3z+685ut/+czJJ/YmuM9VzR65TExzrMi5JkiRJkqSNgCsWJzaf3uO4d7fHdJ/Q8fwLgJcmmQvQHoUeCfp+mGQbYCZ+6OUHSf4gyQOAI6Yw/056jzl3cTnwJ+0didsAi8ebWFU/AdYkOagNHdN3+NKR/fYI9A7AN1v9P2vjuwF7dOxPkiRJkiRJM8hgcWJfAeYmWQm8nd7j0F18DPh3YGV7nPp5LWT7KLAK+BK99zZOtyXAucDXge9PYf5K4N724yqvncoFquo6eu9ovJHe49vDwJoJTjke+ED78Zaf941/EJjTHgv/HHBcVd3Txrdv3/0bWo8T1ZckSZIkSdIGlKrxnlCVJpZkm6q6K8lW9FYenlBV109T7TnAFlX1iyQ7Al8Ddq6qX0503tDQUA0PD09HC5IkSZIkSQKSLK+qodHjvmNR62NZe0x5S+DM6QoVm62Ai5JsQe99iy+bLFSUJEmSJEnShmOwuJFL8ofAKaOGb6+qqbw7cUZV1fNGjyX5AHDgqOFTq+rjHWvfCfxWEi5JkiRJkqSNg8HiRq6qzgfOH3QfU1VVrxh0D5IkSZIkSZp5/niLJEmSJEmSpM4MFiVJkiRJkiR1ZrAoSZIkSZIkqTODRUmSJEmSJEmdGSxKkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktTZ3EE3IE2nVXesYeGS8wbdhiRJkrTRWr108aBbkCTNEq5YlCRJkiRJktSZwaLGlGRhkpvGGL84ydA61jw0yQF9+y9N8oJJ5p+7LteSJEmSJEnSzPJRaG1IhwJ3AVcCVNWHB9qNJEmSJEmS1pkrFjWRuUnOTLIyyeeTbNV/MMldfdtHJTmjbW+f5AtJrmt/DkyyEHgp8NokK5IcnOStSU5q5zwmyVeT3Jjk+iQ7jrrWvkluSPL7M33TkiRJkiRJmpzBoiayC7CsqvYEfgq8fIrnnQq8p6r2BY4EPlZVq4EPt/FFVXXZqHM+DXygqvYCDgC+P3KgPT79YeAZVfXt0RdLckKS4STDa+9e0+0OJUmSJEmStE58FFoT+W5VXdG2PwWcOMXzDgd2SzKy/6Ak2443uR17RFWdDVBVv2jjAH8ALAOeWlXfG+v8qlrW5jBvwU41xR4lSZIkSZK0HgwWNZHRId1E+1v2bT8A2L+qft4/uS9oHG3cA/RWLm4J7A2MGSxKkiRJkiRpw/NRaE1khyT7t+3nApePOv6DJH+Q5AHAEX3jFwCvHNlJsqht3gn81srFqvop8B9Jntnmz+t7n+NPgMXA3yU5dD3uRZIkSZIkSdPIYFET+QZwbJKVwIOBD406vgQ4F/g6fe9EpPfI9FD70Zdb6P1oC8A/A0eM/HjLqFrPB05s17oS+F8jB6rqB8CfAB9I8vjpuTVJkiRJkiStj1T5SjrNHvMW7FQLjn3voNuQJEmSNlqrly4edAuSpE1MkuVVNTR63HcsalbZ4xHzGfY/lCRJkiRJkmacj0JLkiRJkiRJ6sxgUZIkSZIkSVJnBouSJEmSJEmSOjNYlCRJkiRJktSZwaIkSZIkSZKkzgwWJUmSJEmSJHVmsChJkiRJkiSpM4NFSZIkSZIkSZ0ZLEqSJEmSJEnqzGBRkiRJkiRJUmdzB92ANJ1W3bGGhUvOG3QbkiRJ0kZr9dLFg25BkjRLuGJRkiRJkiRJUmcGi5uxJB9Lstug+5AkSZIkSdKmx0ehN2NV9eLprplkTlWtne66rfbcqrp3JmpLkiRJkiSpG1cszgJJ/irJiW37PUm+3rafnORTSZ6a5Kok1yc5K8k27fjFSYba9l1JTkmyPMlXk+zXjn87yZ+2OQuTXNbqXJ/kgDZ+aJKLkvwjsKqNfanVujnJCX293pXk5CQ3Jrk6ycPa+PZJvpDkuvbnwDb+1iTLklwAfGJDfaeSJEmSJEmamMHi7HApcHDbHgK2SbIFcBC9oO9NwOFV9ThgGHjdGDW2Bi6uqn2AO4G/BZ4CHAH8TZvzX8BTWp2jgff1nb8f8MaqGnm0+oWt1hBwYpKH9F3n6qraq/X9kjZ+KvCeqtoXOBL4WF/tfYBnVNXzOnwnkiRJkiRJmkE+Cj07LAf2SbItcA9wPb1A72DgHGA34IokAL8DXDVGjV8CX2nbq4B7qupXSVYBC9v4FsBpSRYBa4Gd+86/tqpu79s/MckRbfuRwE7A/7TrnNvX91Pa9uHAbq1HgAe1+wE4p6p+Pt7NtxWRJwDMedD2402TJEmSJEnSNDJYnAVaALgaOB64ElgJHAbsCNwOXFhVz52kzK+qqtr2ffQCSqrqviQj/05eC/wA2Iveatdf9J3/s5GNJIfSCwr3r6q7k1wMbDnGddZy/7/BB7T5vxEgtqDxZ0ygqpYBywDmLdipJporSZIkSZKk6eGj0LPHpcBJ7fMy4KXACuBq4MAkjwFIslWSnccrMon5wPer6j7g+cCcCeb9uIWKuwJPmELtC4BXjuy0VZGSJEmSJEnaSBkszh6XAQuAq6rqB/RWE15WVf8NHAd8JslKekHjrut4jQ8Cxya5mt5j0OOtJPwKMLdd7+3tmpM5ERhKsjLJLfSCUUmSJEmSJG2kcv9TqdKmb96CnWrBse8ddBuSJEnSRmv10sWDbkGStIlJsryqhkaPu2JRkiRJkiRJUmf+eItmlT0eMZ9h/w+sJEmSJEnSjHPFoiRJkiRJkqTODBYlSZIkSZIkdWawKEmSJEmSJKkzg0VJkiRJkiRJnRksSpIkSZIkSerMYFGS/n/27jzcrrLM8/73R0KFOThEO9JiSowgggQ5gMygFFVlLIECxFmElsZSEW208aVKUQsNYivOGi3EWQQcEKoEVOZBSCAkAUG6JLYiZWkpkRkJ9/vHfo5sDmfayUl2hu/nus519nrWM9xr5/zB9eNZa0mSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ5N7ncB0kRadMdSZpxwfr/LkCRJklZbS+bM7ncJkqS1hDsWJUmSJEmSJPXMYHEtkmRGksXDtF+SZGAC5j8iySfb5zOSHLqic/a4/pIkT16Va0qSJEmSJGl4BouSJEmSJEmSemawuPaZnORLSRYmOTvJRt0nk7wiyaIki5OcMo721yf5WZJLgT2GrLV3kquS/Hxw92I6Tm3zLEpyeGvfN8l5XfN+MskR7fOSJO9Ncn0bs01rf1KSC5PckORzQCb2q5IkSZIkSdLyMlhc+2wNzK2q5wF/BP5h8ESSpwGnAC8EZgE7JzlolPbpwHvpBIp/BWw7ZK3pwJ7AS4A5re3v2xw7APsDp7Z5xvK7qno+8Bng+Nb2HuCKqtoROBfYcnxfgSRJkiRJklY2g8W1zy+r6sr2+at0gr9BOwOXVNVvq+ph4GvA3qO079rV/hBw5pC1vltVj1TVzcBTW9uewDeqallV/Qa4tM0/lm+33/OBGe3z3u0aqKrzgT8MNzDJ0UnmJZm37L6l41hKkiRJkiRJK8pgce1ToxyPdCvxaLcYD52v24PDzDHSXA/z2L+3DUaYaxkweZzrdzpUza2qgaoamLTR1LG6S5IkSZIkaQIYLK59tkyyW/v8CuCKrnM/AfZJ8uQkk9r5S8do37c963B94LBxrH8ZcHiSSUmm0dl1eC3wC2DbJFOSTAVeNM65XgWQ5G+BJ4xjjCRJkiRJklaByWN30Rrmp8Dr2stObqPzzMK/A6iqO5O8C7iYzs7Cf62q7wGM0n4ScDVwJ3A9MGmM9b8D7AbcSGe34Tur6j/aXN8CFra6bhjHtbwX+EaS6+kEnf9vHGMkSZIkSZK0CqRqzDtNpTXGlOkza/rrTut3GZIkSdJqa8mc2f0uQZK0hkkyv6oGhra7Y1Frle23mMo8/0NJkiRJkiRppfMZi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6NrnfBUgTadEdS5lxwvn9LkOSJEnqiyVzZve7BEnSOsQdi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGixMsyT1jnJ+RZPGqXHOC19o8yT+M0eeqVVWPJEmSJEmS+sNgcTWVZFK/5k3HSH8bmwPDBouDc1fV7std4BjGqE2SJEmSJEmriAHNSpJkkyQ/SnJ9kkVJDuw6PTnJl5IsTHJ2ko3amCVJ3p3kCuCwJG9Icl2SG5Oc09XvL5Nc3c69v2vNJDk1yeK25uGtfd8kFyf5OrBohHpnJPlpkk8D1wNPT/KOtsbCJO9tXecAWyVZ0NZ63NzdOyiHmyPJKd27HpOclOR/jdL/cbUNqf3oJPOSzFt239Je/6kkSZIkSZK0HAwWV54HgIOr6vnAfsD/SZJ2bmtgblU9D/gjj90B+EBV7VlV3wS+XVU7V9UOwE+Bo1qfjwGfqaqdgf/oGvv3wCxgB2B/4NQk09u5XYATq2rbUWreGvhyVe3YPs9s42YBOyXZGzgB+PeqmlVV7xht7iQHjDDHN4HDu7q+DDhrlP6Pqa2qftG9TlXNraqBqhqYtNHUUS5PkiRJkiRJE8VgceUJ8IEkC4EfAlsAT23nfllVV7bPXwX27Bp3Ztfn7ZJcnmQR8Crgua19D+Ab7fNXuvrvCXyjqpZV1W+AS4Gd27lrq+r2MWr+RVVd0z4f0H5uoLNLcBs6od9wRpp72Dmq6gbgKUmelmQH4A9V9f/GWLO7NkmSJEmSJPXZ5H4XsBZ7FTAN2Kmq/pRkCbBBO1dD+nYf39v1+QzgoKq6MckRwL4jjBmUYdqGm3c8fQJ8sKo+95gFkhk9zD3sHM3ZwKHAf6Ozg3GsNcdTvyRJkiRJklYRdyyuPFOB/2yh4n7AM7rObZlkt/b5FcAVI8yxKXBnkvXpBJWDrgRe3j53t18GHJ5kUpJpwN7AtctZ/wXAkUk2AUiyRZKnAHe3ulZkDuiEiS+nEy6ePY7+kiRJkiRJWo24Y3Hl+Rrw/STzgAXALV3nfgq8LsnngNuAz4wwxz8BPwF+QefFKIOB3luBryd5K3BOV//vALsBN9LZ0fjOqvqPJNv0WnxVXZjkOcDV7dGQ9wCvrqp/T3JlksXAvwHn9zoHncD1piSbAndU1Z1j9F/Wa/2SJEmSJElauVI13B210pppYGCg5s2b1+8yJEmSJEmS1hpJ5lfVwNB2b4WWJEmSJEmS1DNvhV7HJHkS8KNhTr2oqv5rVdcjSZIkSZKkNZPB4jqmhYez+l2HJEmSJEmS1mzeCi1JkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZ5P7XYA0kRbdsZQZJ5zf7zIkSZKkvlgyZ3a/S5AkrUPcsShJkiRJkiSpZwaLkiRJkiRJknpmsLiWSfK+JPuP0WffJLuP0eeMJIdObHXLL8mMJIv7XYckSZIkSZI6fMbiWqaq3j2ObvsC9wBXrYwakkyqqmUrOMfkqnp4omqSJEmSJEnSxHLH4hogycZJzk9yY5LFSQ5P8u4k17XjuUnS+v55p2GSJUnem+T6JIuSbJNkBnAM8LYkC5LsNcrS+ye5PMnPkrykzTkpyalt7YVJ/mdr3zfJxUm+Dixqx5ckOTvJLUm+1lXjSLVfkuQDSS4F3ppkp3bNVwNvWklfryRJkiRJkpaDweKa4W+AX1fVDlW1HfAD4JNVtXM73hB4yQhjf1dVzwc+AxxfVUuAzwIfrapZVXX5KOvOAPYBZgOfTbIBcBSwtKp2BnYG3pDkL1v/XYATq2rbdrwjcBywLfBMYI/WPlrtm1fVPlX1f4AvAsdW1W6jfTlJjk4yL8m8ZfctHa2rJEmSJEmSJojB4pphEZ3dg6ck2auqlgL7JflJkkXAC4HnjjD22+33fDpBYS++VVWPVNVtwM+BbYADgNcmWQD8BHgSMLP1v7aqbu8af21V/aqqHgEWdK0/Wu1nAiSZSidkvLS1f2WkIqtqblUNVNXApI2m9niJkiRJkiRJWh4+Y3ENUFU/S7IT8GLgg0kupHNr8EBV/TLJScAGIwx/sP1eRu//3jXMcYC3VNUF3SeS7AvcO8Laf16/7Xr89Ci1D86RYdaXJEmSJEnSasIdi2uAJE8D7quqrwIfBp7fTv0uySZAr29vvhvYdBz9DkuyXpKt6NzKfCtwAfDGJOu32p6dZOMe1h4MEUetvaruApYm2bM1vaqHNSRJkiRJkrSSuWNxzbA9cGqSR4A/AW8EDqJzi/QS4Loe5/s+cHaSA+nsPhzpOYu3ApcCTwWOqaoHknyBzi3N17eXrvy21TIuVXVXks+Ps/bXA6cnuY9OoClJkiRJkqTVRKq821RrjynTZ9b0153W7zIkSZKkvlgyZ3a/S5AkrYWSzK+qgaHt7ljUWmX7LaYyz/+YkiRJkiRJWukMFtdxSU4EDhvSfFZVndyPeiRJkiRJkrRmMFhcx7UA0RBRkiRJkiRJPfGt0JIkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWeT+12ANJEW3bGUGSec3+8yJEmSpJViyZzZ/S5BkqQ/c8eiJEmSJEmSpJ4ZLEqSJEmSJEnq2RodLCY5I8mh/a5jLEn2TXLeCs5xSZKBiappOWvYN8nuo5x/aZITVmVNkiRJkiRJ6g+fsajHSDK5qh4e4fS+wD3AVSOMOxc4t0+1SZIkSZIkaRVao3YsJnltkoVJbkzylda8d5Krkvy8e/diknckua71f29r2zjJ+W384iSHt/Z3t76Lk8xNktZ+SZLT2vyLk+zSNc/pbcwNSQ5s7TOSXJ7k+vbzuN19SXZuY56ZZKcklyaZn+SCJNPH+ApePUwtu7S2G9rvrVv75Ulmda17ZZLnjfC9ntSu+0Lgy0mmJTmnXd91SfZIMgM4BnhbkgVJ9mo7Rj+S5GLglCRHJPlkm3O4OdZLsiTJ5l1r/98kTx2u/3C1jfH9SJIkSZIkaRVZY3YsJnkucCKwR1X9LskTgY8A04E9gW3o7JY7O8kBwExgFyDAuUn2BqYBv66q2W3OqW36T1bV+1rbV4CXAN9v5zauqt3b+NOB7VodP66qI1tIdm2SHwL/CfxVVT2QZCbwDeDPty+3oPETwIHAncBXgQOr6rct5DwZOHKUr2G4Wm4B9q6qh5PsD3wAOAT4AnAEcFySZwNTqmrhKHPvBOxZVfcn+Trw0aq6IsmWwAVV9ZwknwXuqaoPt+s5Cng2sH9VLUtyRNd8Hxthju8BBwNfTLIrsKSqfjPcmsBzhtY2XOFJjgaOBpi02bRRLlGSJEmSJEkTZY0JFoEXAmdX1e8Aqur3bWPhd6vqEeDmJE9tfQ9oPze0403oBI2XAx9OcgpwXlVd3s7vl+SdwEbAE4GbeDRY/EZb77Ikm7Ug8QDgpUmOb302ALYEfg18su0UXEYndBv0HGAucEBV/TrJdnSCwYvadUyiEzaOZrhaNgW+1ILMAtZvfc8C/inJO+iElWeMMfe5XcHd/sC2rS6AzZJsOsK4s6pq2TDtI81xJvBu4IvAy9vxWGueO1KoCFBVc+l8t0yZPrNGvkRJkiRJkiRNlDUpWAyd4GyoB4f0Gfz9war63OMmSXYCXgx8sN1e+yHg08BAVf0yyUl0gsJBQ9esNv8hVXXrkLlPAn4D7EDnNvMHuk7f2ebdkU4AGeCmqtpthOsdznC1vB+4uKoObrcrXwJQVfcluYjO7siX0bVzcgT3dn1eD9htaJjXFfqNNK7bSHNcDTwryTTgIOCfx7HmSGtIkiRJkiSpT9akZyz+CHhZkicBtFuhR3IBcGSSTVrfLZI8JcnTgPuq6qvAh4Hn82iI+LvWf+hbpgefw7gnsLSqlrb535L8+VmMO7a+U4E72w7K19DZhTjoLmA28IEk+wK3AtOS7NbmWL/d7j2a4WqZCtzRzh8xpP8XgI8D11XV78eYu9uFwJsHD7qe1Xg3nR2Syz1HVRXwHTq3sf+0qv5rjDUlSZIkSZK0GlpjdixW1U1JTgYuTbKMR29zHq7vhUmeA1zdsr97gFcDzwJOTfII8CfgjVV1V5LPA4uAJcB1Q6b7Q5KrgM149PmH7wdOAxa2cHEJnecyfho4J8lhwMUM2WnXniX4d8C/tbkOBT7envU4uc150yhfw3C1fIjOrdBvB348ZL35Sf5I57bjXhwLfCrJwlbXZXRe3PJ9Os+wPBB4y3LOAZ3bn6/jsUHoaP0lSZIkSZK0mklnA5mGk+QS4PiqmtfvWpZH26F5CbBN20W51hsYGKh589bIfy5JkiRJkqTVUpL5VfW4x+ytSbdCqwdJXgv8BDhxXQkVJUmSJEmStOqsMbdC90NV7buq10zyKWCPIc0fq6qebmeuqi8DXx4y9+uBtw7pemVVvannQiVJkiRJkrROM1hczazMkK+Fk70+b1GSJEmSJEl6HG+FliRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPZvc7wKkibTojqXMOOH8fpchSZIkrRRL5szudwmSJP2ZOxYlSZIkSZIk9cxgUZIkSZIkSVLPDBbXAUlmJFncPg8k+fgoffdNct5KqmPfJLt3HR+UZNuVsZYkSZIkSZJWLoPFdUxVzauqY/u0/L7A7l3HBwE9BYtJfC6oJEmSJEnSasBgcTWX5NVJrk2yIMnnkkxKck+Sk5PcmOSaJE9tfbdqx9cleV+Se4aZ7887EpPs0+ZdkOSGJJu2bpskOTvJLUm+liSj1Dcnyc1JFib5cGubluScVsd1SfZIMgM4BnhbW28f4KXAqe14q/bzgyTzk1yeZJs23xlJPpLkYuCUYWo4Osm8JPOW3bd0hb5vSZIkSZIkjY+7v1ZjSZ4DHA7sUVV/SvJp4FXAxsA1VXVikg8BbwD+GfgY8LGq+kaSY8axxPHAm6rqyiSbAA+09h2B5wK/Bq4E9gCuGKa+JwIHA9tUVSXZvJ36GPDRqroiyZbABVX1nCSfBe6pqsEA8lzgvKo6ux3/CDimqm5LsivwaeCFbc5nA/tX1bKhdVTVXGAuwJTpM2sc1y1JkiRJkqQVZLC4ensRsBNwXds0uCHwn8BDwOBzEOcDf9U+70bn9mKArwMfHmP+K4GPJPka8O2q+lVb59qq+hVAkgXADIYJFoE/0gkjv5Dk/K6a9ge27drouFnXbshhtWBzd+CsrnFTurqcNVyoKEmSJEmSpP4wWFy9BfhSVb3rMY3J8VU1uDNvGcv571hVc1og+GLgmiT7t1MPdnUbcf6qejjJLnQC0JcDb6azw3A9YLequn9I3aOVsx5wV1XNGuH8vaNfjSRJkiRJklYln7G4evsRcGiSp0Dn1uMkzxil/zXAIe3zy8eaPMlWVbWoqk4B5gHb9FJc22U4tar+FTgOmNVOXUgnZBzsN9h+N9C9c/HPx1X1R+D2JIe1MUmyQy/1SJIkSZIkadUxWFyNVdXNwD8CFyZZCFwETB9lyHHA25Nc2/qN9SaT45IsTnIjcD/wbz2WuClwXqvtUuBtrf1YYKC90OVmOi9tAfg+cHB7WctewDeBd7QXx2xF5/mRR7V6bgIO7LEeSZIkSZIkrSJ59I5aremSbATc316k8nLgFVW1ToVzAwMDNW/evH6XIUmSJEmStNZIMr+qBoa2+4zFtctOwCfTeZjhXcCR/S1HkiRJkiRJayuDxbVIVV0OrJTnEib5DvCXQ5r/d1VdsDLWkyRJkiRJ0urNYFHjUlUH97sGSZIkSZIkrT58eYskSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknk3udwHSRFp0x1JmnHB+v8uQJEmSVoolc2b3uwRJkv7MHYuSJEmSJEmSemawKEmSJEmSJKlnBotrsSTTkvwkyQ1J9hql35IkT04yI8nicc49K8mLJ6DGpyU5e0XnkSRJkiRJ0qplsLiWSjIZeBFwS1XtWFWXT/ASs4CegsVW02OOq+rXVXVoD3NM6mVNSZIkSZIkrRwGi6uxtoPwp0k+n+SmJBcm2bDtFrwmycIk30nyhNb/kiQfSHIp8FbgQ8CLkyxo416RZFGSxUlOGWPtZ7adjjsPc+4vgPcBh7e5D0+ycZLTk1zXxh3Y+h6R5Kwk3wcuHOb4z7skk0xKcmqbY2GS/9na901ycZKvA4sm7huWJEmSJEnS8vKt0Ku/mcArquoNSb4FHAK8E3hLVV2a5H3Ae4DjWv/Nq2ofgCT/BQxU1ZuTPA04BdgJ+AOdUO+gqvru0AWTbA18E3h9VS0Yer6qHkry7sG525gPAD+uqiOTbA5cm+SHbchuwPOq6vdJjhhyPKNr6qOApVW1c5IpwJVJLmzndgG2q6rbh6n3aOBogEmbTRv1y5QkSZIkSdLEcMfi6u/2rnBvPrAVnfDw0tb2JWDvrv5njjDPzsAlVfXbqnoY+NqQcYOmAd8DXj1cqDiKA4ATkiwALgE2ALZs5y6qqt939R163D3Ha9scPwGeRCdYBbh2uFARoKrmVtVAVQ1M2mhqDyVLkiRJkiRpebljcfX3YNfnZcDmY/S/d4T2jHO9pcAvgT2Am8Y5ZnD+Q6rq1sc0JrsOU9NoNb6lqi4YMse+o4yRJEmSJElSH7hjcc2zFPhD11ueXwNcOkr/QT8B9mlvf54EvGKEcQ8BB9HZOfjKUea7G9i06/gC4C1JApBkx3HUNNQFwBuTrN/meHaSjZdjHkmSJEmSJK1k7lhcM70O+GySjYCfA68fa0BV3ZnkXcDFdHYG/mtVfW+EvvcmeQlwUZJ7R+h3MY/e+vxB4P3AacDCFi4uAV7S43V9AZgBXN/m+C2dkFOSJEmSJEmrmVRVv2uQJsyU6TNr+utO63cZkiRJ0kqxZM7sfpcgSVoHJZlfVQND292xqLXK9ltMZZ7/sSVJkiRJkrTSGSxqVEn+GjhlSPPtVXVwP+qRJEmSJEnS6sFgUaNqb2i+YMyOkiRJkiRJWqf4VmhJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktSzyf0uQJpIi+5YyowTzu93GZIkSVLPlsyZ3e8SJEnqiTsWJUmSJEmSJPXMYFE9SzIjyeJVuN7mSf5hVa0nSZIkSZKksRksak2wOWCwKEmSJEmStBoxWNTympzkS0kWJjk7yUZJ3p3kuiSLk8xNEoAkxya5ufX9ZmvbJ8mC9nNDkk1b+zvaHAuTvLetNQfYqvU9tT+XK0mSJEmSpG6+vEXLa2vgqKq6MsnpdHYUfrKq3geQ5CvAS4DvAycAf1lVDybZvI0/HnhTG78J8ECSA4CZwC5AgHOT7N3Gb1dVs1bd5UmSJEmSJGk07ljU8vplVV3ZPn8V2BPYL8lPkiwCXgg8t51fCHwtyauBh1vblcBHkhwLbF5VDwMHtJ8bgOuBbegEjaNKcnSSeUnmLbtv6QRdniRJkiRJkkZjsKjlVcMcfxo4tKq2Bz4PbNDOzQY+BewEzE8yuarmAP8D2BC4Jsk2dHYpfrCqZrWfZ1XVv4xZSNXcqhqoqoFJG02dmKuTJEmSJEnSqAwWtby2TLJb+/wK4Ir2+Xft1uZDAZKsBzy9qi4G3knnRSybJNmqqhZV1SnAPDq7Ey8AjmzjSbJFkqcAdwObrqLrkiRJkiRJ0jj4jEUtr58Cr0vyOeA24DPAE4BFwBLgutZvEvDVJFPp7Ej8aFXdleT9SfYDlgE3A//WnsH4HODq9t6Xe4BXV9W/J7kyyeLW7x2r7jIlSZIkSZI0nFQNvaNVWnNNmT6zpr/utH6XIUmSJPVsyZzZ/S5BkqRhJZlfVQND292xqLXK9ltMZZ7/QSZJkiRJkrTS+YxFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST2b3O8CpIm06I6lzDjh/H6XIUmSJPVsyZzZ/S5BkqSeuGNRkiRJkiRJUs/WmmAxyUFJtu1zDVf1c/3llWRWkhePo99Ako9PwHonJTl+ReeRJEmSJElS/6yWwWKS5blF+yCgp2BxOdcZUVXtPpHzrUKzgDGDxaqaV1XHrvxyJEmSJEmStLrrS7CY5J+S3JLkoiTfSHJ8kkuSfCDJpcBbk+yU5NIk85NckGR6G/uGJNcluTHJOUk2SrI78FLg1CQLkmzVfn7Qxl+eZJs2/owkH0lyMXDKCPXt0+ZZkOSGJJsm+XSSl7bz30lyevt8VJJ/bp/vab+nJ7msjV+cZK8kk9rai5MsSvK2Ub6fS5J8tM3x0yQ7J/l2ktsG12r93t7mW5zkuNY2I8nirj7HJzmpa95Tklyb5Getrr8A3gcc3uo9PMkuSa5q135Vkq3b+H2TnNc+n5Tk9Dbnz5OMGjgmOTHJrUl+CGzd1T4ryTVJFrbv9QmtfefWdnWSU7uvSZIkSZIkSf23yl/ekmQAOATYsa1/PTC/nd68qvZJsj5wKXBgVf02yeHAycCRwLer6vNtrn8GjqqqTyQ5Fzivqs5u534EHFNVtyXZFfg08MK2zrOB/atq2QhlHg+8qaquTLIJ8ABwGbAXcC6wBTC99d0T+OaQ8a8ELqiqk5NMAjaisytwi6rartW3+Rhf1UNVtXeStwLfA3YCfg/8e5KPAjOA1wO7AgF+0kLZP4wx7+Sq2qXd+vyeqto/ybuBgap6c6ttM2Dvqno4yf7AB+j8mw21DbAfsClwa5LPVNWfhnZKshPwcob/N/8y8JaqujTJ+4D3AMcBXwSOrqqrkswZ7YKSHA0cDTBps2ljXL4kSZIkSZImQj/eCr0n8L2quh8gyfe7zp3Zfm8NbAdclARgEnBnO7ddCxQ3BzYBLhi6QAsDdwfOauMBpnR1OWuUUBHgSuAjSb5GJ8j8VZLLgePSeY7jzcAT2i7K3YChu/WuA05vAel3q2pBkp8Dz0zyCeB84MJR1odOgAmwCLipqu5s1/Zz4Ol0vsfvVNW9rf3bPBp8jubb7fd8OuHkcKYCX0oyEyhg/RH6nV9VDwIPJvlP4KnAr4bpt1er9b5W67nt91Q6YfKlrd+X6PybbQ5sWlWDz6z8OvCSkS6oquYCcwGmTJ9ZI/WTJEmSJEnSxOnHrdAZ5dy9XX1uqqpZ7Wf7qjqgnTsDeHNVbQ+8F9hgmHnWA+7qGj+rqp4zzDrDqqo5wP8ANgSuSbJNVd0BPAH4Gzq7Fy8HXgbcU1V3Dxl/GbA3cAfwlSSvrao/ADsAlwBvAr4wWg3Ag+33I12fB48nM/L3+DCP/Xcd+v0MzrWMkYPl9wMXt92VfzfMHEPnGms+6ASU4zXa34gkSZIkSZJWA/0IFq8A/i7JBm1n4exh+twKTEuyG0CS9ZM8t53bFLiz7QZ8VdeYu9s5quqPwO1JDmvjk2SH8RaYZKuqWlRVpwDz6NzyC3A1ndt0B4PF49vvoeOfAfxnu2X7X4DnJ3kysF5VnQP8E/D88dYzgsuAg9J5xuTGwMGtlt8AT0nypCRTGGWnX5c/f3fNVDqhKMARK1jnYK0HJ9kwyaZ0wkqqainwhyR7tX6vAS5tIezdSV7Q2l8+ATVIkiRJkiRpAq3yYLGqrqNzu+6NdG7LnQcsHdLnIeBQ4JQkNwIL6NzaDJ1Q7ifARcAtXcO+CbyjvXBkKzqh41Ft/E3AgT2UeVx7IcqNwP3Av7X2y+k8o/D/0nlO4BMZJlgE9gUWJLmBzrMJP0bnuYyXJFlAZ9flu3qo53Gq6vo2z7V0vo8vVNUN7RmH72tt5/HY72gkFwPbDr68BfgQ8MEkV9K5DX2FtFrPpPPveA6P/c5eR+elOwvpPIfyfa39KGBukqvp7GB8zN+IJEmSJEmS+itVq/6RdEk2qap7kmxEZzfb0S18koBH/0ba5xOA6VX11rHGTZk+s6a/7rSVXZ4kSZI04ZbMGe5mLkmS+i/J/KoaGNrej5e3QGcn2rZ0nt33JUNFDWN2knfR+Rv9BeO8JXv7LaYyz/8gkyRJkiRJWun6EixW1Sv7se5QSV4PDN0Fd2VVvWkVrf8pYI8hzR+rqi+uivUnWpInAT8a5tSLquq/epmrqs7k0beES5IkSZIkaTXTrx2Lq4UW4PUtxFtVAeaq0sLDWf2uQ5IkSZIkSStfP94KLUmSJEmSJGkNZ7AoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWeT+12ANJEW3bGUGSec3+8yJEmSpJ4tmTO73yVIktQTdyxKkiRJkiRJ6pnBolaJJPsmOW85x85Isniia5IkSZIkSdLyM1hciyXxVndJkiRJkiStFAaLa7Ak/5TkliQXJflGkuOTXJLkA0kuBd6a5EVJbkiyKMnpSaa0sTsluTTJ/CQXJJne2i9JckqSa5P8LMlerX1SklOTXJdkYZL/2dr3bWPObrV8LUnaub9pbVcAf99V9y5Jrmp1XZVk69HWkCRJkiRJ0urHHW1rqCQDwCHAjnT+Ha8H5rfTm1fVPkk2AG4DXlRVP0vyZeCNST4FfAI4sKp+m+Rw4GTgyDZ+clXtkuTFwHuA/YGjgKVVtXMLJ69McmHrvyPwXODXwJXAHknmAZ8HXgj8X+DMrvJvAfauqoeT7A98oF3LSGvUxH1zkiRJkiRJmggGi2uuPYHvVdX9AEm+33VuMMTbGri9qn7Wjr8EvAn4IbAdcFHbXDgJuLNr/Lfb7/nAjPb5AOB5SQ5tx1OBmcBDwLVV9atWx4I25p629m2t/avA0V1jv5RkJp3QcP0x1hisf1hJjh6ce9Jm00brKkmSJEmSpAlisLjmyijn7h2jT4Cbqmq3Ec4/2H4v49G/kQBvqaoLHjNRsm9X/6FjRtpp+H7g4qo6OMkM4JIx1pgxwjydRarmAnMBpkyf6e5GSZIkSZKkVcBnLK65rgD+LskGSTYBZg/T5xZgRpJntePXAJcCtwLTkuwGkGT9JM8dY70L6NxGvX4b8+wkG4/S/xbgL5Ns1Y5f0XVuKnBH+3zECqwhSZIkSZKkPnHH4hqqqq5Lci5wI/ALYB6wdEifB5K8HjirvSH6OuCzVfVQu93440mm0vk7OA24aZQlv0DnFufr28tZfgscNEp9D7RblM9P8js6Qeh27fSH6NwK/Xbgx8u7hiRJkiRJkvonVd45uqZKsklV3ZNkI+Ay4Oiqur7fdfXTlOkza/rrTut3GZIkSVLPlswZ7iYkSZL6L8n8qhoY2u6OxTXb3CTbAhsAX1rXQ0WA7beYyjz/g0ySJEmSJGmlM1hcg1XVK/tdgyRJkiRJktZNvrxFkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1bHK/C5Am0qI7ljLjhPP7XYYkSZLUsyVzZve7BEmSeuKORUmSJEmSJEk9M1iUJEmSJEmS1DODxbVMkquW51w7f08P6xyUZNteahthnpcmOWFF55EkSZIkSdKqZbC4lqmq3Ye2JZk00rkVcBDQU7CYZPLQ46o6t6rmLO8ckiRJkiRJ6g9DmrVMknuqapMk+wLvAe4EZgHbdp2bDpwJbEbnb+CNVXV5G38y8BLgfuDAqvrNMGvsDrwU2CfJPwKHtFOfAqYB9wFvqKpbkpwB/B7YEbg+yZOGHC8CBqrqzUmmAZ8FtmzzHVdVVyY5CXgaMAP4HfDKIfUcDRwNMGmzacv5zUmSJEmSJKkXowaLLfSpkc5X1fMmvCJNpF2A7arq9iHtrwQuqKqT227GjVr7xsA1VXVikg8BbwD+eeikVXVVknOB86rqbIAkPwKOqarbkuwKfBp4YRvybGD/qlrWgsbu4yO6pv4Y8NGquiLJlsAFwHPauZ2APavq/mHqmQvMBZgyfeaIf6+SJEmSJEmaOGPtWHxJ+/2m9vsr7fer6OxK0+rt2mFCRYDrgNOTrA98t6oWtPaHgPPa5/nAX41nkSSbALsDZyUZbJ7S1eWsqlo2yvGg/ensrBw83izJpu3zucOFipIkSZIkSeqPUYPFqvoFQJI9qmqPrlMnJLkSeN/KLE4r7N7hGqvqsiR7A7OBryQ5taq+DPypqgZ3/C1j/LfKrwfcVVWzxlnHsHW1eXYbGiC2oHGkMZIkSZIkSeqD8b68ZeMkew4etGfsbbxyStLKluQZwH9W1eeBfwGevxzT3A1sClBVfwRuT3JYmz9JdliOOS8E3txV56zlmEOSJEmSJEmrwHiDxaOATyVZkuR2Os/PO3LllaWVbF9gQZIb6Lx45WPLMcc3gXckuSHJVnRujz8qyY3ATcCByzHnscBAkoVJbgaOWY45JEmSJEmStArk0Ttfx9E52ayNWbrySpKW38DAQM2bN6/fZUiSJEmSJK01ksyvqoGh7ePasZjkqUn+BTizqpYm2TbJURNepSRJkiRJkqQ1wnhvhT4DuAB4Wjv+GXDcSqhHq5kkJyZZMOTnxH7XJUmSJEmSpP4a71t/n1xV30ryLoCqejjJspVYl1YTVXUycHK/65AkSZIkSdLqZbw7Fu9N8iSgAJK8APA5i5IkSZIkSdI6arw7Ft8OnAtsleRKYBpw6EqrSpIkSZIkSdJqbVzBYlVdn2QfYGsgwK1V9aeVWpkkSZIkSZKk1dZ43wq9EXACcFxVLQZmJHnJSq1MkiRJkiRJ0mprvM9Y/CLwELBbO/4V8M8rpSJJkiRJkiRJq73xBotbVdWHgD8BVNX9dG6JliRJkiRJkrQOGm+w+FCSDXn0rdBbAQ+utKokSZIkSZIkrdbG+1bo9wA/AJ6e5GvAHsARK6soaXktumMpM044v99lSJIkST1bMmd2v0uQJKknYwaLSdYDngD8PfACOrdAv7WqfreSa5MkSZIkSZK0mhozWKyqR5K8uaq+BbgVTJIkSZIkSdK4n7F4UZLjkzw9yRMHf1ZqZfqzJDOSLF7Rvknel2T/CajnuCQbTcA8E1KPJEmSJEmSVr3xPmPxSDovbvmHIe3PnNhyNFSSSRM1V1W9e6Q1qmpZD1MdB3wVuG+8A4au0Y6HrWeUOSZX1cO9jJEkSZIkSdLKMd4di9sCnwJuBBYAnwCeu5JqWisleX+St3Ydn5zkrUlOTbI4yaIkh7dz+ya5OMnXgUVD5nlmkhuS7JzkuUmuTbIgycIkM1u3SUk+n+SmJBe2N3qT5Iwkh7bPS5K8O8kVwGFJDkhydZLrk5yVZJMRruNY4GnAxUkubm3Djh1mjaHH3fXslOTSJPOTXJBkemu/JMkHklwKvHW4miRJkiRJkrTqjTdY/BLwHODjdELF57Q2jd+/AK+DP78Q5+XAr4BZwA7A/sCpg4EasAtwYlVtOzhBkq2Bc4DXV9V1wDHAx6pqFjDQ5gOYCXyqqp4L3AUcMkJND1TVnsAPgX8E9q+q5wPzgLcPN6CqPg78GtivqvZL8uQxxj5QVXtW1TdHOCbJ+nT+rg6tqp2A04GTu+bYvKr2qar/M1xNSY5OMi/JvGX3LR3hUiVJkiRJkjSRxnsr9NZVtUPX8cVJblwZBa2tqmpJkv9KsiPwVOAGYE/gG+0W4d+0XXk7A38Erq2q27ummAZ8Dzikqm5qbVcDJyb578C3q+q2JAC3V9WC1mc+MGOEss5sv19AZ1fqlW38X7S5x2OssWcO6T/0GGBrYDs6z/IEmATcOcaYP6uqucBcgCnTZ9Y465YkSZIkSdIKGG+weEOSF1TVNQBJdgWuXHllrbW+ABwB/Dc6u/IOGKXvvUOOlwK/BPYAbgKoqq8n+QkwG7ggyf8Afg482DVuGbDhGGsEuKiqXjHuK3nUWGOHXsfQ48E5bqqq3cY5hyRJkiRJkvps1Fuh23P/FgK7Ale1Z+TdTmdH2t6rosC1zHeAv6GzK/EC4DLg8CSTkkyj851eO8LYh4CDgNcmeSV0nrcI/Lzdnnwu8LzlrOsaYI8kz2rzbpTk2aP0vxvYdDnHDudWYFqS3doc6yfxGZ6SJEmSJEmrsbF2LL5klVSxjqiqh9oLT+6qqmVJvgPsRuelOAW8s6r+I8k2I4y/N8lL6NwyfC+dW5BfneRPwH8A7wM2W466fpvkCOAbSaa05n8EfjbCkLnAvyW5sz1nsZexw63/UHuJy8eTTKXzd3kabWemJEmSJEmSVj+p8pF0q0p7acv1wGFVdVu/61kbTZk+s6a/7rR+lyFJkiT1bMmc2f0uQZKkYSWZX1UDQ9vH+4xFraAk2wLnAd8xVFx5tt9iKvP8DzJJkiRJkqSVzmBxFamqm4Fn9ruOXrRbtf9ySPP/rqoL+lGPJEmSJEmSVh8GixpRVR3c7xokSZIkSZK0ehr1rdCSJEmSJEmSNByDRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9m9zvAqSJtOiOpcw44fx+lyFJkiT1bMmc2f0uQZKknrhjUZIkSZIkSVLPDBYlSZIkSZIk9cxgcR2QZFaSF4+j3z09zHlQkm1XrDJI8tIkJ6zoPJIkSZIkSVq1DBbXDbOAMYPFHh0E9BQsJpk89Liqzq2qOcs7hyRJkiRJkvrDkGYNkGRj4FvAfwcmAe8Hfg58DNgYeBB4EfAn4DPAAPAw8HbgSuB9wIZJ9gQ+CJwPfKL1K+C9VXVOW+tk4CXA/cCBVfWbYerZHXgpsE+SfwQOaac+BUwD7gPeUFW3JDkD+D2wI3B9kicNOV4EDFTVm5NMAz4LbNnmO66qrkxyEvA0YAbwO+CVy/tdSpIkSZIkaWIYLK4Z/gb4dVXNBkgyFbgBOLyqrkuyGZ0g8K0AVbV9km2AC4FnA++mhXdt/CnA0qravh0/oa2zMXBNVZ2Y5EPAG4B/HlpMVV2V5FzgvKo6u83xI+CYqrotya7Ap4EXtiHPBvavqmUtaOw+PqJr6o8BH62qK5JsCVwAPKed2wnYs6ruH1pPkqOBowEmbTZtnF+pJEmSJEmSVoTB4pphEfDhFgieB9wF3FlV1wFU1R8B2o7ET7S2W5L8gk6IN9T+wMsHD6rqD+3jQ21+gPnAX42nuCSbALsDZyUZbJ7S1eWsqlo2ynF3Xdt2zbFZkk3b53OHCxVb/XOBuQBTps+s8dQsSZIkSZKkFWOwuAaoqp8l2YnOcxI/SGcn4nABWoZpG05GGP+nqhpsX8b4/z7WA+6qqlkjnL93jOPueXYbGiC2oHGkMZIkSZIkSeoDX96yBkjyNOC+qvoq8GHgBcDTkuzczm/aXmpyGfCq1vZsOs8qvBW4G9i0a8oLgTd3zf8EevfnOduOyduTHNbmS5IdlmPOoXXNWo45JEmSJEmStAoYLK4ZtgeuTbIAOJHOMxMPBz6R5EbgImADOs81nNReiHImcERVPQhcTOcW4wVJDqfz3MQnJFncxu+3HDV9E3hHkhuSbEUn0DyqzXcTcOByzHksMJBkYZKbgWOWYw5JkiRJkiStAnn0zldpzTcwMFDz5s3rdxmSJEmSJElrjSTzq2pgaLs7FiVJkiRJkiT1zJe3aFRJTgQOG9J8VlWd3I96JEmSJEmStHowWNSoWoBoiChJkiRJkqTH8FZoSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUs8n9LkCaSIvuWMqME87vdxmSJElSz5bMmd3vEiRJ6ok7FiVJkiRJkiT1zGBRkiRJkiRJUs8MFleCJDOSLO7DumckOXSY9n2TnDfBa/1/EzTPF5JsOxFzSZIkSZIkadUxWFyNJJk82vFqpudgMcmkocdV9T+q6ublnUOSJEmSJEn9YbC4kiV5ZpIbkuya5AdJ5ie5PMk27fwZST6S5GLglCHHpya5Lcm01ne9JP83yZNHWXL/Nv/PkrxkmHpOSnJ81/HiJDPa51cnuTbJgiSfGynESzIH2LD1+9poY5Pck+R9SX4C7DbM8SVJBlrfA5JcneT6JGcl2aS1L0ny7iRXAIcNU8/RSeYlmbfsvqVj/ZNIkiRJkiRpAhgsrkRJtgbOAV4PfAB4S1XtBBwPfLqr67OB/avqfw05fhvwVeBVrX1/4Maq+t0oy84A9gFmA59NssE4a30OcDiwR1XNApZ1rfsYVXUCcH9VzaqqV40xdmNgcVXtWlVXDHM8uP6TgX9s1/18YB7w9q5lH6iqPavqm8PUM7eqBqpqYNJGU8dzuZIkSZIkSVpBq/Ottmu6acD3gEOAXwC7A2clGTw/pavvWVW1bITj09s8pwFHAl8cY91vVdUjwG1Jfg5sM856XwTsBFzXatwQ+M8JGLuMTrjKCMeDXgBsC1zZ5vgL4Oqu82eOsxZJkiRJkiStAgaLK89S4JfAHu33XW0333DuHem4qn6Z5DdJXgjsygi7CLvUGMcP89idqoM7GgN8qareNcb8wxlt7ANDQtOhx91zXFRVrxhhjaHfkSRJkiRJkvrIW6FXnoeAg4DXAi8Bbk9yGEA6duhhri/QuSX6WyOEct0Oa89i3Ap4JnDrkPNLgOe3Op4P/GVr/xFwaJKntHNPTPKMUdb5U5L1l3PscK4B9kjyrDbHRkme3eMckiRJkiRJWkUMFleiqrqXTqj4Njq38h6V5EbgJuDAHqY6F9iEsW+Dhk6QeCnwb8AxVfXAkPPnAE9MsgB4I/CzVuvNdJ5xeGGShcBFwPRR1pkLLEzyteUY+zhV9VvgCOAbbY5rGP9t3JIkSZIkSVrFUjX0Tlmtbtpbkz9aVXv1u5bV3cDAQM2bN6/fZUiSJEmSJK01ksyvqoGh7T5jcTWX5AQ6OwvHeraiJEmSJEmStMoYLK7mqmoOMKe7LcmJwGFDup5VVSdP9PpJfsJj32AN8JqqWjTRa0mSJEmSJGnNYbC4BmoB4oSHiCOsteuqWEeSJEmSJElrFl/eIkmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnk/tdgDSRFt2xlBknnN/vMiRJkqSeLZkzu98lSJLUE3csSpIkSZIkSeqZwaIkSZIkSZKknhksDpHkX5NsvgLjT0py/Oq0ZpJtkixIckOSrZZ3na759k2y+wTMM5Dk4ys6jyRJkiRJklY9n7E4RFW9eGhbkgCpqkfW0DUPAr5XVe+ZgLkA9gXuAa4a74Akk6vq4SHH84B5yzuHJEmSJEmS+med27GY5J1Jjm2fP5rkx+3zi5J8NcmSJE9OMiPJT5N8GrgeeHqSdyS5LsnCJO8dZZltk1yS5OeDa7U1vptkfpKbkhzd1d7zmklOTHJrkh8CW49yvS8GjgP+R5KLW9vbkyxuP8d1tZ3ePm/fzm00zHwzgGOAt7VdkHslmZbknFbndUn2aH1PSjI3yYXAl4c53jfJea3vxklOb+NvSHJgaz8iyVlJvg9cOMp3LkmSJEmSpFVoXdyxeBnwv4CPAwPAlCTrA3sCl7ffg7YGXl9V/5DkAGAmsAsQ4Nwke1fVZcOssQ2wH7ApcGuSz1TVn4Ajq+r3STYErktyTlX915CxY64J3Au8HNiRzr/h9cD84S62qv41yWeBe6rqw0l2Al4P7Nrm/EmSS4HTgEuSHAycCPzPqrpvmPmWdM8HkOTrwEer6ookWwIXAM9pQ3YC9qyq+5OcNOR4366pTwR+XFVHttvCr22hKcBuwPOq6vfDXWMLaY8GmLTZtOG6SJIkSZIkaYKti8HifGCnJJsCD9IJ5QaAvYBjgXd19f1FVV3TPh/Qfm5ox5vQCf2GCxbPr6oHgQeT/CfwVOBXwLEtuAN4ehs/NFgcz5qbAt8ZDP6SnDv+y2fPNvbeNvbbwF5VdUOSI4CFwOeq6soe5tyfzi7NwePN2vcLcG5V3d/Vd+jxoAOAl3Y9K3IDYMv2+aKRQkWAqpoLzAWYMn1m9VC3JEmSJEmSltM6FyxW1Z+SLKGza+8qOkHafsBWwE+HdL+363OAD1bV57o7JHkT8IZ2OPisxAe7uiwDJrfdefsDu1XVfUkuoROeDTWeNY8DljdAyyjnZtJ5duLTepxzPTrX9ZjAsAWN9w7pO/S4u65DqurWIXPsOsoYSZIkSZIk9ck694zF5jLg+Pb7cjrPDFxQVaOFdRcARybZBCDJFkmeUlWfqqpZ7efXo4yfCvyhhYrbAC8YR53DrtnqPjjJhm1n4N+NY65BlwEHJdkoycbAwcDlSaYCHwP2Bp6U5NBR5ribzq7JQRcCbx48SDKrh3oGXQC8pb20hiQ7LscckiRJkiRJWkXW1WDxcmA6cHVV/QZ4oLWNqKouBL4OXJ1kEXA2jw3XxvIDOjsXFwLvB64Zo/+Ia1bV9cCZwALgnLFqHzLn9cAZwLXAT4AvVNUNwEeBT1fVz4CjgDktxBzO9+kEmwuSDN5CPtBeMHMznaC2V+8H1gcWJlncjiVJkiRJkrSayuib9KQ1y5TpM2v6607rdxmSJElSz5bMmd3vEiRJGlaS+VU1MLR9nXvGotZu228xlXn+B5kkSZIkSdJKZ7C4FknyKWCPIc0fq6ovLud8rwfeOqT5yqp60/LMJ0mSJEmSpLWHweJaZKIDvxZILlcoKUmSJEmSpLXbuvryFkmSJEmSJEkrwGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8m97sAaSItumMpM044v99lSJIkSY+zZM7sfpcgSdKEcseiJEmSJEmSpJ4ZLK6jksxIsnglzLtvkvMmet4295IkT14Zc0uSJEmSJKk3BouSJEmSJEmSemawKJI8M8kNSXZN8oMk85NcnmSbdn5aknOSXNd+9mjt+yRZ0H5uSLJpm3KTJGcnuSXJ15Kk9X9R67coyelJprT2JUnem+T6dm5w3SclubCN+RyQVf/tSJIkSZIkaTgGi+u4JFsD5wCvBz4AvKWqdgKOBz7dun0M+GhV7QwcAnyhtR8PvKmqZgF7Afe39h2B44BtgWcCeyTZADgDOLyqtqfz4qA3dpXyu6p6PvCZNi/Ae4ArqmpH4Fxgywm7cEmSJEmSJK0Q3wq9bpsGfI9OWPgLYHfgrLbBEGBK+70/sG1X+2Ztd+KVwEeSfA34dlX9qvW5tqp+BZBkATADuBu4vap+1ub4EvAm4LR2/O32ez7w9+3z3oOfq+r8JH8Y7iKSHA0cDTBps2k9fgWSJEmSJElaHgaL67alwC+BPdrvu9ruw6HWA3arqvuHtM9Jcj7wYuCaJPu39ge7+iyj83c21m3Mg2MG+w+qsS6iquYCcwGmTJ85Zn9JkiRJkiStOG+FXrc9BBwEvBZ4CXB7ksMA0rFD63ch8ObBQUlmtd9bVdWiqjoFmAdsM8patwAzkjyrHb8GuHSM+i4DXtXW+lvgCeO+MkmSJEmSJK1UBovruKq6l06o+DbgTOCoJDcCNwEHtm7HAgNJFia5GTimtR+XZHHrfz/wb6Os8wCd5zielWQR8Ajw2THKey+wd5LrgQOA/7c81yhJkiRJkqSJlyrvHNXaY8r0mTX9daf1uwxJkiTpcZbMmd3vEiRJWi5J5lfVwNB2n7Gotcr2W0xlnv/BJkmSJEmStNJ5K7QkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknk3udwHSRFp0x1JmnHB+v8uQJEmSHmfJnNn9LkGSpAnljkVJkiRJkiRJPTNYlCRJkiRJktSztSpYTHJQkm3H6HNJkoFh2geSfHyMsTOSLB7h3BlJDu2t4t5q7GH8kiRPHqb9pUlOaJ/H/K5GmX+5x45UjyRJkiRJktYsa1WwCBwELFfgVVXzqurYiS1n9VJV51bVnHZ4EMv5XS3P2CSThx4PqafnOSRJkiRJktQ/fQ8Wk7wzybHt80eT/Lh9flGSryY5IMnVSa5PclaSTdr5OUluTrIwyYeT7A68FDg1yYIkW42y7GFJrk3ysyR7tfn2TXJe+zwtyUVtzc8l+UXXDsBJST6f5KYkFybZcJhreneS65IsTjI3SVr7JUlOGWbtDZN8s13LmcDj5uya+2VJPtI+vzXJz9vnrZJc0dX1La3+RUm2aX2OSPLJ4b6r9vODJPOTXD44Zpj1xz227eL8SJKLgVOGOT4iySe7vvNz2vd2XZI9WvtJ7Tu8EPjyCDUdnWReknnL7ls60lcnSZIkSZKkCdT3YBG4DNirfR4ANkmyPrAnsAj4R2D/qno+MA94e5InAgcDz62q5wH/XFVXAecC76iqWVX176OsObmqdgGOA94zzPn3AD9ua34H2LLr3EzgU1X1XOAu4JBhxn+yqnauqu3ohIQvGWPtNwL3tWs5GdhplNq7v6+9gP9KsgWd7+vyrn6/a/V/Bji+e4IRvqu5wFuqaqfW/9PDLb4cY59N59/vf41wPOhjwEeramc63+kXus7tBBxYVa8coaa5VTVQVQOTNpo6XBdJkiRJkiRNsNXh1tL5wE5JNgUeBK6nEzDuRSfA2ha4sm36+wvgauCPwAPAF5KcD5zX45rf7lp7xjDn96QTXFJVP0jyh65zt1fVgjHG75fkncBGwBOBm4Dvj7L23sDH23oLkywcqfCq+o8km7Tv6+nA19v4vbrmHrrO3480H0DbBbo7cFb7ngGmjDamh7FnVdWyUY4H7Q9s2zXHZu0aAc6tqvvHU48kSZIkSZJWjb4Hi1X1pyRLgNcDVwELgf2ArYDbgYuq6hVDxyXZBXgR8HLgzcALe1j2wfZ7GcN/BxmmbejYwfGPuW05yQZ0duwNVNUvk5wEbDCOtWvssv/sajrf1610dikeCewGdO8CHOsau60H3FVVs3qoYbxj7x3juHue3YYGiC1oHGmMJEmSJEmS+mR1uBUaOrf3Ht9+Xw4cAywArgH2SPIsgCQbJXl22yU3tar+lc4txbPaPHcDm7LirgBe1tY8AHhCD2MHQ8TftTrH86boy4BXtfW2A543jv6D39cNdILYB6uqlwcM/vm7qqo/ArcnOazVkCQ7rKSxI7mQTkBMm2fWcswhSZIkSZKkVWR1CRYvB6YDV1fVb+jc5nx5Vf0WOAL4Rrs9+BpgGzqh1nmt7VLgbW2ebwLvSHLDGC9vGct7gQOSXA/8LXAnnTBtTFV1F/B5Os+H/C5w3TiGfYbOsyUXAu8Erh2j/+V0boO+rN1W/Es6YWgvhn5XrwKOSnIjnVu3D1xJY0dyLDDQXmBzM51wWZIkSZIkSaupVPVyB+66IckUYFlVPZxkN+Azy3mbsFaxgYGBmjdvXr/LkCRJkiRJWmskmV9VA0Pb+/6MxdXUlsC3kqwHPAS8oc/1SJIkSZIkSauVtTZYTPIpYI8hzR+rqi+ONbaqbgN2XCmF9SDJT3j825lfU1WLVtH6JwKHDWk+q6pOXhXrS5IkSZIkafW11gaLVfWmftewoqpq1z6vfzJgiChJkiRJkqTHWV1e3iJJkiRJkiRpDWKwKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSeja53wVIE2nRHUuZccL5/S5DkiRJepwlc2b3uwRJkiaUOxYlSZIkSZIk9cxgUeOSZN8k563kNWYlefHKXEOSJEmSJEkTw2BRq5NZgMGihU3ogwAA1PZJREFUJEmSJEnSGsBgcR2SZEaSW5J8IcniJF9Lsn+SK5PclmSX9nNVkhva762HmWfYPkmOSPLdJN9PcnuSNyd5e+t3TZIntn6XJBlon5+cZEmSvwDeBxyeZEGSw5NsnOT0JNe1OQ5cld+XJEmSJEmSRmawuO55FvAx4HnANsArgT2B44H/D7gF2LuqdgTeDXxgmDlG67Ndm3MX4GTgvtbvauC1IxVVVQ+1uc6sqllVdSZwIvDjqtoZ2A84NcnGy3vhkiRJkiRJmji+FXrdc3tVLQJIchPwo6qqJIuAGcBU4EtJZgIFrD/MHKP1ubiq7gbuTrIU+H5rX0QnzOzFAcBLkxzfjjcAtgR+2t0pydHA0QCTNpvW4xKSJEmSJElaHgaL654Huz4/0nX8CJ2/h/fTCQcPTjIDuGSYOUbrM9b8AA/z6G7ZDUapNcAhVXXrKH2oqrnAXIAp02fWaH0lSZIkSZI0MbwVWkNNBe5on49YgT6jWQLs1D4f2tV+N7Bp1/EFwFuSBCDJjsuxliRJkiRJklYCg0UN9SHgg0muBCatQJ/RfBh4Y5KrgCd3tV8MbDv48hY6OyPXBxYmWdyOJUmSJEmStBpIlXeOau0xZfrMmv660/pdhiRJkvQ4S+bM7ncJkiQtlyTzq2pgaLs7FiVJkiRJkiT1zJe3aK2y/RZTmef/CZYkSZIkSVrp3LEoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6NrnfBUgTadEdS5lxwvn9LkOSJEl6nCVzZve7BEmSJpQ7FiVJkiRJkiT1zGBRkiRJkiRJUs8MFtchSWYkWdzH9Q9Ksm3X8RFJntaveiRJkiRJkrT8DBbXYklWt2doHgRs23V8BNBTsLgaXpMkSZIkSdI6yZBmDZDkn4BXAb8EfgfMB34IfBbYCPh34Miq+kOSS4CrgD2Ac9vx6cB9wBVdc24AfAYYAB4G3l5VFyc5Anhpm3cr4DtV9c4R6poE/Eubo4DTq+qjSbYCPgVMa+u+AXhim3efJP8IfKON+1qS+4Hd6ISOHwE2add5RFXdOfSagP+znF+lJEmSJEmSJojB4mouyQBwCLAjnX+v6+kEi18G3lJVlyZ5H/Ae4Lg2bPOq2qeNX9jV79Suqd8EUFXbJ9kGuDDJs9u5WW29B4Fbk3yiqn45THmzgC2qaru21uatfS5wTFXdlmRX4NNV9cIk5wLnVdXZrf/fAsdX1bwk6wOfAA6sqt8mORw4GThy6DUN8x0dDRwNMGmzaaN9nZIkSZIkSZogBourvz2B71XV/QBJvg9sTCdou7T1+RJwVteYM1vfqUP6fQX42655PwFQVbck+QUwGCz+qKqWtjluBp5BZ7fkUD8HnpnkE8D5dMLJTYDdgbOSDPabMo7r3BrYDriojZsE3Dn0moZTVXPphJlMmT6zxrGWJEmSJEmSVpDB4uovY3d5nHu7xo4UtI0274Ndn5cxwt9Ju/V6B+Cv6eyAfBmdXZN3VdWsHuodrOemqtpthPP3jtAuSZIkSZKkPvDlLau/K4C/S7JB2w04m07I9ocke7U+rwEuHTqwqu4ClibZszW9quv0ZYPH7RboLYFbeyksyZOB9arqHOCfgOdX1R+B25Mc1vqkhY8AdwObdk3RfXwrMC3Jbm3c+kme20s9kiRJkiRJWnXcsbiaq6rr2rMJbwR+AcwDlgKvAz6bZCM6tyS/foQpXg+cnuQ+4IKu9k+38YvovLzliKp6sOv25fHYAvhiksGA+l3t96uAz7SXtKwPfLPV/03g80mOBQ4Fzmg1DL685VDg4+0W7snAacBNvRQkSZIkSZKkVSNVPpJudZdkk6q6p4WIlwFHV9X1/a5rdTQwMFDz5s3rdxmSJEmSJElrjSTzq2pgaLs7FtcMc5NsC2wAfMlQUZIkSZIkSf1msLgGqKpX9ruGJD/h8W93fk1VLepHPZIkSZIkSeovg0WNS1Xt2u8aJEmSJEmStPrwrdCSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnk/tdgDSRFt2xlBknnN/vMiRJkrQOWjJndr9LkCRplXLHoiRJkiRJkqSeGSyuwZIcluSnSS5ux99IsjDJ2yZ4nX9NsvkEznfPRM0lSZIkSZKk/vBW6DXbUcA/VNXFSf4bsHtVPWOiF6mqF0/0nMsryeSqerjfdUiSJEmSJK3r3LG4hkjy3STzk9yU5Ogk7wb2BD6b5FTgQuApSRYk2SvJVkl+0MZcnmSbNs8ZST6e5KokP09yaGvfN8llSb6T5OYkn02yXju3JMmTk8xoOyQ/3+q4MMmGrc+xbdzCJN9sbZsk+WKSRa39kK7rOTnJjUmuSfLU1jYtyTlJrms/e7T2k5LMTXIh8OVV9qVLkiRJkiRpRO5YXHMcWVW/b0HedcA+wAuB46tqXpJPAedV1SyAJD8Cjqmq25LsCny69QeYTieU3AY4Fzi7te8CbAv8AvgB8Pdd5wbNBF5RVW9I8i3gEOCrwAnAX1bVg123Tf8TsLSqtm81PaG1bwxcU1UnJvkQ8Abgn4GPAR+tqiuSbAlcADynjdkJ2LOq7h/6xSQ5GjgaYNJm08b3bUqSJEmSJGmFGCyuOY5NcnD7/HQ6Ad+wkmwC7A6clWSweUpXl+9W1SPAzYO7BZtrq+rnbY5v0AkfhwaLt1fVgvZ5PjCjfV4IfC3Jd4Hvtrb9gZcPDqyqP7SPDwHndc3xV139t+2qebMkm7bP5w4XKrZ55wJzAaZMn1nD9ZEkSZIkSdLEMlhcAyTZl07otltV3ZfkEmCDUYasB9w1uHtxGA92T9/1eWgoN1xI1z12GbBh+zwb2Bt4KfBPSZ7b5h5ujj9V1WD7Mh79O1yPzjU+JkBsQeO9w16JJEmSJEmS+sJnLK4ZpgJ/aKHiNsALRutcVX8Ebk9yGEA6dhjHOrsk+cv2bMXDgSvGU1zr//Squhh4J7A5sAmd5z6+uavfE4ad4FFD+88az/qSJEmSJEla9QwW1ww/ACYnWQi8H7hmHGNeBRyV5EbgJuDAcYy5GpgDLAZuB74zzvomAV9Nsgi4gc5zEu+i89zEJyRZ3OrYb4x5jgUG2otebgaOGef6kiRJkiRJWsXy6B2pWpe1262Pr6qX9LmUFTJl+sya/rrT+l2GJEmS1kFL5szudwmSJK0USeZX1cDQdp+xqLXK9ltMZZ7/QSdJkiRJkrTSGSwKgKq6BLikz2VIkiRJkiRpDeEzFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1bHK/C5Am0qI7ljLjhPP7XYYkSZLWQUvmzO53CZIkrVLuWJQkSZIkSZLUM4NFSZIkSZIkST0zWFzDJDkmyWtXwTqXJBnoof/Tkpw9wrkZSRZPXHWSJEmSJEnqN5+xuIapqs/2u4bhVNWvgUOHtifxb0ySJEmSJGkt5I7Flajt1LslyReSLE7ytST7J7kyyW1JdkmycZLTk1yX5IYkB7axH0/y7vb5r5NclmS9JCclOb61PyvJD5PcmOT6JFsl2STJj9rxoq75ZiT5aZLPJ7kpyYVJNhzjEg5Lcm2SnyXZq2uey9v81yfZvat9cft8RJKzknwfuHDIdzIpyantehcm+Z+tfXq7xgXtu9qr9T2jHS9K8raJ+9eRJEmSJEnSinA32cr3LOAw4GjgOuCVwJ7AS4H/D7gZ+HFVHZlkc+DaJD8ETgCuS3I58HHgxVX1SJLuub8GzKmq7yTZgE5Q/BBwcFX9McmTgWuSnNv6zwReUVVvSPIt4BDgq6PUPrmqdknyYuA9wP7AfwJ/VVUPJJkJfAMY7pbp3YDnVdXvk8zoaj8KWFpVOyeZAlyZ5ELg74ELqurkJJOAjYBZwBZVtR1A+34eJ8nR7ftl0mbTRrkcSZIkSZIkTRSDxZXv9qpaBJDkJuBHVVVJFgEzgP8OvHRwFyKwAbBlVf00yRuAy4C3VdW/d0+aZFM6odt3AKrqgda+PvCBJHsDjwBbAE/tqmVB+zy/rT+abw/Td33gk0lmAcuAZ48w9qKq+v0w7QcAz0syeNv0VDqB53XA6a3+71bVgiQ/B56Z5BPA+QzZ/TioquYCcwGmTJ9ZY1yTJEmSJEmSJoDB4sr3YNfnR7qOH6Hz/S8DDqmqW4cZuz3wX8DThjmXYdoAXgVMA3aqqj8lWUInrBxayzJgrFuhB/sv49G/lbcBvwF2oLND8oERxt47QnuAt1TVBY870QlDZwNfSXJqVX05yQ7AXwNvAl4GHDlGzZIkSZIkSVoFfMZi/10AvCXtHuckO7bfzwD+F7Aj8LdJdu0eVFV/BH6V5KDWf0qSjejsAPzPFiruBzxjguudCtxZVY8ArwEm9Tj+AuCNbWciSZ7dnjP5DDp1fx74F+D57Vbu9arqHOCfgOdP2FVIkiRJkiRphbhjsf/eD5wGLGzh4pIkf0cnXDu+qn6d5CjgjCQ7Dxn7GuBzSd4H/InOsxy/Bnw/yTxgAXDLBNf7aeCcJIcBFzPyzsSRfIHObdXXt+v9LXAQsC/wjiR/Au4BXkvnNu4vJhkMwN+1osVLkiRJkiRpYqTKR9Jp7TFl+sya/rrT+l2GJEmS1kFL5szudwmSJK0USeZX1eNe3uuORa1Vtt9iKvP8DzpJkiRJkqSVzmBxHZfkU8AeQ5o/VlVf7Ec9kiRJkiRJWjMYLK7jqupN/a5BkiRJkiRJax7fCi1JkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJkno2ud8FSBNp0R1LmXHC+f0uQ5IkSeugJXNm97sESZJWKXcsSpIkSZIkSeqZwaLGlOSkJMdP0FyXJBmYiLkkSZIkSZLUPwaLWmMk8dZ9SZIkSZKk1YTBoh4nyWuTLExyY5KvDDn35x2HSZ6cZEn7fESS7yb5fpLbk7w5yduT3JDkmiRP7Jrm1UmuSrI4yS5t/MZJTk9yXRtzYNe8ZyX5PnDhKvkCJEmSJEmSNCZ3gOkxkjwXOBHYo6p+1wLBY8c5fDtgR2AD4P8C/7uqdkzyUeC1wGmt38ZVtXuSvYHT27gTgR9X1ZFJNgeuTfLD1n834HlV9fsVv0JJkiRJkiRNBINFDfVC4Oyq+h1AVf0+yXjHXlxVdwN3J1kKfL+1LwKe19XvG23uy5Js1oLEA4CXdj3LcQNgy/b5otFCxSRHA0cDTNps2nhrlSRJkiRJ0gowWNRQAWqU8w/z6C30Gww592DX50e6jh/hsX9rQ+evtu4hVXXrY4pJdgXuHa3gqpoLzAWYMn3maLVLkiRJkiRpgviMRQ31I+BlSZ4EMOTZiABLgJ3a50OXc43D29x7AkurailwAfCWtO2RSXZczrklSZIkSZK0CrhjUY9RVTclORm4NMky4AY6YeKgDwPfSvIa4MfLucwfklwFbAYc2dreT+cZjAtbuLgEeMlyzi9JkiRJkqSVLFXeOaq1x5TpM2v6607rdxmSJElaBy2ZM7vfJUiStFIkmV9VA0Pb3bGotcr2W0xlnv9BJ0mSJEmStNL5jEVJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPZvc7wKkibTojqXMOOH8fpchSZKkddCSObP7XYIkSauUOxYlSZIkSZIk9cxgUZIkSZIkSVLPDBbXYkk2T/IP/a5jLElOSnJ8+3xGkkP7XZMkSZIkSZJGZ7C4dtscWO2DRUmSJEmSJK15DBbXbnOArZIsSHJq+1mcZFGSwwGSfCXJgYMDknwtyUuHmyzJEUm+l+QHSW5N8p6uc29vcy9Octw42k9sc/wQ2HqE9XZKcmmS+UkuSDJ9hH5HJ5mXZN6y+5b29g1JkiRJkiRpufhW6LXbCcB2VTUrySHAMcAOwJOB65JcBnwBeBvwvSRTgd2B140y5y7AdsB9bY7zgQJeD+wKBPhJkkvpBNcjtb8c2JHO3+D1wPzuRZKsD3wCOLCqftuC0JOBI4cWVFVzgbkAU6bPrJ6+IUmSJEmSJC0Xg8V1x57AN6pqGfCbFvDtXFXnJvlUkqcAfw+cU1UPjzLPRVX1XwBJvt3mLeA7VXVvV/tedMLE4drXa+33tfZzh1lnazoB5kVJACYBd67QNyBJkiRJkqQJY7C47sgo574CvIrOLsLH7QgcYuiOwBpl7tHWHGtnYYCbqmq3MfpJkiRJkiSpD3zG4trtbmDT9vky4PAkk5JMA/YGrm3nzgCOA6iqm8aY86+SPDHJhsBBwJVt7oOSbJRkY+Bg4PIx2g9OsmGSTYG/G2adW4FpSXaDzq3RSZ7b6xcgSZIkSZKklcMdi2uxqvqvJFcmWQz8G7AQuJHObsF3VtV/tH6/SfJT4LvjmPYKOjscnwV8varmASQ5g0eDyi9U1Q1jtJ8JLAB+QSdsHFr7Q0kOBT7env04GTgNGCv4lCRJkiRJ0iqQKt91sa5LshGwCHh+VY34WuUkRwADVfXmVVVbrwYGBmrevHn9LkOSJEmSJGmtkWR+VQ0MbfdW6HVckv2BW4BPjBYqSpIkSZIkSd28FXodV1U/BLbsbkvy18ApQ7reXlUH03keoyRJkiRJktZxBot6nKq6ALig33VIkiRJkiRp9eWt0JIkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6NrnfBUgTadEdS5lxwvn9LkOSJEnroCVzZve7BEmSVil3LEqSJEmSJEnqmTsWNeGSnATcA2wGXFZVP+xvRZIkSZIkSZpoBotaaarq3f2uQZIkSZIkSSuHt0JrQiQ5McmtSX4IbN3azkhyaPu8JMl7k1yfZFGSbVr7tCQXtfbPJflFkie3c29Psrj9HNeva5MkSZIkSdLjGSxqhSXZCXg5sCPw98DOI3T9XVU9H/gMcHxrew/w49b+HWDLrjlfD+wKvAB4Q5IdV9pFSJIkSZIkqScGi5oIewHfqar7quqPwLkj9Pt2+z0fmNE+7wl8E6CqfgD8oav9O1V1b1Xd08buNdykSY5OMi/JvGX3LV3hi5EkSZIkSdLYDBY1UWocfR5sv5fx6PM9M0Lfkdofv3DV3KoaqKqBSRtNHe8wSZIkSZIkrQCDRU2Ey4CDk2yYZFPg73oYewXwMoAkBwBP6JrzoCQbJdkYOBi4fAJrliRJkiRJ0grwrdBaYVV1fZIzgQXAL+gtAHwv8I0khwOXAncCd7c5zwCubf2+UFU3TFzVkiRJkiRJWhEGi5oQVXUycPIo52d0fZ4H7NsOlwJ/XVUPJ9kN2K+qHmz9PgJ8ZGXVLEmSJEmSpOVnsKh+2xL4VpL1gIeAN/S5HkmSJEmSJI2DwaL6qqpuA3acqPm232Iq8+bMnqjpJEmSJEmSNAJf3iJJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJkno2ud8FSBNp0R1LmXHC+f0uQ5IkSWuZJXNm97sESZJWO+5YlCRJkiRJktQzg0VJkiRJkiRJPTNY7KMkxyXZaALnW5LkySsw/ogkn5yoenpY95IkA+3zCl2DJEmSJEmSVg2Dxf46DpiwYLFXSSb1a21JkiRJkiSt2QwWV5EkGyc5P8mNSRYneQ/wNODiJBe3Pp9JMi/JTUne2zV2SZL3Jrk+yaIk27T2JyW5MMkNST4HpGvMd5PMb3Md3dV+T5L3JfkJsFuS1yf5WZJLgT3GuIYzknw2yeVtzEta+wZJvthquyHJfmO0b5jkm0kWJjkT2HCE9V6d5NokC5J8ziBUkiRJkiRp9WGwuOr8DfDrqtqhqrYDTgN+DexXVfu1PidW1QDwPGCfJM/rGv+7qno+8Bng+Nb2HuCKqtoROBfYsqv/kVW1EzAAHJvkSa19Y2BxVe0K/DvwXjqB4l8B247jOmYA+wCzgc8m2QB4E0BVbQ+8AvjSGO1vBO6rqucBJwM7DV0kyXOAw4E9qmoWsAx41XAFJTm6BbLzlt23dByXIEmSJEmSpBVlsLjqLAL2T3JKkr2qargE7GVJrgduAJ7LY4O+b7ff8+mEewB7A18FqKrzgT909T82yY3ANcDTgZmtfRlwTvu8K3BJVf22qh4CzhzHdXyrqh6pqtuAnwPbAHsCX2l13AL8Anj2KO3ddS8EFg6zzovoBI7XJVnQjp85XEFVNbeqBqpqYNJGU8dxCZIkSZIkSVpRk/tdwLqiqn6WZCfgxcAHk1zYfT7JX9LZibhzVf0hyRnABl1dHmy/l/HYf7caulaSfYH9gd2q6r4kl3TN9UBVLRtt/FiXMsxxhus4Svt41g3wpap613gLkyRJkiRJ0qrjjsVVJMnT6Nz++1Xgw8DzgbuBTVuXzYB7gaVJngr87TimvYx2e3CSvwWe0NqnAn9ooeI2wAtGGP8TYN/2rMb1gcPGseZhSdZLshWdHYS3Dqnj2XRuyR5v+3Z0bv0e6kfAoUme0vo9MckzxlGfJEmSJEmSVgF3LK462wOnJnkE+BOd5wzuBvxbkjurar8kNwA30bnF+MpxzPle4Bvt9ulLgf/X2n8AHJNkIZ0g75rhBlfVnUlOAq4G7gSuB8Z6Qcqtba2nAsdU1QNJPk3neYuLgIeBI6rqwVHaPwN8sdW3ALh2mNpuTvKPwIVJ1qPznb2Jzu3UkiRJkiRJ6rNU9XonrP5/9u48XK+qvvv/+2NCgwwGB+oTaSEOAcoY4IAyKSqlrXGogkWlCmpFLXV8UGlRxKmNxSriHC2CikgZ9EFoBURmBHICIQko+jwQfxat1qqRQVDC9/fHvY7cHs50JyfnTk7er+s619n32muv9d375I9cn2utfW+s2vbsC6rqnH7XMpqBgYEaHBzsdxmSJEmSJEnTRpIl7QuHf49boSVJkiRJkiT1zK3Qepgkx/Pw9y2eXVVH9aEcSZIkSZIkrYcMFvUwVfUB4AP9rkOSJEmSJEnrL7dCS5IkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKkns3sdwHSZFp+5yrmHndhv8uQJEnSNLNy4YJ+lyBJ0nrHFYuSJEmSJEmSemawKEmSJEmSJKlnG12wmOTNSTabQL8Dk9ySZGmSRyY5qX0+aS3mvntNzid5XZJXrOm8XeNcnmSgx2vubr/nJlnRjucnec4k1POEJOes7TiSJEmSJEmaehvjOxbfDHwJuHecfkcAH6qqzwMkeS2wdVXdP5FJksysqgfWptAhVfXpdT1Hj+YDA8C/T/SC4bW2zz8CDuthjBlVtbqXQiVJkiRJkrRuTOsVi0k2T3JhkpuTrEjybuAJwGVJLmt9PpVksK1GfE9r+xvgr4ATkpyR5Hxgc+D6JIcn2S7JpUmWtd/btutOS/LhNvYHkzwxybeTLE7yvq665iS5sq2GXJHkwK5zH2j1Xpfk8a3txCTHtuPLk/xjkiuANyXZK8kVSZYkuSjJnHEey18nubbNu8/w8dvnFUnmjvJM/wB4L3B4q//w9pxPbfd5U5IXtL5HJTk7ydeBi0f43L0KckZbFbq4PdfXtvaDklyW5MvA8lFqOrr9DQdX37tqnNuXJEmSJEnSZJjuKxb/HPhRVS0ASDIbeCXwzKr6WetzfFX9PMkM4NIku1XV55IcAFxQVee0a++uqvnt+OvAF6rq9CSvAk4B/rKNtz1wcFWtboHkp6rqC0mO6arrZcBFVfWBNu/Q1uzNgeuq6vgk/wy8Bnj/CPe1VVU9I8kmwBXAC6rqv5McDnwAeNUYz2TzqtovydOBU4FdJvAcf6eqfpPkBGCgqv6uPY9/BL5VVa9KshVwQ5Jvtkv2BXZrz/ioYZ/ndg39amBVVe2dZBZwTZKL27l9gF2q6o5RaloELAKYNWde9XI/kiRJkiRJWjPTesUinRVuByf5YJIDq2qk5Wx/leRG4CZgZ2CnCYy7L/DldvxF4ICuc2d3bdfdHzizq9+QxcArk5wI7FpVd7X23wAXtOMlwNxR5j+r/d6BTjB4SZKlwDuBPxqn9jMBqupK4FEtCFxbhwDHtRouBzYFtm3nLqmqn3f1Hf65e4xXtDGuBx4LzGvnbhgtVJQkSZIkSVJ/TOsVi1X1vSR7Ac8B/qlrBRwASZ4IHAvsXVW/SHIanVCs56m6ju8Z49xQXVe2FYMLgC8mOamqvgD8tqqG+q9m9L/P0BwBbqmqfdew1qHPD/D7IXOvzyDAoVV12+81Jk/l4c9j+OfuMd5QVRcNG+OgMa6RJEmSJElSn0zrFYtJngDcW1VfAj4E7AncBWzZujyKTmi1qr3P8C8mOPS1wEva8RHA1aP0u2ZYv6G6tgN+WlWfBf611bUmbgO2TrJvG3eTJDuPc83hre8BdLYerwJWDtWQZE/gieOM0f0MAS4C3pAkbYw9eryPoTFe37Z3k2T7JJuvwTiSJEmSJEmaAtN6xSKwK3BSkgeB3wKvp7ON+T+S/LiqnpnkJuAW4HY6QeBEvBE4NcnbgP+m897GkbwJ+HKSNwHndrUfBLwtyW+Bu4FX9HZbHe19h4cBp7T3R84ETqZzP6P5RZJr6YSqQ+9iPJeHtiEvBr43ztSX8dDW538C3tfmXdbCxZXAc3u8nc/R2fp9Yxvjv3novZWSJEmSJElaz+ShnbfShm9gYKAGBwf7XYYkSZIkSdK0kWRJVQ0Mb5/WW6ElSZIkSZIkrRvTfSv0RinJJ+h8I3W3j1bV5/tRjyRJkiRJkqYfg8VpqKqO6XcNkiRJkiRJmt7cCi1JkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZzP7XYA0mZbfuYq5x13Y7zIkSZI0zaxcuKDfJUiStN5xxaIkSZIkSZKknhksSpIkSZIkSeqZweJGIMlWSf52Esebn+Q5kzDOE5KcMxk1SZIkSZIkaWoZLG4ctgImLVgE5gM9BYtJZg7/XFU/qqrDehhjRi9zSpIkSZIkad0xWNw4LASenGRpkpPaz4oky5McDpDki0leMHRBkjOSPH/4QEn+AHgvcHgb7/Akmyc5NcniJDcNjZPkqCRnJ/k6cPEIn+cmWdH6zmh1LU6yLMlrW/tBSS5L8mVg+bp+UJIkSZIkSZoYvxV643AcsEtVzU9yKPA6YHfgccDiJFcCnwPeAvyfJLOB/YAjhw9UVb9JcgIwUFV/B5DkH4FvVdWrkmwF3JDkm+2SfYHdqurnSY4a9nlu19CvBlZV1d5JZgHXJLm4ndun1X/HSDeX5GjgaIAZj9p6TZ6PJEmSJEmSeuSKxY3PAcCZVbW6qn4CXAHsXVVXAE9J8ofAS4Fzq+qBCY55CHBckqXA5cCmwLbt3CVV9fOuvsM/d4/xijbG9cBjgXnt3A2jhYoAVbWoqgaqamDGZrMnWLIkSZIkSZLWhisWNz4Z49wXgSOAlwCv6nHMQ6vqtt9rTJ4K3DOs7/DP3WO8oaouGjbGQWNcI0mSJEmSpD5xxeLG4S5gy3Z8JZ33I85IsjXwdOCGdu404M0AVXXLBMcDuAh4Q5IAJNljDWq8CHh9kk3aGNsn2XwNxpEkSZIkSdIUMFjcCFTV/9B5Z+EKOu84XAbcDHwLeHtV/Vfr9xPgO8DnxxnyMmCnoS9vAd4HbAIsa3O8bw3K/BxwK3BjG+MzuKJWkiRJkiRpvZWq6ncNWk8k2YzONy/vWVWr+l3Pmpg1Z17NOfLkfpchSZKkaWblwgX9LkGSpL5JsqSqBoa3uyJMACQ5GDgV+PCGGioC7LrNbAb9T58kSZIkSdI6Z7AoAKrqmzz0Tc4AJPkz4IPDut5RVS+cssIkSZIkSZK0XjJY1KjaNzRfNG5HSZIkSZIkbXT88hZJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktSzmf0uQJpMy+9cxdzjLux3GZIkSZpmVi5c0O8SJEla77hiUZIkSZIkSVLPDBYlSZIkSZIk9cxgcQxJLk8ysKbnJ7mW9yY5eCrmmmpJPpdkp3H6TNmzliRJkiRJ0vh8x+IGIMmMqjphiuZZva7nGa6q/maq55QkSZIkSdLa2ShWLCZ5e5I3tuOPJPlWO352ki8lOSTJt5PcmOTsJFsMu35GktOSrEiyPMlbuk6/OMkNSb6X5MAxati59VuaZFmSeUnmJvluktNb2zlJNmv9VyY5IcnVbY7TkhzWde49rd7lSXZs7VsnuaS1fybJD5I8rp376675P5NkRmu/u62GvB7Yd5TaFya5tdX4odZ2WpJPJ7mq3ftzW/vc1nZj+9mvtR/UVh2e0+75jCRp5363GnG8v4UkSZIkSZLWDxtFsAhcCQyFfgPAFkk2AQ4AlgPvBA6uqj2BQeCtw66fD2xTVbtU1a7A57vOzayqfYA3A+8eo4bXAR+tqvmthv9s7TsAi6pqN+BXwN92XXNfVR1QVV8ZYbyftXo/BRzb2t4NfKu1fxXYFiDJnwCHA/u3+VcDR7RrNgdWVNVTq+rq4ZMkeQzwQmDnVuP7u07PBZ4BLAA+nWRT4KfAn7YaDgdO6eq/B53ntBPwJGD/YXM9jvH/Fg+T5Ogkg0kGV9+7arzukiRJkiRJmgQbS7C4BNgryZbA/cC36YR7BwK/phN0XZNkKXAksN2w628HnpTkY0n+nE4AOOS8rjnmjlHDt4F/SPIOYLuq+nVr/2FVXdOOv0Qn7Bxy1hjjjTTvAcBXAKrqG8AvWvuzgb2Axe0en00n2INOyHjuGPP8CrgP+FySFwH3dp37t6p6sKq+T+cZ7QhsAnw2yXLgbDrPdsgNVfWfVfUgsJSHP6+nMf7f4mGqalFVDVTVwIzNZo/XXZIkSZIkSZNgo3jHYlX9NslK4JXAtcAy4JnAk4E7gEuq6qVjXP+LJLsDfwYcA/wV8Kp2+v72ezVjPM+q+nLbbrwAuCjJ39AJ42p4167je8a4rZHmzSh9A5xeVX8/wrn7xnqvYlU9kGQfOmHkS4C/A541Qq1Dn98C/ATYnU5wfd8INQ+vu7vOMf8WkiRJkiRJWj9sLCsWobMd+tj2+yo6W5OXAtcB+yd5CkCSzZJs331h26L7iKo6F3gXsGevkyd5EnB7VZ0CnA/s1k5tm2To3YYvBR62HbkHV9MJPUlyCPDo1n4pcFiSP2znHpNk3JWAre8WwOyq+nc625jnd51+cZJHJHkynRWQtwGzgR+3VYkvB2b0UP+4fwtJkiRJkiStHzamYPEqYA7w7ar6CZ2VdFdV1X8DRwFnJllGJ9zacdi12wCXt+25pwEjrfwbz+HAijbGjsAXWvt3gCPb3I+h887ENfUe4JAkNwJ/AfwYuKuqbqXz7sKL2zyX0HkWE7ElcEG77go6KxKH3Nba/gN4XVXdB3yy3c91wPaMvery90zwbyFJkiRJkqT1QKqG72bVVEkyF7igqnaZpPFmAavb9uV9gU+1L2uZdElOo1P7Oeti/DU1MDBQg4OD/S5DkiRJkiRp2kiypKoGhrdvFO9Y3IhsC/xbkkcAvwFe0+d6JEmSJEmSNE0ZLE6yJH8GfHBY8x1V9cLhfatqJTApqxXbeN8H9ljT65N8FXjisOZ3VNVFI8x11JrOI0mSJEmSpA2fweIkayHcw4K4DcFI4ackSZIkSZI0ko3py1skSZIkSZIkTRKDRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9m9nvAqTJtPzOVcw97sJ+lyFJkqRpZuXCBf0uQZKk9Y4rFiVJkiRJkiT1zGCxz5I8P8lx4/R5QpJzxukzN8nLJre6qdFqX9GOD0pyQb9rkiRJkiRJ0tgMFvusqs6vqoXj9PlRVR02zlBzgZ6DxSQzer1GkiRJkiRJMlhch9pKvO8m+VySFUnOSHJwkmuSfD/JPkmOSvLx1v+0JKckuTbJ7UkO6xpnRdfxVUlubD/7tekWAgcmWZrkLd3jtusuSHJQO747yXuTXA/sm+Svk9zQrv3MWGFju/Zf2tyXJtm6tc9Pcl2SZUm+muTR47TvleTmJN8Gjhllrs2TnJpkcZKbkrxgbf4ekiRJkiRJmjwGi+veU4CPArsBO9JZVXgAcCzwDyP0n9POP5dOWDjcT4E/rao9gcOBU1r7ccBVVTW/qj4yTk2bAyuq6qnA/7Rx9q+q+cBq4Ihxrr2xzX8F8O7W/gXgHVW1G7B8Au2fB95YVfuOMdfxwLeqam/gmcBJSTYf3inJ0UkGkwyuvnfVOLcuSZIkSZKkyeC3Qq97d1TVcoAktwCXVlUlWU5n+/JwX6uqB4Fbkzx+hPObAB9PMp9OCLj9GtS0Gji3HT8b2AtYnATgkXTCy9E8CJzVjr8EnJdkNrBVVV3R2k8Hzu6h/YvAX4ww1yHA85Mc2z5vCmwLfKe7U1UtAhYBzJozr8a6cUmSJEmSJE0Og8V17/6u4we7Pj/IyM+/u39GOP8W4CfA7nRWnN43yrwP8PsrUjftOr6vqlZ3zXF6Vf39KOOMZ02CvEzwugCHVtVtazCHJEmSJEmS1iG3Qm94ZgM/bqsaXw4MvQ/xLmDLrn4rgflJHpHkj4F9RhnvUuCwJH8IkOQxSbYbY/5HAENfJPMy4OqqWgX8IsmBrf3lwBVjtP8SWJXkgNY+2tbri4A3pC2lTLLHGHVJkiRJkiRpCrliccPzSeDcJC8GLgPuae3LgAeS3AycBpwM3EHnvYYrgBtHGqyqbk3yTuDiJI8Afkvny1R+MMr89wA7J1kCrKLzfkaAI4FPJ9kMuB145TjtrwROTXIvnQBxJO9r97GshYsr6bx7UpIkSZIkSX2WKl9Jp4lLcndVbdHvOkYza868mnPkyf0uQ5IkSdPMyoUL+l2CJEl9k2RJVQ0Mb3fFoqaVXbeZzaD/6ZMkSZIkSVrnDBY1oiTXA7OGNb98fV6tKEmSJEmSpKljsKgRVdVT+12DJEmSJEmS1l9+K7QkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSerZzH4XIE2m5XeuYu5xF/a7DEmSJG1gVi5c0O8SJEna4LhiUZIkSZIkSVLPDBYlSZIkSZIk9cxgUX2X5NoJ9Ll7KmqRJEmSJEnSxBgsqu+qar9+1yBJkiRJkqTeGCyuJ5JsnuTCJDcnWZHk8CQrkzyunR9Icnk7fkaSpe3npiRbJpmT5MrWtiLJga3vIUm+neTGJGcn2SLJdkm+n+RxSR6R5Kokh0y0rta+MskHk9zQfp7S2p+X5PpW1zeTPL61n5jk1CSXJ7k9yRu75ri76/htSRYnWZbkPevocUuSJEmSJGktGSyuP/4c+FFV7V5VuwDfGKPvscAxVTUfOBD4NfAy4KLWtjuwtIWS7wQOrqo9gUHgrVX1A+CDwKeB/w3cWlUXr0Fdv6qqfYCPAye3tquBp1XVHsBXgLd39d8R+DNgH+DdSTbpnqiFm/Pa+fnAXkmePsZzGLru6CSDSQZX37tqvO6SJEmSJEmaBAaL64/lwMFtFeCBVTVWQnYN8OG26m+rqnoAWAy8MsmJwK5VdRfwNGAn4JokS4Ejge0AqupzwJbA6+gElWtS15ldv/dtx38EXJRkOfA2YOeu/hdW1f1V9TPgp8Djh811SPu5CbiRThA5b4zaaPeyqKoGqmpgxmazx+suSZIkSZKkSWCwuJ6oqu8Be9EJ8v4pyQnAAzz0N9q0q+9C4G+ARwLXJdmxqq4Eng7cCXwxySuAAJdU1fz2s1NVvRogyWZ0QkCALXqs63enRzj+GPDxqtoVeG133cD9XcergZnDpgvwT131PqWq/nW02iRJkiRJktQ/BovriSRPAO6tqi8BHwL2BFbSCfUADu3q++SqWl5VH6SzvXnHJNsBP62qzwL/2q6/Dti/6/2HmyXZvg3zQeAM4ATgsz3WNeTwrt/fbsez6YSb0Fkh2YuLgFcl2aLNvU2SP+xxDEmSJEmSJE2B4SvG1D+7AicleRD4LfB6OisS/zXJPwDXd/V9c5Jn0ln1dyvwH8BLgLcl+S1wN/CKqvrvJEcBZyaZ1a59Z5I5wN7A/lW1OsmhSV5ZVZ+fYF1DZiW5nk5A/dLWdiJwdpI76QSbT5zoA6iqi5P8CfDtJLT7+Gs626YlSZIkSZK0HklVjd9LGibJSmCgvS9xvTEwMFCDg4P9LkOSJEmSJGnaSLKkqgaGt7sVWpIkSZIkSVLP3AotAJI8Frh0hFPPrqr/Gd5YVXPXeVGSJEmSJElabxksCoAWHs7vdx2SJEmSJEnaMLgVWpIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9WxmvwuQJtPyO1cx97gL+12GJEmSNjArFy7odwmSJG1wXLEoSZIkSZIkqWcGi5pySU5Lclg7vjzJQL9rkiRJkiRJUm8MFrVBSTKj3zVIkiRJkiTJYHHaSfK1JEuS3JLk6NZ2d5J/SXJjkkuTbN3aL09ycpJrk6xIsk9r3zzJqUkWJ7kpyQta+1FJzkvyjSTfT/LPrf35SZa2n9uS3NHa90pyRavnoiRzxqn9kCTfbnWenWSL1r4yyQlJrgZevM4eniRJkiRJkibMYHH6eVVV7QUMAG9M8lhgc+DGqtoTuAJ4d1f/zatqP+BvgVNb2/HAt6pqb+CZwElJNm/n5gOHA7sChyf546o6v6rmV9V84GbgQ0k2AT4GHNbqORX4wGhFJ3kc8E7g4FbnIPDWri73VdUBVfWVEa49OslgksHV966a6HOSJEmSJEnSWvBboaefNyZ5YTv+Y2Ae8CBwVmv7EnBeV/8zAarqyiSPSrIVcAjw/CTHtj6bAtu240urahVAkluB7YAfts9vB35dVZ9IsguwC3BJEoAZwI/HqPtpwE7ANa3/HwDf7jp/1kgXtdoXAYsAZs2ZV2PMIUmSJEmSpElisDiNJDkIOBjYt6ruTXI5nVBwuBrleOhzgEOr6rZh4z8VuL+raTXt31CSZ9PZpvz0oe7ALVW170TLBy6pqpeOcv6eCY4jSZIkSZKkKeBW6OllNvCLFiruSGcVIHT+zoe145cBV3ddczhAkgOAVW014kXAG9KWDibZY6xJk2wHfBL4q6r6dWu+Ddg6yb6tzyZJdh5jmOuA/ZM8pfXfLMn2E7lpSZIkSZIkTT1XLE4v3wBel2QZnWDvutZ+D7BzkiXAKlqY2PwiybXAo4BXtbb3AScDy1q4uBJ47hjzHgU8FvhqyyJ/VFXPSXIYcEqS2XT+rZ0M3DLSAFX130mOAs5MMqs1vxP43kRuXJIkSZIkSVMrVb6SbrpLcndVbTFC++XAsVU1OPVVrRuz5syrOUee3O8yJEmStIFZuXBBv0uQJGm9lWRJVQ0Mb3fFoqaVXbeZzaD/KZQkSZIkSVrnDBY3AiOtVmztB01xKZIkSZIkSZom/PIWSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST2b2e8CpMm0/M5VzD3uwn6XIUmSpA3MyoUL+l2CJEkbHFcsSpIkSZIkSeqZwaIkSZIkSZKknhksbiSSPD/JcWOcn5tkRQ/jHZXkCZNQ1+uSvGJtx5EkSZIkSdLU8h2L00CSmVX1wFh9qup84PxJnPYoYAXwo4leMLzO9vnTvUw6kXuVJEmSJEnSumewuJ5IMhf4D+BqYD/gTuAFwA7Ap4HNgP8HvKqqfpHkcuBaYH/g/CTHAE8GZgM/Bw6qqiuTXAW8EjgAGKiqv0vy+Dbmk9r0r6cTEM5I8tnu+avq1yPUehgwAJyR5NfAvsBOwIeBLYCfAUdV1Y9HqPN5wz5vCdxdVR9K8mTgE8DWwL3Aa6rqu0lOa/e0B3Aj8L/X+EFLkiRJkiRpUrgVev0yD/hEVe0M/BI4FPgC8I6q2g1YDry7q/9WVfWMqvoX4Ht0wr0DgCXAgUlmAX9UVf932DynAFdU1e7AnsAtY8z/MFV1DjAIHFFV84EHgI8Bh1XVXsCpwAdGqXOkz0MWAW9oYxwLfLLr3PbAwVX1sFAxydFJBpMMrr531UglS5IkSZIkaZK5YnH9ckdVLW3HS+isQNyqqq5obacDZ3f1P6vr+Crg6cATgX8CXgNcASweYZ5nAa8AqKrVwKokjx5h/rkTrHsHYBfgkiQAM4Afj1LnSJ9JsgWdlZJntzEAZnV1ObvV+jBVtYhOKMmsOfNqgjVLkiRJkiRpLRgsrl/u7zpeDWw1Tv97uo6vAl4HPAE4AXgbcBBw5VrM/8gJXhfglqradwJ1jvQZOqtnf9lWQE5kDEmSJEmSJPWRW6HXb6uAXyQ5sH1+OZ1ViCO5ns6Kvwer6j5gKfBaOoHjcJfSea8iSWYkedQa1HYXsGU7vg3YOsm+bcxNkuzcy2BV9SvgjiQvbmMkye5rUJckSZIkSZKmgMHi+u9I4KQky4D5wHtH6lRV9wM/BK5rTVfRCf6Wj9D9TcAzkyyns+W5pxCwOQ34dJKldLY+HwZ8MMnNdELN/dZgzCOAV7cxbqHz5TWSJEmSJElaD6XKV9Jp+pg1Z17NOfLkfpchSZKkDczKhQv6XYIkSeutJEuqamB4u+9Y1LSy6zazGfQ/hZIkSZIkSeucwaLGlOQTwP7Dmj9aVZ/vRz2SJEmSJElaPxgsakxVdUy/a5AkSZIkSdL6xy9vkSRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPZvZ7wKkybT8zlXMPe7CfpchSZKkDczKhQv6XYIkSRscVyxKkiRJkiRJ6pnBoiRJkiRJkqSeGSyuoSTPT3LcOH2ekOSccfrMTfKyya1uzSU5KMkF/a5DkiRJkiRJ6zeDxTVUVedX1cJx+vyoqg4bZ6i5QM/BYpIZvV4zHSTxvaCSJEmSJEnrAYPFEbRVhN9N8rkkK5KckeTgJNck+X6SfZIcleTjrf9pSU5Jcm2S25Mc1jXOiq7jq5Lc2H72a9MtBA5MsjTJW7rHbdddkOSgdnx3kvcmuR7YN8lfJ7mhXfuZ0cLGJDNajSuSLE/yltb+lCTfTHJzq+nJ7ZItkpzTnsEZSdL6r0zyntZ3eZIdW/s+7d5var93aO0j3ktb7bm0/dyW5I52fq8kVyRZkuSiJHNa++VJ/jHJFcCb1voPLEmSJEmSpLVmsDi6pwAfBXYDdqSzqvAA4FjgH0boP6edfy6dsHC4nwJ/WlV7AocDp7T244Crqmp+VX1knJo2B1ZU1VOB/2nj7F9V84HVwBGjXDcf2KaqdqmqXYHPt/YzgE9U1e7AfsCPW/sewJuBnYAnAft3jfWzdg+fovMsAL4LPL2q9gBOAP5xrJtoqz3nt7pvBj6UZBPgY8BhVbUXcCrwga7LtqqqZ1TVvwwfL8nRSQaTDK6+d9VYU0uSJEmSJGmSuK10dHdU1XKAJLcAl1ZVJVlOZ/vycF+rqgeBW5M8foTzmwAfTzKfTgi4/RrUtBo4tx0/G9gLWNwWFD6STng5ktuBJyX5GHAhcHGSLemEjV8FqKr7ANpYN1TVf7bPS+nc79VtrPPa7yXAi9rxbOD0JPOAavc6riRvB35dVZ9IsguwC3BJq2EGDwWdAGeNNk5VLQIWAcyaM68mMrckSZIkSZLWjsHi6O7vOn6w6/ODjPzcuvtnhPNvAX4C7E5npeh9o8z7AL+/knTTruP7qmp11xynV9XfjzLO71TVL5LsDvwZcAzwV3RWJI6m+15W8/v3e/8I7e8DLquqFyaZC1w+3r0keTbwYuDpXfdzS1XtO0pN94xRryRJkiRJkqaYW6Gnzmzgx21V48vprMgDuAvYsqvfSmB+kkck+WNgn1HGuxQ4LMkfAiR5TJLtRuqY5HHAI6rqXOBdwJ5V9SvgP5P8ZeszK8lma3Fvd7bjo8a7l1bnJ4G/qqpft763AVsn2bf12STJzmtYjyRJkiRJktYxVyxOnU8C5yZ5MXAZD63AWwY8kORm4DTgZOAOYDmwArhxpMGq6tYk76SzrfkRwG/prEb8wQjdtwE+3/oBDK1yfDnwmSTvbde/eA3v7Z/pbIV+K/CtrvZrRrmXo4DHAl9t255/VFXPaV96c0qS2XT+bZ4M3LKGNUmSJEmSJGkdSpWvpNP0MTAwUIODg/0uQ5IkSZIkadpIsqSqBoa3uxVakiRJkiRJUs/cCj3NJLkemDWs+eVD33AtSZIkSZIkTQaDxWmmqp7a7xokSZIkSZI0/bkVWpIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9WxmvwuQJtPyO1cx97gL+12GJEmSNjArFy7odwmSJG1wXLEoSZIkSZIkqWcGi5IkSZIkSZJ6ZrC4hpJcuybn2vm7J7+ih80xP8lz1vU8kyHJE5KcM06fuUlWTFVNkiRJkiRJGpvB4hqqqv2GtyWZMdq5PpgP9BQsJunLOzer6kdVdVg/5pYkSZIkSdKaMVhcQ0OrDpMclOSyJF8Glg87NyfJlUmWJlmR5MCu6z+Q5OYk1yV5/ChzzEhyezq2SvJgkqe3c1cleUqSfZJcm+Sm9nuHJH8AvBc4vM19eJLNk5yaZHHr+4I2zlFJzk7ydeDiUeoY8T6S3J3kX5LcmOTSJFu39te0eW5Ocm6SzVr7aUlOaXXenuSw1v671Yjtnk9q1y9L8toJ/C2OTjKYZHD1vavG/+NJkiRJkiRprRksTo59gOOraqdh7S8DLqqq+cDuwNLWvjlwXVXtDlwJvGakQatqNfA9YCfgAGAJcGCSWcAfVdX/Bb4LPL2q9gBOAP6xqn7Tjs+qqvlVdRZwPPCtqtobeCZwUpLN21T7AkdW1bNGub+x7uPGqtoTuAJ4d2s/r6r2bvf3HeDVXWPNaffyXGDhCHO9GljV6twbeE2SJ45S19BzWlRVA1U1MGOz2WN1lSRJkiRJ0iTpy9bXaeiGqrpjhPbFwKlJNgG+VlVLW/tvgAva8RLgT8cY+yrg6cATgX+iE0Je0cYGmA2cnmQeUMAmo4xzCPD8JMe2z5sC27bjS6rq52PUMNp9PAic1Y6/BJzXjndJ8n5gK2AL4KKusb5WVQ8Ct46yUvMQYLeh1Yzt/ubRCVglSZIkSZK0nnDF4uS4Z6TGqrqSTih4J/DFJK9op35bVdWOVzN2wHsVcCCdVZH/TiesO4jOSkeA9wGXVdUuwPPoBIYjCXBoW8E4v6q2rarvjFX/BO7jYV3b79OAv6uqXYH3DKvp/mE1jVTnG7rqfGJVjbhFW5IkSZIkSf1jsLgOJdkO+GlVfRb4V2DPNRjmemA/4MGquo/ONuTX0gkcobOi7852fFTXdXcBW3Z9vgh4Q5K02vaYaAFj3McjgKGVhS8Drm7HWwI/biscj5joPF11vr5dS5Ltu7ZsS5IkSZIkaT1hsLhuHQQsTXITcCjw0V4HqKr7gR8C17Wmq+gEd8vb538G/inJNcCMrksvA3Ya+vIWOisbNwGWtS9Ked8k3Mc9wM5JlgDPovOFMQDvohOIXkLnHZC9+BxwK3Bjq/MzuGVfkiRJkiRpvZOHduRKvUlyd1Vt0e86ug0MDNTg4GC/y5AkSZIkSZo2kiypqoHh7a5YlCRJkiRJktQzt5iuJ5IcD7x4WPPZVfWBKaxhV+CLw5rvr6qnjtR/fVutKEmSJEmSpKljsLieaAHilIWIo9SwHJjfzxokSZIkSZK0YXArtCRJkiRJkqSeGSxKkiRJkiRJ6pnBoiRJkiRJkqSeGSxKkiRJkiRJ6pnBoiRJkiRJkqSeGSxKkiRJkiRJ6pnBoiRJkiRJkqSezex3AdJkWn7nKuYed2G/y5AkSdJ6ZOXCBf0uQZKkackVi5IkSZIkSZJ6ZrAoSZIkSZIkqWcbXLCYZG6SFSO0X55kYA3GOyrJxyenujHnWZnkcSO0H5Rkv3U9/2RqNV8wxXOemOTYqZxTkiRJkiRJo9vggsVp6CBggwoWJUmSJEmSpA01WJyZ5PQky5Kck2Sz7pNJPpVkMMktSd7T1b53kmuT3JzkhiRbDrtuQZJvj7KycLQxVyZ5T5IbkyxPsmNrf2ySi5PclOQzQEYYcy7wOuAtSZYmOTDJ85Jc3677ZpLHt74nJjm1rcy8Pckbx3pASV7Rns/NSb7Y2rZLcmlrvzTJtuO0n5bklPbMbk9yWNcUW7Rn/90kZyRJu+bZrfblrd5ZXc/pce14IMnl491XkuOT3Jbkm8AOY92vJEmSJEmSptaGGizuACyqqt2AXwF/O+z88VU1AOwGPCPJbkn+ADgLeFNV7Q4cDPx66IIkLwSOA55TVT8bYc6Hjdl17mdVtSfwKWBou+67gaurag/gfGDb4QNW1Urg08BHqmp+VV0FXA08rV33FeDtXZfsCPwZsA/w7iSbjPRwkuwMHA88q93rm9qpjwNfaM/tDOCUcdoB5gAHAM8FFna17wG8GdgJeBKwf5JNgdOAw6tqVzrfOv76kWoc5mH3lWQv4CVtnhcBe492cZKjW+g7uPreVROYTpIkSZIkSWtrQw0Wf1hV17TjL9EJvrr9VZIbgZuAnemEXzsAP66qxQBV9auqeqD1fybwDmBBVf1ilDlHGnPIee33EmBuO356q42quhAYbdzh/gi4KMly4G1triEXVtX9Lfj8KfD4UcZ4FnDOUEBaVT9v7fsCX27HX+Sh5zZaO8DXqurBqrp12Hw3VNV/VtWDwFI6970DcEdVfa/1OZ3OcxjPSPd1IPDVqrq3qn5FJ5wdUVUtqqqBqhqYsdnsCUwnSZIkSZKktbWhBos12uckT6SzavDZbQXehcCmdLYiD79uyO3AlsD2bYwZbWvy0iTvHWPMIfe336vprNIbrU6SHNM19hNGqOVjwMfbir/XjjLPSHP93jRj3Gu30fp0t3fPmVHah2p52HbvLg/w0L+3TYedG+2+JnIPkiRJkiRJ6oMNNVjcNsm+7fildLYPD3kUcA+wqr2f8C9a+3eBJyTZGyDJlkmGAqwf0Nlu+4UkO1fV6rY1eX5VnTDGmGO5EjiizfUXwKMBquoTXWP/CLiLTqg5ZDZwZzs+ckJP4+EupbPC8rFt/se09mvpbC+m1Xb1OO29+i4wN8lT2ueXA1e045XAXu340AmMdSXwwiSPbO/CfN4a1iRJkiRJkqR1YEMNFr8DHJlkGfAYOu82BKCqbqazXfkW4FTgmtb+G+Bw4GNJbgYuoWvlXFXdRidUOzvJk7snG23McbwHeHrbPn0I8P+N0u/rdAK0pUkOBE5sNVwFjPSux3FV1S3AB4Ar2r1+uJ16I/DK9txezkPvXhytvdd57wNe2epfDjxI5x2S0HkeH233tXoCY91I552YS4FzgavWpCZJkiRJkiStG6lyt6mmj1lz5tWcI0/udxmSJElaj6xcuKDfJUiStEFLsqR9qfHvGe0dfdIGaddtZjPofxwlSZIkSZLWOYPFDVh7h+KlI5x6dlX9z1TXI0mSJEmSpI2HweIGrIWH8/tdhyRJkiRJkjY+G+qXt0iSJEmSJEnqI4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST2b2e8CpMm0/M5VzD3uwn6XIUmSpCm0cuGCfpcgSdJGyRWLkiRJkiRJknpmsKhJl+TEJMcmuTzJQA/XHZTkgnVZmyRJkiRJkiaHwaIkSZIkSZKknhksalIkOT7JbUm+CezQderFSW5I8r0kB7a+myb5fJLlSW5K8swRxts8yalJFrc+L5iqe5EkSZIkSdL4/PIWrbUkewEvAfag82/qRmBJOz2zqvZJ8hzg3cDBwDEAVbVrkh2Bi5NsP2zY44FvVdWrkmwF3JDkm1V1z7q/I0mSJEmSJI3HFYuaDAcCX62qe6vqV8D5XefOa7+XAHPb8QHAFwGq6rvAD4DhweIhwHFJlgKXA5sC2440eZKjkwwmGVx976q1vhlJkiRJkiSNzxWLmiw1Svv97fdqHvr3lgmMF+DQqrpt3ImrFgGLAGbNmTdaHZIkSZIkSZpErljUZLgSeGGSRybZEnjeBPofAdC2QG8LDA8QLwLekCSt3x6TW7IkSZIkSZLWhsGi1lpV3QicBSwFzgWuGueSTwIzkixv1x1VVfcP6/M+YBNgWZIV7bMkSZIkSZLWE6ly56imj1lz5tWcI0/udxmSJEmaQisXLuh3CZIkTWtJllTVwPB237GoaWXXbWYz6H8sJUmSJEmS1jm3QkuSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnq2cx+FyBNpuV3rmLucRf2uwxJkiRNoZULF/S7BEmSNkquWJQkSZIkSZLUM4NFTaokK5M8rh1f2+96JEmSJEmStG4YLGqNJRlzK31V7TdVtUiSJEmSJGlq+Y5FAZDkFcCxQAHLgH8D3gn8AfA/wBFV9ZMkJwJPAOYCP0vyBuBMYGvgBiBdY95dVVskeQTwceAZwB10Au1Tq+qcJCcAzwMeCVwLvLaqKsnlwPXAM4GtgFdX1VXr8hlIkiRJkiRp4lyxKJLsDBwPPKuqdgfeBFwNPK2q9gC+Ary965K9gBdU1cuAdwNXt37nA9uOMMWL6ASRuwJ/A+zbde7jVbV3Ve1CJ1x8bte5mVW1D/DmNs9o9R+dZDDJ4Op7V038xiVJkiRJkrTGXLEogGcB51TVzwCq6udJdgXOSjKHzqrFO7r6n19Vv27HT6cTHFJVFyb5xQjjHwCcXVUPAv+V5LKuc89M8nZgM+AxwC3A19u589rvJXSCyRFV1SJgEcCsOfNqYrcsSZIkSZKkteGKRUFn+/LwQO5jdFYT7gq8Fti069w9w/qOF+ZlxMZkU+CTwGFtns8Om+f+9ns1huCSJEmSJEnrFYNFAVwK/FWSxwIkeQwwG7iznT9yjGuvBI5o1/0F8OgR+lwNHJrkEUkeDxzU2odCxJ8l2QI4bG1uQpIkSZIkSVPHVWCiqm5J8gHgiiSrgZuAE4Gzk9wJXAc8cZTL3wOcmeRG4Arg/xuhz7nAs4EVwPfofCnLqqr6ZZLPAsuBlcDiSbspSZIkSZIkrVOp8pV0WveSbFFVd7dVkTcA+1fVf032PLPmzKs5R5482cNKkiRpPbZy4YJ+lyBJ0rSWZElVDQxvd8WipsoFSbai80Uw71sXoSLArtvMZtD/WEqSJEmSJK1zBouaElV1UL9rkCRJkiRJ0uTxy1skSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9WxmvwuQJtPyO1cx97gL+12GJEmSptDKhQv6XYIkSRslVyxKkiRJkiRJ6pnBoiRJkiRJkqSeGSxOgiQrkzyuh/7zkzyn6/NRST4+SbWcmOTYdX3N2kpy91TOJ0mSJEmSpMllsNgf84HnjNdJkiRJkiRJWl8ZLPYoyeZJLkxyc5IVSQ5vp96Q5MYky5Ps2NX31CSLk9yU5AVJ/gB4L3B4kqVd1w+N/7wk17f+30zy+NZ+Yhvr8iS3J3lj1zXHJ7ktyTeBHcap/41Jbk2yLMlXuk7tNMrYf53khlbrZ5LMaO2HJPl2u+ezk2zR2lcm+WC75oYkT2ntT2z9Fyd5X9f4SXJSe5bLh55Hkkck+WSSW5JckOTfkxzW459LkiRJkiRJ64jBYu/+HPhRVe1eVbsA32jtP6uqPYFPAUPbio8HvlVVewPPBE4CNgFOAM6qqvlVddaw8a8GnlZVewBfAd7edW5H4M+AfYB3J9kkyV7AS4A9gBcBe49T/3HAHlW1G/C6ccb+E+BwYP+qmg+sBo5o277fCRzc7nkQeGvXWL+qqn2AjwMnt7aPAp9qz+K/uvq+iM4Kzt2Bg4GTksxp7XOBXYG/AfYd7YaSHJ1kMMng6ntXjXP7kiRJkiRJmgwz+13ABmg58KEkHwQuqKqrkgCc184voROKARwCPL/r/YWbAtuOM/4fAWe1cO0PgDu6zl1YVfcD9yf5KfB44EDgq1V1L0CS88cZfxlwRpKvAV8bZ+xnA3sBi9s9PhL4KfA0YCfgmtb+B8C3u8Y6s+v3R9rx/sCh7fiLwAfb8QHAmVW1GvhJkivohKMHAGdX1YPAfyW5bLQbqqpFwCKAWXPm1Tj3L0mSJEmSpElgsNijqvpeWyX4HOCfklzcTt3ffq/moeca4NCquq17jCRPHWOKjwEfrqrzkxwEnNh17v6u4+55egnTFgBPB54PvCvJzmOMHeD0qvr7YfU/D7ikql46yhw1gePfDTfKGKO1S5IkSZIkaT3gVugeJXkCcG9VfQn4ELDnGN0vovPuxbRr92jtdwFbjnLNbODOdnzkBEq6Enhhkkcm2RJ43hi1PwL446q6jM4W662ALcYY+1LgsCR/2K5/TJLtgOuA/bven7hZku27rju86/fQSsZr6GzZBjhiWP2HJ5mRZGs6oecNdLaEH9retfh44KAx6pQkSZIkSdIUc8Vi73al8x7AB4HfAq8Hzhml7/vovGNwWQsXVwLPBS4DjkuyFPinYdecCJyd5E46Ad4Txyqmqm5MchawFPgBcNUY3WcAX0oym86KwI9U1S9b7jnS2LcmeSdwcQslfwscU1XXJTkKODPJrNb9ncD32vGsJNfTCa6HVjW+CfhykjcB53ZN81U670+8mc6KxrdX1X8lOZfOVuwVbdzrAV+gKEmSJEmStJ5Ila+k0+RJshIYqKqfTcJYW1TV3UkeS2cV4/5V9V9jXTNrzryac+TJazu1JEmSNiArFy7odwmSJE1rSZZU1cDwdlcsan12QZKt6Hw5zPvGCxUBdt1mNoP+x1KSJEmSJGmdM1icppJ8gs43MXf7aFV9fl3OW1VzJ3GsgyZrLEmSJEmSJE0ug8VpqqqO6XcNkiRJkiRJmr78VmhJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktSzmf0uQJpMy+9cxdzjLux3GZIkSZpCKxcu6HcJkiRtlFyxKEmSJEmSJKlnBosaVZK5SV7W9Xl+kudMwrhPSHJOOz4oyQVrO6YkSZIkSZKmlsGiSMdI/xbmAi/r+jwfWOtgsap+VFWHrcm1Sdy+L0mSJEmStB4wWNxItdWI30nySeBG4F+TrEiyPMnhrdtC4MAkS5O8A3gvcHj7fHjru1ULJv8nySva2F9McnCSGUlOSrI4ybIkr+2ae8UINW2e5NTW/6YkL2jtRyU5O8nXgYun4PFIkiRJkiRpHK7+2rjtALwSuBR4HbA78DhgcZIrgeOAY6vquQBJfgIMVNXftc/PBPYHfgDcDhwIfAF4GvB64NXAqqraO8ks4JokFwM1Sj3HA9+qqlcl2Qq4Ick327l9gd2q6ueT+QAkSZIkSZK0ZlyxuHH7QVVdBxwAnFlVq6vqJ8AVwN4TuP4q4Ont51PArkm2AX5eVXcDhwCvSLIUuB54LDBvjPEOAY5r/S8HNgW2becuGS1UTHJ0ksEkg6vvXTWBsiVJkiRJkrS2XLG4cbun/c4aXn8lcAyd8O944IXAYXQCx6Fx31BVF3VflGTuKOMFOLSqbhvW/6ldtT5MVS0CFgHMmjNvtNWQkiRJkiRJmkSuWBR0AsLD2zsRt6azAvEG4C5gy65+v/e5qn5IZ+v0vKq6HbgaOJaHgsWLgNcn2QQgyfZJNh+jjouANyRJ67/HZNycJEmSJEmSJp/BogC+CiwDbga+Bby9qv6rtT2Q5OYkbwEuA3Ya+vKWdu31wPfa8VXANnQCRoDPAbcCN7Yva/kMY6+SfR+wCbCs9X/fZN2gJEmSJEmSJleq3Dmq6WPWnHk158iT+12GJEmSptDKhQv6XYIkSdNakiVVNTC83XcsalrZdZvZDPofS0mSJEmSpHXOrdCSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSejaz3wVIk2n5nauYe9yF/S5DkiRJk2TlwgX9LkGSJI3CFYuSJEmSJEmSemawKEmSJEmSJKlnBouasCR/mWSnHvrPTbJiXdYkSZIkSZKk/jBY3EglWZP3a/4lMOFgUZIkSZIkSdOXweI0leRdSb6b5JIkZyY5NsnlSf4xyRXAm5LsleSKJEuSXJRkTrv2NUkWJ7k5yblJNkuyH/B84KQkS5M8eZR592rXfRs4pqt9bpKrktzYfvZr7Qe1us5p9Z6RJF1jPay+EeY8OslgksHV966a3AcpSZIkSZKkERksTkNJBoBDgT2AFwEDXae3qqpnAKcAHwMOq6q9gFOBD7Q+51XV3lW1O/Ad4NVVdS1wPvC2qppfVf9vlOk/D7yxqvYd1v5T4E+rak/g8Db/kD2AN9NZDfkkYP8km4xR3++pqkVVNVBVAzM2mz3ms5EkSZIkSdLkWJPtsFr/HQD8n6r6NUCSr3edO6v93gHYBbikLRCcAfy4ndslyfuBrYAtgIsmMmmS2XSCyyta0xeBv2jHmwAfTzIfWA1s33XpDVX1n22MpcBc4Jdj1CdJkiRJkqQ+M1icnjLGuXu6+twywspCgNOAv6yqm5McBRzUw7w1yrm3AD8BdqezUva+rnP3dx2vpvPvcqz6JEmSJEmS1GduhZ6ergael2TTJFsAC0bocxuwdZJ9AZJskmTndm5L4MdtO/IRXdfc1c6NqKp+CaxKckBr6r52NvDjqnoQeDmdFYhjGas+SZIkSZIk9ZnB4jRUVYvpvA/xZuA8YBBYNazPb4DDgA8muRlYCuzXTr8LuB64BPhu12VfAd6W5KbRvrwFeCXwifblLb/uav8kcGSS6+hsg75npIsnWJ8kSZIkSZL6LFWj7VzVhizJFlV1d5LNgCuBo6vqxn7Xta4NDAzU4OBgv8uQJEmSJEmaNpIsqaqB4e2+Y3H6WpRkJ2BT4PSNIVSUJEmSJEnS1DFYnKaq6mXrcvwknwD2H9b80ar6/LqcV5IkSZIkSesHg0Wtkao6pt81SJIkSZIkqX/88hZJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPZvZ7wKkybT8zlXMPe7CfpchSZKkSbJy4YJ+lyBJkkbhikVJkiRJkiRJPTNYlCRJkiRJktQzg8UeJTkoyQVrOcZRSZ4wWeMneW+Sg9einrW+p2HjPSHJORPo9w+TNackSZIkSZKm1gYVLCbZ4N8JmWQGcBQwYrC4JqrqhKr65ihzTbmq+lFVHTaBrj0Hi/26J0mSJEmSJP2+vgSLSd6V5LtJLklyZpJjkzw5yTeSLElyVZIdW9/Tknw4yWXAB9vnTyW5LMntSZ6R5NQk30lyWtccn0oymOSWJO/pal+Z5D1JbkyyfGieUep8RpKl7eemJFu2U1skOafdwxlJ0vo/u/Vb3mqa1TXnCUmuBl4KDABntHEfOcLUo41/QpLFSVYkWdTVflqSw0aY68VJDkny7Xa/ZyfZovX78zb+1cCLxvl7nZjki0m+leT7SV7T2pPkpFbP8iSHt/a5SVa046OSnNf+tt9P8s+tfSHwyPYMzmhtf53khtb2maEQMcndbVXm9cC+Y9UqSZIkSZKkqTHlwWKSAeBQYA86gdZAO7UIeENV7QUcC3yy67LtgYOr6n+3z48GngW8Bfg68BFgZ2DXJPNbn+OragDYDXhGkt26xvtZVe0JfKrNNZpjgWOqaj5wIPDr1r4H8GZgJ+BJwP5JNgVOAw6vql3pfOP267vGuq+qDqiqLwGDwBFVNb+qfs3DPWz81v7xqtq7qnYBHgk8d5S676uqA4BvAu+k8+z2bPO+tdX6WeB57b7+1xjPYMhuwAI6wd4JbSv3i4D5wO7AwcBJSeaMcO184HBgV+DwJH9cVccBv27P4Igkf9L67N+e92rgiHb95sCKqnpqVV09fPAkR7cQeXD1vasmcCuSJEmSJElaW/1YsXgA8H+q6tdVdRedYHBTYD/g7CRLgc8A3QHV2VW1uuvz16uqgOXAT6pqeVU9CNwCzG19/irJjcBNdELHnbquP6/9XtLVfyTXAB9O8kZgq6p6oLXfUFX/2eZc2sbYAbijqr7X+pwOPL1rrLPGmGe4kcYHeGaS65MspxOs7jzK9UNzPY3OfV/TnuuRwHbAjq3W77fn+KUJ1DT0N/sZcBmwD52/5ZlVtbqqfgJcAew9wrWXVtWqqroPuLXVMNyzgb2Axa3WZ9MJVaETMp47WmFVtaiqBqpqYMZmsydwK5IkSZIkSVpb/XhnYUZoewTwy7ZSbST3DPt8f/v9YNfx0OeZSZ5IZ7Xh3lX1i7ZFetMRrl/NGM+gqhYmuRB4DnBdHvqClO45h8YY6b7GugcAkjyVTpAKcALwq5HGb6sMPwkMVNUPk5w47J5GmivAJVX10mFzzgdqnHqHG96/GP+eh4z0vIYLcHpV/f0I5+4bFixLkiRJkiSpz/qxYvFq4HlJNm3v+1sA3AvckeTF8Lt39+2+FnM8ik64tirJ44G/WJNBkjy5rYb8IJ1txKO+jxH4LjA3yVPa55fTWcE3kruALQGq6vq2HXh+VZ0/xvhDIeLP2nObyJejXEdnm/ZT2v1slmT7VusTkzy59XvpaAN0eUH7mz0WOAhYDFxJZ2vzjCRb01mhecMExhry2ySbtONLgcOS/GGr9TFJRlrZKEmSJEmSpPXAlAeLVbUYOB+4mc6W5EFgFZ336b06yc10tjS/YC3muJnOFuhbgFPpbGleE29uX0xyM533K/7HGHPeB7ySznbu5XRWT356lO6nAZ8e48tbRhr/l3Tei7gc+BqdYG+8a/6bzjdQn5lkGZ2gccdW69HAhe3LW34wgRJuAC5sY7yvqn4EfBVYRudv+S3g7VX1XxO5n2YRsCzJGVV1K533QV7car2E398OL0mSJEmSpPVIOq/Ym+JJky2q6u4km9FZ9XZ0Vd045YVoQtq267ur6kP9rmU8s+bMqzlHntzvMiRJkjRJVi5c0O8SJEna6CVZ0r4k+ff04x2LAIuS7ERne+/phoqaLLtuM5tB//MpSZIkSZK0zvUlWKyql/Vj3tEkeSXwpmHN11TVMf2op198DpIkSZIkSZqofq1YXK9U1eeBz/e7jn7zOUiSJEmSJGmi+vGt0JIkSZIkSZI2cAaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJkno2s98FSJNp+Z2rmHvchf0uQ5IkSZNk5cIF/S5BkiSNwhWLkiRJkiRJknpmsKhJkWRukhX9rkOSJEmSJElTw2BRG5Qkbt+XJEmSJElaDxgsajLNTHJ6kmVJzkmyWZJnJ7kpyfIkpyaZlWTv1mfTJJsnuSXJLu341CSL2zUvAEhyVJKzk3wduLjP9yhJkiRJkiQMFjW5dgAWVdVuwK+AtwKnAYdX1a50vizo9VW1GDgfeD/wz8CXqmoFcDzwraraG3gmcFKSzdvY+wJHVtWzpvKGJEmSJEmSNDKDRU2mH1bVNe34S8CzgTuq6nut7XTg6e34vcCfAgN0wkWAQ4DjkiwFLgc2BbZt5y6pqp+PNGmSo5MMJhlcfe+qSbwdSZIkSZIkjcb31WkyVQ99HwNsAWxCJ0C8BwhwaFXd1t0xyVPb+ZEnrVoELAKYNWdeLzVIkiRJkiRpDbliUZNp2yT7tuOXAt8E5iZ5Smt7OXBFO14EvAs4A/hga7sIeEOSACTZY0qqliRJkiRJUs9csajJ9B3gyCSfAb4PvAm4Dji7fZvzYuDTSV4BPFBVX04yA7g2ybOA9wEnA8tauLgSeO7U34YkSZIkSZLGkyp3jmr6mDVnXs058uR+lyFJkqRJsnLhgn6XIEnSRi/JkqoaGN7uikVNK7tuM5tB//MpSZIkSZK0zvmORUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9m9nvAqTJtPzOVcw97sJ+lyFJkqRJsnLhgn6XIEmSRuGKRUmSJEmSJEk9M1iUJEmSJEmS1DODxWkkydwkK3rof1SSj7fjE5Mcu+6qG3X+J3R9/lySndrxi5N8J8ll7fOZSZYlectU1ihJkiRJkqSR+Y5F9dNRwArgRwBV9Tdd514N/G1VXZbkfwH7VdV2U1+iJEmSJEmSRuKKxelnZpLT2+q+c5JslmRlkscBJBlIcnmvgya5PMlHklzZVhLuneS8JN9P8v6ufl9LsiTJLUmObm0zkpyWZEWS5UnekuQwYAA4I8nSJI9scwwkOQE4APh0kpOAi4E/bP0OHKG2o5MMJhlcfe+qNXpokiRJkiRJ6o0rFqefHYBXV9U1SU4F/nYSx/5NVT09yZuA/wPsBfwc+H9JPlJV/wO8qqp+nuSRwOIk5wJzgW2qaheAJFtV1S+T/B1wbFUNtnYAquq9SZ41dC7JJ4ALqmr+SEVV1SJgEcCsOfNqEu9XkiRJkiRJo3DF4vTzw6q6ph1/ic7Kv8lyfvu9HLilqn5cVfcDtwN/3M69McnNwHWtbV47/6QkH0vy58CvJrEmSZIkSZIk9YHB4vQzfMVeAQ/w0N9607UY+/72+8Gu46HPM5McBBwM7FtVuwM3AZtW1S+A3YHLgWOAz61FDZIkSZIkSVoPGCxOP9sm2bcdvxS4GlhJZ9sywKHrcO7ZwC+q6t4kOwJPA2jvd3xEVZ0LvAvYs/W/C9hyHdYjSZIkSZKkdcRgcfr5DnBkkmXAY4BPAe8BPprkKmD1Opz7G3RWLi4D3kdnOzTANsDlSZYCpwF/39pPo/MFLUvbOxklSZIkSZK0gUiV33Wh6WNgYKAGBwf7XYYkSZIkSdK0kWRJVQ0Mb3fFoiRJkiRJkqSezex3AVq/JPkEsP+w5o9W1ef7UY8kSZIkSZLWTwaL+j1VdUy/a5AkSZIkSdL6z63QkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJkno2s98FSJNp+Z2rmHvchf0uQ5IkSZNk5cIF/S5BkiSNwhWLkiRJkiRJknpmsKg1lmRukhVTNNfrkrxiKuaSJEmSJEnS+NwKrb5IMqOqVk+0f1V9el3WI0mSJEmSpN64YlFra2aS05MsS3JOks2SPDvJTUmWJzk1ySyAJCuTnJDkauDwJEu7flYn2a79XNrGuzTJtu3aE5Mc29c7lSRJkiRJ0u8YLGpt7QAsqqrdgF8BbwVOAw6vql3prIp9fVf/+6rqgKr6clXNr6r5wGeBc6vqB8DHgS+08c4ATpm6W5EkSZIkSdJEGSxqbf2wqq5px18Cng3cUVXfa22nA0/v6n9W98VJ9gf+BnhVa9oX+HI7/iJwwHgFJDk6yWCSwdX3rlqzu5AkSZIkSVJPDBa1tqrH/vcMHSSZA/wrndWNd6/p+FW1qKoGqmpgxmazeyxHkiRJkiRJa8JgUWtr2yT7tuOXAt8E5iZ5Smt7OXDF8IuSbAL8G/COrtWNANcCL2nHRwBXr5OqJUmSJEmStFYMFrW2vgMcmWQZ8BjgI8ArgbOTLAceBEb6Ruf9gL2B93R9gcsTgDcCr2zjvRx401TchCRJkiRJknozs98FaMNVVSuBnUY4dSmwxwj953YdXwFsOsrQzxrh2hPXpEZJkiRJkiStG65YlCRJkiRJktQzVyxqWtl1m9kMLlzQ7zIkSZIkSZKmPVcsSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKkns3sdwHSZFp+5yrmHndhv8uQJEnSJFm5cEG/S5AkSaNwxaIkSZIkSZKknhksqmdJLk8yMEL7vyfZqg8lSZIkSZIkaYq5FVqTpqqe0+8aJEmSJEmSNDVcsSiSzE3y3SSnJ1mW5JwkmyXZK8kVSZYkuSjJnGHXPaJd8/72eWWSx7XxvpPks0luSXJxkke2Pk9O8o025lVJdmztL06yIsnNSa5sbTOSnJRkcavrtVP9bCRJkiRJkjQyg0UN2QFYVFW7Ab8CjgE+BhxWVXsBpwIf6Oo/EzgD+F5VvXOE8eYBn6iqnYFfAoe29kXAG9qYxwKfbO0nAH9WVbsDz29trwZWVdXewN7Aa5I8cTJuVpIkSZIkSWvHrdAa8sOquqYdfwn4B2AX4JIkADOAH3f1/wzwb1X1AUZ2R1UtbcdLgLlJtgD2A85uYwLMar+vAU5L8m/Aea3tEGC3JIe1z7PpBJZ3dE+U5GjgaIAZj9p6ovcrSZIkSZKktWCwqCE17PNdwC1Vte8o/a8FnpnkX6rqvhHO3991vBp4JJ0Vsr+sqvkPm7zqdUmeCiwAliaZD4TO6saLxiy8ahGdlZDMmjNv+H1IkiRJkiRpHXArtIZsm2QoRHwpcB2w9VBbkk2S7NzV/1+Bf6ez+nBCAXVV/Qq4I8mL25hJsns7fnJVXV9VJwA/A/4YuAh4fZJNWp/tk2y+1ncqSZIkSZKktWawqCHfAY5Msgx4DO39isAHk9wMLKWzjfl3qurDwI3AF5NM9N/SEcCr25i3AC9o7SclWZ5kBXAlcDPwOeBW4MbW/hlcZStJkiRJkrReSJU7Rzd2SeYCF1TVLv2uZW3NmjOv5hx5cr/LkCRJ0iRZuXBBv0uQJGmjl2RJVQ0Mb3f1l6aVXbeZzaD/+ZQkSZIkSVrnDBZFVa2k8w3QkiRJkiRJ0oT4jkVJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktSzmf0uQJpMy+9cxdzjLux3GZIkSZokKxcu6HcJkiRpFK5YlCRJkiRJktQzg0VJkiRJkiRJPTNY3MAkmZtkRTseSHLKGH0PSnLBFNX1hCTnTMVckiRJkiRJ6j/fsbgBq6pBYLDfdSSZWVU/Ag6bgnkeWJdzSJIkSZIkaWJcsTiFkvx1khuSLE3ymSQzktyd5ANJbk5yXZLHt75Pbp8XJ3lvkrtHGO93KxKTPKONuzTJTUm2bN22SHJOku8mOSNJxqhvYZJbkyxL8qHWdlqSTye5Ksn3kjy3tR+V5OwkXwcuHraS8qgk5yX5RpLvJ/nnrjle3ca5PMlnk3y8tW+d5Nx2v4uT7N/aT0yyKMnFwBdGqfvoJINJBlffu6rnv4skSZIkSZJ654rFKZLkT4DDgf2r6rdJPgkcAWwOXFdVx7cA7jXA+4GPAh+tqjOTvG4CUxwLHFNV1yTZArivte8B7Az8CLgG2B+4eoT6HgO8ENixqirJVl2n5wLPAJ4MXJbkKa19X2C3qvp5krnDhpzf5r4fuC3Jx4DVwLuAPYG7gG8BN7f+HwU+UlVXJ9kWuAj4k3ZuL+CAqvr1SDdeVYuARQCz5syrUZ6PJEmSJEmSJpErFqfOs+kEZIuTLG2fnwT8Bhh6D+ISOiEedEK7s9vxlycw/jXAh5O8Ediqa8vwDVX1n1X1ILC0a/zhfkUnjPxckhcB93ad+7eqerCqvg/cDuzY2i+pqp+PMt6lVbWqqu4DbgW2A/YBrqiqn1fVb7vuD+Bg4OPt2ZwPPKpr1eX5o4WKkiRJkiRJ6g9XLE6dAKdX1d//XmNybFUNrbJbzRr+TapqYZILgecA1yU5uJ26v6vbqONX1QNJ9qETeL4E+DvgWUOnh3dvv+8Zo6SR5h11GzadkHvf4QFi27k91jySJEmSJEnqA1csTp1LgcOS/CF0th4n2W6M/tcBh7bjl4w3eJInV9XyqvognS902XG8a4ZdvwUwu6r+HXgzna3MQ16c5BFJnkxnleVtvYzd5QbgGUkenWQmD90fwMV0wsyheuYjSZIkSZKk9ZbB4hSpqluBd9L5opNlwCXAnDEueTPw1iQ3tH7jfSvJm5OsSHIz8GvgP3oscUvgglbbFcBbus7d1tr+A3hd297cs6q6E/hH4Hrgm3S2SA/d1xuBgfbFMbcCE3mvpCRJkiRJkvokD+3C1fokyWbAr9sXqbwEeGlVvaAPdZwGXFBV50zSeFtU1d1txeJXgVOr6quTMTbAwMBADQ4OTtZwkiRJkiRJG70kS6pqYHi771hcf+1F58tMAvwSeFV/y5k0J7b3P25KZ/vz1/pbjiRJkiRJktaEweJ6qqquAnZfF2Mn+SrwxGHN76iqi0ao46jJnLuqjp3M8SRJkiRJktQfBosboap6Yb9rkCRJkiRJ0obNL2+RJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1LOZ/S5AmkzL71zF3OMu7HcZkiRJmqCVCxf0uwRJkrSGXLEoSZIkSZIkqWcGi5IkSZIkSZJ6tsEHi0mu7ePc/zDBfi9O8p0kl7XPZyZZluQtazjv3CQr1uR8kvcmOXhN5h02zpuTbDYJ40xKPZIkSZIkSZpaG+w7FpPMqKrVVbVfH8v4B+AfJ9Dv1cDfVtVlSf4XsF9VbTfRSZLMrKoH1rTIblV1wihzzKiq1T0M9WbgS8C9E71g+Bzt84j1jDHGpD0LSZIkSZIkrbl1umIxydeSLElyS5KjW9vdST7Y2r+ZZJ8klye5PcnzW58ZSU5Ksrit7Httaz8oyWVJvgwsHxqva763J1me5OYkC1vba9o4Nyc5d2iVXZLTkpyS5No292Fj3MecJFcmWZpkRZID2/iPbG1njHG/JwAHAJ9OchJwMfCH7boDk8xPcl27z68meXS77vIk/5jkCuBNSfZq9/Bt4Jiu2nZOckMbb1mSee3UjCSfbbVcnOSRXfd9WDtemeSEJFcDL05ySJJvJ7kxydlJthjlebwReAJwWdcqzBGvHWGO4Z+769kryRXtGV6UZM5Iz2LMf3SSJEmSJEmaEut6K/SrqmovYAB4Y5LHApsDl7f2u4D3A38KvBB4b7vu1cCqqtob2Bt4TZIntnP7AMdX1U7dEyX5C+AvgadW1e7AP7dT51XV3q3tO23sIXPohH7PBRaOcR8vAy6qqvnA7sDSqjoO+HVVza+qI0a736p6LzAIHFFVbwOeD/y/dt1VwBeAd1TVbnTC0nd3zbtVVT2jqv4F+Dzwxqrad1htrwM+2mobAP6ztc8DPlFVOwO/BA4d5d7uq6oDgG8C7wQOrqo9W81vHemCqjoF+BHwzKp6ZpLHjXPtfVV1QFV9ZZTPJNkE+BhwWHuGpwIfGOVZ/J4kRycZTDK4+t5Vo9ymJEmSJEmSJtO63gr9xiQvbMd/TCfs+g3wjda2HLi/qn6bZDkwt7UfAuzWtYpwdte1N1TVHSPMdTDw+aq6F6Cqft7ad0nyfmArYAvgoq5rvlZVDwK3Jnn8GPexGDi1hV9fq6qlPdzv/4w2aJLZdAKzK1rT6cDZXV3OGqXfF4G/aMffBo5P8kd0QtTvJwG4o6vOJTz0bIc7q/1+GrATcE27/g/a2BMx3rVnDes//DPADsAuwCVtjBnAj8e5BoCqWgQsApg1Z15NsGZJkiRJkiSthXUWLCY5iE7Yt29V3ZvkcmBT4LdVNRT+PAjcD1BVDyYZqifAG6rqohHGvGe0KYGRQqXTgL+sqpuTHAUc1HXu/mHXj6iqrkzydGAB8MUkJ1XVF0aobaT7XRtD9zravVFVX05yfavtoiR/A9zO79/bauCRE5jjkqp66RrUOd61w/9mI/0NA9wyworMsa6RJEmSJElSn6zLrdCzgV+0kG1HOqvaJuoi4PVthSBJtk+y+TjXXAy8qusdio9p7VsCP25jHTHaxWNJsh3w06r6LPCvwJ7t1G+HamQN7reqVgG/SHJga3o5cMUI/X4JrEpyQGv63X0keRJwe9uefD6wW6/311wH7J/kKW3czZJsP0b/u+g82zW5diS3AVsn2beNsUmSnXscQ5IkSZIkSVNkXW6F/gbwuiTL6IRG1/Vw7efobN29MZ19sf9N5/2Jo6qqbySZDwwm+Q3w73S+tfldwPXAD+hsvd5y1EFGdxDwtiS/Be4GXtHaFwHLktwIvIo1u98j6Xyxy2Z0Vhq+cpR+r6SzHftefn879+HAX7fa/ovOeyofNdEbG1JV/91WdJ6ZZFZrfifwvVEuWQT8R5Ift/cs9nLtSPP/pm19P6Vt/Z4JnAzc0uu9SJIkSZIkad3LQ7uSpQ3frDnzas6RJ/e7DEmSJE3QyoUL+l2CJEkaR5IlVTUwvH1df3mLNKV23WY2g/7nVJIkSZIkaZ0zWOySZFc637jc7f6qemo/6lkfJPkq8MRhze8Y/sU6kiRJkiRJ2rgYLHapquXA/H7XsT6pqhf2uwZJkiRJkiStf9blt0JLkiRJkiRJmqYMFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1bGa/C5Am0/I7VzH3uAv7XYYkSZImaOXCBf0uQZIkrSFXLEqSJEmSJEnqmcHiRirJiUmOHeP85UkGprImSZIkSZIkbTgMFjXpkrjFXpIkSZIkaZozWNyIJDk+yW1Jvgns0NrmJ7kuybIkX03y6K5L/jrJtUlWJNmn9d88yalJFie5KckLWvtRSc5O8nXg4vb5a0m+nuSOJH+X5K3tmuuSPKZd95o21s1Jzk2yWWs/Lckpbf7bkxw2pQ9LkiRJkiRJYzJY3Egk2Qt4CbAH8CJg73bqC8A7qmo3YDnw7q7LNq+q/YC/BU5tbccD36qqvYFnAicl2byd2xc4sqqe1T7vArwM2Af4AHBvVe0BfBt4RetzXlXtXVW7A98BXt01/xzgAOC5wMK1fASSJEmSJEmaRG5Z3XgcCHy1qu4FSHI+sDmwVVVd0fqcDpzddc2ZAFV1ZZJHJdkKOAR4ftf7GTcFtm3Hl1TVz7uuv6yq7gLuSrIK+HprXw7s1o53SfJ+YCtgC+Ciruu/VlUPArcmefxoN5bkaOBogBmP2nrcByFJkiRJkqS1Z7C4cam17F9AgEOr6rbuE0meCtwzrP/9XccPdn1+kIf+7Z0G/GVV3ZzkKOCgUa7PqEVWLQIWAcyaM6/Xe5QkSZIkSdIacCv0xuNK4IVJHplkS+B5dILAXyQ5sPV5OXBF1zWHAyQ5AFhVVavorCh8Q5K0c3usZV1bAj9OsglwxFqOJUmSJEmSpCniisWNRFXdmOQsYCnwA+CqdupI4NPtS1NuB17ZddkvklwLPAp4VWt7H3AysKyFiyvpvANxTb0LuL7VtJxO0ChJkiRJkqT1XKrcOarpY9aceTXnyJP7XYYkSZImaOXCBf0uQZIkjSPJkqoaGN7uikVNK7tuM5tB/3MqSZIkSZK0zvmORUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9m9nvAqTJtPzOVcw97sJ+lyFJkqQJWrlwQb9LkCRJa8gVi5IkSZIkSZJ6ZrA4zSSZm2RFv+voRZLnJzlunD5HJfn4VNUkSZIkSZKksbkVWr+TZGZVPTDV81bV+cD5Uz2vJEmSJEmS1pwrFtdDSV6RZFmSm5N8Mcl2SS5tbZcm2bb1e3ySr7Z+NyfZb9g4T0pyU5K9kzw5yTeSLElyVZIdW5/Tknw4yWXAB0ep5xlJlrafm5JsmeSgJFe2+W9N8ukkj2j9P5VkMMktSd7TNc7KJO9JcmOS5V01/G41YpKtk5ybZHH72X+dPGRJkiRJkiStFVcsrmeS7AwcD+xfVT9L8hjgdOALVXV6klcBpwB/2X5fUVUvTDID2AJ4dBtnB+ArwCurammSS4HXVdX3kzwV+CTwrDbt9sDBVbV6lLKOBY6pqmuSbAHc19r3AXYCfgB8A3gRcA5wfFX9vNV0aZLdqmpZu+ZnVbVnkr9t4/7NsLk+Cnykqq5uAepFwJ+M88yOBo4GmPGorcfqKkmSJEmSpElisLj+eRZwTlX9DKAFdPvSCe0Avgj8c1ffV7R+q4FVSR4NbA38H+DQqrqlhYH7AWcnGZpnVtecZ48RKgJcA3w4yRnAeVX1n22cG6rqdoAkZwIH0AkW/6qFfTOBOXTCx6Fg8bz2e0nXPXU7GNipq85HJdlyjNqoqkXAIoBZc+bVWH0lSZIkSZI0OQwW1z8BxgvHxjv//7d35+F2VvXd/98fEySMQRF5IlWjFsEBDHIAkUFQ6hTHgqKiAlZTFUVteWycEGht4/CzTnWIPhBUihQERKMCIrMCOYGQBAR9fhCq6E+0YpRRCN/fH3tFNsczZCcn2SfJ+3Vduc69173utb73yX3V8Ola914O/BzYB7iOzpb331fVjBH63znqZFVzkswHXgxckeSgEeqoJE+gsxJxj6q6Pck8YEpXn3vbzxUM//w9DNi7qu7ubuwKGiVJkiRJkjQB+I7FiecCOiv+tgVoW6F/BLymnT8MuKyr79tav0lJtm7tf6KzVfqNSV5XVX8Abk7yqtY3SZ6xqgUleVJVLamqjwKDwM7t1J5JntDerXhoq2trOkHl8iTbAy/q8f7PA97RNfeMHq+XJEmSJEnSOmCwOMFU1XXAR4CLk1wLfBI4GjgyyWLgDcC7Wvd3AQcmWUJna/HTusa5E3gJ8J4kL6cTSP5dG/M64OU9lPXuJEvbtXcD32vtPwbmAEuBm4Gzqupa4Jo2x4l0tlH34mhgoH1RzfXAW3u8XpIkSZIkSetAqnwlnXqX5ADgmKp6SZ9LeYhNp+1Y0w7/VL/LkCRJ0ipaNmdmv0uQJEljSLKwqgaGtvuORW1QdtlhKoP+41SSJEmSJGmtM1jUnyU5kge3Wa90eVUdNbRvVV0EXLQOypIkSZIkSdIEZLCoP6uqk4CT+l2HJEmSJEmSJj6/vEWSJEmSJElSzwwWJUmSJEmSJPXMYFGSJEmSJElSzwwWJUmSJEmSJPXMYFGSJEmSJElSzwwWJUmSJEmSJPXMYFGSJEmSJElSzwwWJUmSJEmSJPVscr8LkMbTkluXM332/H6XIUmSJGDZnJn9LkGSJK1FrliUJEmSJEmS1DODRUmSJEmSJEk9M1jsgyTTkyxdhX4nJDmoHb87yeZd596/Nmtcl7rvc5Q+85Icsq5qkiRJkiRJ0ugMFieoJJOq6tiq+kFrejeweVeXDSZYHHKfkiRJkiRJWg8YLPbP5CQnJ1mc5IwkmydZluTYJJcBr1q5Si/J0cBjgAuTXJhkDrBZkkVJTgFIcnaShUmuSzJr5SRJ7kjykSTXJrkiyfZJtkpyc5JNWp+t29ybDFdokqOTXN9q/UZrOy7J15L8MMnPkryltW+Z5IIkVydZkuTlrX16kp8k+XKr8bwkm7Vzf16NmGT3JBe3ezk3ybS19RcgSZIkSZKk1Wew2D87AXOralfgD8DbW/s9VbVvVX1jZceq+gzwS+DAqjqwqmYDd1fVjKo6rHV7U1XtDgwARyfZtrVvAVxRVc8ALgHeUlV/BC4CVn5N32uAb1bVfSPUOhvYrdX61q72XdsYewPHJnkMcA/wyqp6JnAg8P8kSeu/I/AfVfU04PfAwd2TtGDzs8Ah7V5OBD4yyu9w5XWzkgwmGVxx1/KxukuSJEmSJGkcGCz2z8+r6vJ2/HVg33Z82mqOd3SSa4ErgMfSCfEA/gR8px0vBKa3468AR7bjI4GTRhl7MXBKktcD93e1f6uq7q6q3wIXAnsCAf41yWLgB8AOwPat/81VtWiYWlbaCXg6cH6SRcAHgb8a7aYBqmpuVQ1U1cCkzaeO1V2SJEmSJEnjYHK/C9iI1Qif7+x1oCQHAAcBe1fVXUkuAqa00/dV1cqxV9D+zqvq8rY9+TnApKoa7ctkZgL7Ay8DPpTkaaPcw2HAdsDuVXVfkmVdtdzb1XcFsNnQWwGuq6q9R79jSZIkSZIk9ZsrFvvncUlWBmivBS4bo/8fga26Pt/X9U7EqcDtLVTcGXjWKtbwVeBURlmtmORhwGOr6kLgvcA2wJbt9MuTTGnbrg8AFrRabmuh4oHA41exFoAbge1W/l6SbNIVYkqSJEmSJGkCMVjsn58Ah7ctw48EvjBG/7nA95Jc2PV5cfvylu/T+TKYxcA/09kOvSpOAR5BJ1wcySTg60mWANcA/15Vv2/nrgLmt/n+uap+2cYcSDJIZ/XiDatYC1X1J+AQ4KNtW/ci4Nmrer0kSZIkSZLWnTy4S1Ybm/ZNzC+vqjesxrXHAXdU1SfGvbA1MDAwUIODg/0uQ5IkSZIkaYORZGFVDQxt9x2LG6kknwVeBLy437VIkiRJkiRp/WOwuJGqqncObUvyH8A+Q5o/XVV/8Q7GqjpuLZUmSZIkSZKk9YDBov6sqo7qdw2SJEmSJElaP/jlLZIkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWeT+12ANJ6W3Lqc6bPn97sMSZIkAcvmzOx3CZIkaS1yxaIkSZIkSZKknhksatwkOSDJd9rxy5LMXs1xHpPkjPGtTpIkSZIkSePJrdBaK6rqHOCc1bz2l8Ah41uRJEmSJEmSxpMrFvUQSaYnuSHJV5IsTXJKkoOSXJ7kZ0n2bH9+lOSa9nOnYcY5Isnn2vG8JJ9pfW9KckhrT5KPt3mWJDm0q4al7fhpSa5KsijJ4iQ7rsvfhyRJkiRJkobnikUN56+BVwGzgAXA64B9gZcB7wfeCOxfVfcnOQj4V+DgMcac1sbYmc5KxjOAvwVmAM8AHgUsSHLJkOveCny6qk5J8nBg0tCBk8xqtTJp6+16vVdJkiRJkiStBoNFDefmqloCkOQ64IKqqiRLgOnAVODktnqwgE1WYcyzq+oB4Pok27e2fYFTq2oF8OskFwN7AIu7rvsx8IEkfwWcWVU/GzpwVc0F5gJsOm3H6v12JUmSJEmS1Cu3Qms493YdP9D1+QE6YfQ/AxdW1dOBlwJTehwzQ36OqKr+k85KybuBc5M8dxXmkiRJkiRJ0lpmsKjVMRW4tR0fsQbjXAIcmmRSku2A/YGrujskeSJwU1V9hs4W6l3XYD5JkiRJkiSNE4NFrY6PAf+W5HKGeedhD86is+35WuCHwHur6v8b0udQYGmSRXTez/jVNZhPkiRJkiRJ4yRVvpJOG45Np+1Y0w7/VL/LkCRJErBszsx+lyBJksZBkoVVNTC03S9v0QZllx2mMug/YCVJkiRJktY6t0JLkiRJkiRJ6pnBoiRJkiRJkqSeGSxKkiRJkiRJ6pnBoiRJkiRJkqSeGSxKkiRJkiRJ6pnBoiRJkiRJkqSeGSxKkiRJkiRJ6pnBoiRJkiRJkqSeGSxKkiRJkiRJ6pnBoiRJkiRJkqSeTe53AdJ4WnLrcqbPnt/vMiRJkjYKy+bM7HcJkiSpj1yxKEmSJEmSJKlnBouSJEmSJEmSemawqDWW5Lgkx7Tji5IM9LsmSZIkSZIkrV0GixpROnxGJEmSJEmS9BcMjfQQSaYn+UmSzwNXAx9KsiDJ4iTHd/X7QJIbk/wA2GnIMK9P8qMkS5Ps2fo/MsnZbZwrkuza2o9LcmJb6XhTkqO75nh9kquSLErypSST1v5vQJIkSZIkSavCYFHD2Qn4KvBPwA7AnsAMYPck+yfZHXgNsBvwt8AeQ67foqqeDbwdOLG1HQ9cU1W7Au9v46+0M/CCNs+Hk2yS5CnAocA+VTUDWAEcNlyxSWYlGUwyuOKu5Wt045IkSZIkSVo1k/tdgCakW6rqiiSfAJ4PXNPatwR2BLYCzqqquwCSnDPk+lMBquqSJFsn2QbYFzi4tf8wybZJprb+86vqXuDeJLcB2wPPA3YHFiQB2Ay4bbhiq2ouMBdg02k71prevCRJkiRJksZmsKjh3Nl+Bvi3qvpS98kk7wZGC/CGnqs21kj97u1qW0HnuQxwclW9bxVrliRJkiRJ0jrkVmiN5lzgTUm2BEiyQ5JHA5cAr0yyWZKtgJcOue7Q1n9fYHlVLW/XHNbaDwB+W1V/GGXuC4BD2nwr39H4+HG7M0mSJEmSJK0RVyxqRFV1XnvX4Y/bduQ7gNdX1dVJTgMWAbcAlw659PYkPwK2Bt7U2o4DTkqyGLgLOHyMua9P8kHgvPbN1PcBR7X5JEmSJEmS1Gep8pV02nBsOm3Hmnb4p/pdhiRJ0kZh2ZyZ/S5BkiStA0kWVtXA0HZXLGqDsssOUxn0H7iSJEmSJElrne9YlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPZvc7wKk8bTk1uVMnz2/32VIkiRtFJbNmdnvEiRJUh+5YlGSJEmSJElSzwwWJUmSJEmSJPXMYHENJLmjD3NOT/K61bhuXpJDxmH+dyfZfJTzX0ny1DWdR5IkSZIkSRObweJqSDKpj9NPB3oOFnsxxv29Gxg2WEwyqareXFXXr5XC6PvvXpIkSZIkSc1GHywmeWOSxUmuTfK1oSv7Vq5KTHJAkguT/CewZMgYX0vy8q7PpyR52TBz7ZHkR22uq5JslWRKkpOSLElyTZIDW9/pSS5NcnX78+w2zBxgvySLkrwnyaQkH0+yoN3H37frk+RzSa5PMh949Bi/h2VJjk1yGfCqJM9P8uM29+lJtkxyNPAY4MIkF678/SQ5IcmVwN5JLkoy0M4NN8aLkvxX17wHJPn2SP2Hq20V/lolSZIkSZK0lm3U3wqd5GnAB4B9quq3SR4JfHKUS/YEnl5VNw9p/wrwHuBbSaYCzwYOHzLXw4HTgEOrakGSrYG7gXcBVNUuSXYGzkvyZOA24G+q6p4kOwKnAgPAbOCYqnpJG3cWsLyq9kiyKXB5kvOA3YCdgF2A7YHrgRPH+JXcU1X7JnkUcCZwUFXdmeSfgH+oqhOS/ANwYFX9tl2zBbC0qo5t9ay830cBHxw6BvCvwJeSbFFVdwKHAqeN0v+E7tqGK7r9DmYBTNp6uzFuUZIkSZIkSeNhow4WgecCZ6wMyarqdyuDsRFcNUyoSFVdnOQ/kjwa+Fvgm1V1/5BuOwG/qqoF7Zo/ACTZF/hsa7shyS3Ak4FbgM8lmQGsaG3DeT6wa9cqy6nAjsD+wKlVtQL4ZZIfjnZjzWnt57OAp9IJKQEeDvx4hGtWAN8cpn3YMarq/iTfB16a5AxgJvBe4DljzHkaI6iqucBcgE2n7Vhj3qUkSZIkSZLW2MYeLAYYGkTdT9sink7C9fCuc3eOMtbXgMOA1wBvatefS2e14CDwmWHmWlnDcN4D/Bp4RqvnnlHu4Z1Vde5DGpMXjzDfaFbeX4Dzq+q1q3DNPS28HK6ukcY4DTgK+B2woKr+2H7Xo8052u9ekiRJkiRJ69jG/o7FC4BXJ9kWoG2FXgbs3s6/HNhkFceaR+eLTaiq69rPF1TVjKp6M3AD8Jgke7S5tkoyGbiETiBJ2wL9OOBGOisPf1VVDwBvAFZ+ackfga265j0XeFuSTVaOkWSLNu5r2jsYpwEHruJ9AFwB7JPkr9uYm7fahpt/dca4CHgm8BYeXIk4Wn9JkiRJkiRNMBt1sNgCwI8AFye5ls77Fb8MPCfJVcBerOJKuar6NfAT4KQRzv+JzvsEP9vmOh+YAnwemJRkCZ2Q7Yiqure1H57kCjrboFfWsRi4P50vgHkPnfc7Xg9cnWQp8CU6K1HPAn5G54tmvgBc3MPv5TfAEcCpSRbTCf12bqfnAt9b+eUtqzNGW+H4HeBF7edYc0qSJEmSJGmCSZWvpBsPSTanE+I9s6qW97uejdXAwEANDg72uwxJkiRJkqQNRpKFVTUwtH2jXrE4XpIcRGer82cNFSVJkiRJkrQx2Ni/vGVcVNUP6LwbccJLchbwhCHN/zT0y18kSZIkSZKk0RgsbmSq6pX9rkGSJEmSJEnrP7dCS5IkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknhksSpIkSZIkSeqZwaIkSZIkSZKknk3udwHSeFpy63Kmz57f7zIkSZI2CsvmzOx3CZIkqY9csShJkiRJkiSpZwaLkiRJkiRJknpmsDiGJEcn+UmSW5N8boy+ByR59lquZ0aSF6/GdRclGRiH+d8/xvnvJtlmTeeRJEmSJEnSxGawOLa3Ay8GPrAKfQ8A1mqwCMygU89ak2TSKKeHDRbT8bCqenFV/X7tVDZmbZIkSZIkSVpHDBZHkeSLwBOBc4BHdLW/NMmVSa5J8oMk2yeZDrwVeE+SRUn2G2a8Fya5Osm1SS5obY9McnaSxUmuSLJra98zyY/aHD9KslOShwMnAIe2OQ5NskWSE5MsaH1f3q7fLMk32rinAZuNca93JDkhyZXA3klen+SqNs+XkkxKMgfYrLWdkmR6W835eeBq4LFJliV5VBtzuDHeluRjXfMekeSzI/UfrrZhap+VZDDJ4Iq7lq/aX64kSZIkSZLWiMHiKKrqrcAvgQOB27tOXQY8q6p2A74BvLeqlgFfBP69qmZU1aXdYyXZDvgycHBVPQN4VTt1PHBNVe1KZzXgV1v7DcD+bY5jgX+tqj+149PaHKfRWUn5w6rao9X58SRbAG8D7mrjfgTYfYzb3QJYWlV7Af8DHArsU1UzgBXAYVU1G7i7zX1Yu24n4KtVtVtV3dJ1v08ZbgzgDOBvu+Y9FDhtlP4Pqa2qLhtaeFXNraqBqhqYtPnUMW5TkiRJkiRJ42FyvwtYT/0VnTBsGvBw4OZVuOZZwCVVdTNAVf2ute8LHNzafphk2yRTga2Bk5PsCBSwyQjjPh94WZJj2ucpwOOA/YHPtHEXJ1k8Rn0rgG+24+fRCSIXJIHOasfbRrjulqq6Ypj2Yceoqt8kuSnJs4Cf0QkmLweOGmXO7tokSZIkSZI0ARgsrp7PAp+sqnOSHAAcN7RD28a7sH08BxikExD+Rddh2gr4Z+DCqnpl22Z90Qi1hM4qyBuHzL9ynFV1T1Wt6Brz5Kp63ypcd+codY00xmnAq+msyjyrqiqdgkfq312bJEmSJEmSJgC3Qq+eqcCt7fjwrvY/AlsBVNWKtmV4RlUdC/wYeE6SJ0Dn3YrtmktoW35bSPnbqvrDkDmOGG6O5lzgnS2YI8luw4z7dGDXHu7vAuCQJI9eWWuSx7dz9yUZafXkqo5xJvAK4LV0Qsax+kuSJEmSJGmCMVhcPccBpye5FPhtV/u3gVcO9+UtVfUbYBZwZpJreTBQOw4YaFuV5/BgUPkx4N+SXA50fxPyhcBTV355C52VjZsAi5MsbZ8BvgBs2cZ9L3DVqt5cVV0PfBA4r11/PjCtnZ7b5jpldceoqtuB64HHV9VVqzCnJEmSJEmSJphU9bJbVprYBgYGanBwsN9lSJIkSZIkbTCSLKyqgaHtrliUJEmSJEmS1DO/vGUjk+RKYNMhzW+oqiX9qEeSJEmSJEnrJ4PFjUxV7dXvGiRJkiRJkrT+cyu0JEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ5N7ncB0nhacutyps+e3+8yJEmSNgrL5szsdwmSJKmPXLEoSZIkSZIkqWcGi5IkSZIkSZJ6ZrC4HkoyPcnScRrrgCTfGY+xepx3XpJD2vFFSQba8XeTbLOu65EkSZIkSVJvfMfiRibJpKpasQbXT66q+8ezpm5V9eK1NbYkSZIkSZLGjysW11+Tk5ycZHGSM5JsnuR5Sa5JsiTJiUk2BUiyLMmxSS4DXpXkhUluaJ//duWASbZo1y1o47y8tR+R5PQk3wbOG6mgJO9tc1+bZE5rm5HkilbnWUkeMdpNtVof1Y5fn+SqJIuSfCnJpDX+rUmSJEmSJGlcGCyuv3YC5lbVrsAfgH8A5gGHVtUudFajvq2r/z1VtS9wNvBl4KXAfsD/6urzAeCHVbUHcCDw8SRbtHN7A4dX1XOHKybJi4BXAHtV1TOAj7VTXwX+qdW5BPjwqtxckqcAhwL7VNUMYAVw2Ah9ZyUZTDK44q7lqzK8JEmSJEmS1pDB4vrr51V1eTv+OvA84Oaq+mlrOxnYv6v/ae3nzq3fz6qq2rUrPR+YnWQRcBEwBXhcO3d+Vf1ulHoOAk6qqrsAqup3SaYC21TVxSPUNJrnAbsDC1o9zwOeOFzHqppbVQNVNTBp86mrOLwkSZIkSZLWhO9YXH9Vj/3vXIVrAxxcVTc+pDHZa8j1I13ba01jjXdyVb1vHMeUJEmSJEnSOHHF4vrrcUn2bsevBX4ATE/y163tDcDFw1x3A/CEJE/qunalc4F3JglAkt16qOc84E1JNm/XPrKqlgO3J9lvjJqGcwFwSJJHrxwvyeN7qEeSJEmSJElrkcHi+usnwOFJFgOPBP4dOBI4PckS4AHgi0Mvqqp7gFnA/PblLbd0nf5nYBNgcZKl7fMqqarvA+cAg23r8jHt1OF03tW4GJgBnLCK410PfBA4r117PjBtVeuRJEmSJEnS2pXOa/akDcOm03asaYd/qt9lSJIkbRSWzZnZ7xIkSdI6kGRhVQ0Mbfcdi9qg7LLDVAb9B64kSZIkSdJaZ7ConiTZBfjakOZ7q2qvftQjSZIkSZKk/jBYVE+qagmddyVKkiRJkiRpI+aXt0iSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ5N7ncB0nhacutyps+e3+8yJEmSNgrL5szsdwmSJKmPXLEoSZIkSZIkqWcGi5IkSZIkSZJ6ZrC4GpK8O8nm4zjesiSPWoPrj0jyuYlQiyRJkiRJkjYOBour593AuAWLvUoyqV9z91MS3wkqSZIkSZI0QRgsjiHJFknmJ7k2ydIkHwYeA1yY5MLW5wtJBpNcl+T4rmuXJTk+ydVJliTZubVvm+S8JNck+RKQrmvOTrKwjTWrq/2OJCckuRLYO8mRSX6a5GJgnzHu4VWt9muTXNLaJiX5RKtrcZJ3dl3yzmFqPi7JiUkuSnJTkqNXpeau40OSzGvHi7r+3J3kOe33fGKSBe338vLW94gkpyf5NnDeqv69SZIkSZIkae1yBdjYXgj8sqpmAiSZChwJHFhVv219PlBVv2srCS9IsmtVLW7nfltVz0zyduAY4M3Ah4HLquqEJDOBWV3zvamNtRmwIMk3q+p/gC2ApVV1bJJpwH8CuwPLgQuBa0a5h2OBF1TVrUm2aW2zgCcAu1XV/Uke2dV/uJoBdgYOBLYCbkzyhaq6b5Sah1VVM9rv8qXAe4EfAccDP6yqN7Uar0ryg3bJ3sCuVfW74cZrYeYsgElbbzfKr0GSJEmSJEnjxRWLY1sCHJTko0n2q6rlw/R5dZKr6YR7TwOe2nXuzPZzITC9He8PfB2gquYDt3f1PzrJtcAVwGOBHVv7CuCb7Xgv4KKq+k1V/Qk4bYx7uByYl+QtwMpt1AcBX6yq+1sd3aHdcDUDzK+qe1ugehuw/Rg1jyjJjsDHgUNbOPl8YHaSRcBFwBTgca37+SOFiq32uVU1UFUDkzafOtbUkiRJkiRJGgeuWBxDVf00ye7Ai4F/S/KQ7bhJnkBnVd8eVXV72+47pavLve3nCh76+66hcyU5gE7gt3dV3ZXkoq6x7qmqFaNdP8o9vDXJXsBMYFGSGXS2X480xkg139t1vAKYPEbN3eP/+XeSZAvgv4C3VNUvVzYDB1fVjd2FtLrvHPsuJUmSJEmStC65YnEMSR4D3FVVXwc+ATwT+COd7cAAW9MJvpYn2R540SoMewlwWBv/RcAjWvtU4PYW0O0MPGuE668EDmjvatwEeNUY9/Ckqrqyqo4FfktnVeF5wFtXfiHKkK3QvRit5l8neUqShwGv7Go/CTipqi7tajuXzrsd0+rZbTXrkSRJkiRJ0jrgisWx7QJ8PMkDwH3A2+i88+97SX5VVQcmuQa4DriJzrbjsRwPnNq2T18M/Hdr/z6dsG8xcCOdrcV/oap+leQ44MfAr4CreXCL83A+3rYeB7gAuBZYCjwZWJzkPuDLwOdWofahRqt5NvAd4Odtvi2TPB44BHhykje1fm8G/hn4VKsnwDLgJatRjyRJkiRJktaBVK3yjlppwhsYGKjBwcF+lyFJkiRJkrTBSLKwqgaGtrsVWpIkSZIkSVLP3Aq9AUnyAf7yfYunV9VH+lGPJEmSJEmSNlwGixuQFiAaIkqSJEmSJGmtcyu0JEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnq2eR+FyCNpyW3Lmf67Pn9LkOSJGmDsGzOzH6XIEmSJjBXLEqSJEmSJEnqmcGiVlmS6UmW9rsOSZIkSZIk9Z/BoiRJkiRJkqSeGSxqtSR5YpJrksxPckhX+x3t52lJXtzVPi/JwW3V46VJrm5/nt3OT0tySZJFSZYm2S/Jy9rnRUluTHLzur9TSZIkSZIkDcdgUT1LshPwTeBI4DcjdPsGcGjr/3DgecB3gduAv6mqZ7bzn2n9XwecW1UzgGcAi6rqnKqa0dquBT4xQj2zkgwmGVxx1/JxuENJkiRJkiSNxW+FVq+2A74FHFxV1yUZqd/3gM8k2RR4IXBJVd2dZCrwuSQzgBXAk1v/BcCJSTYBzq6qRSsHSvJe4O6q+o/hJqqqucBcgE2n7VhreH+SJEmSJElaBa5YVK+WAz8H9mmf76c9R+mkjA8HqKp7gIuAF9BZmfiN1v89wK/prEoc6Op/CbA/cCvwtSRvbGM+D3gV8Na1e1uSJEmSJEnqhSsW1as/Aa8Azm3vU1wG7A78F/ByYJOuvt8A3kwnQDyitU0FflFVDyQ5HJgEkOTxwK1V9eUkWwDPTHIx8HnghVV191q+L0mSJEmSJPXAFYvqWVXdCbyEzurDnwPPSXIVsBdwZ1fX8+isQvxBVf2ptX0eODzJFXS2Qa/sfwCwKMk1wMHAp+mEkdsCZ7UvcPnu2rwvSZIkSZIkrbpU+Uo6bTg2nbZjTTv8U/0uQ5IkaYOwbM7MfpcgSZImgCQLq2pgaLtbobVB2WWHqQz6D2BJkiRJkqS1zq3QkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZ5P7XYA0npbcupzps+f3uwxJkqQNwrI5M/tdgiRJmsBcsShJkiRJkiSpZwaLG6kk85IcMkz7Y5Kc0Y6PSPK5cZrvuCTHjMdYkiRJkiRJ6j+3QushquqXwF8EjpIkSZIkSVI3VyxuJJK8McniJNcm+Vpr3j/Jj5LctHL1YpLpSZZ2XfqYJN9P8rMkH+sa746u40OSzGvHL01yZZJrkvwgyfZdYz01yUVtvqOHmy/JMUmOa8dvSbKg1fzNJJuP869FkiRJkiRJq8lgcSOQ5GnAB4DnVtUzgHe1U9OAfYGXAHNGuHwGcCiwC3BokseOMd1lwLOqajfgG8B7u87tDLwA2BP4cJJNxhjrzKrao9X8E+DvxugvSZIkSZKkdcSt0BuH5wJnVNVvAarqd0kAzq6qB4Drh6ws7HZBVS0HSHI98Hjg56PM9VfAaUmmAQ8Hbu46N7+q7gXuTXIbMNKcKz09yb8A2wBbAucO1ynJLGAWwKSttxtjSEmSJEmSJI0HVyxuHALUMO33DukznO4+K3gwjO4eb0rX8WeBz1XVLsDfDzk33Fj389DnsLv/POAdbazjh5z7s6qaW1UDVTUwafOpI9yGJEmSJEmSxpPB4sbhAuDVSbYFSPLIcRjz10mekuRhwCu72qcCt7bjw1dlHODRSbZNsimdbdkrbQX8qm2ZPmwcapYkSZIkSdI4cSv0RqCqrkvyEeDiJCuAa8Zh2NnAd+hsi15KZ6sywHHA6UluBa4AnjBGbfclOQG4ks626Ru6Tn+otd8CLKETNEqSJEmSJGkCSNVwO2Sl9dOm03asaYd/qt9lSJIkbRCWzZnZ7xIkSdIEkGRhVQ0MbXcrtCRJkiRJkqSeuRVaG5RddpjKoP+fdUmSJEmSpLXOFYuSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnk/tdgDSelty6nOmz5/e7DEmSpA3Csjkz+12CJEmawFyxKEmSJEmSJKlnBouSJEmSJEmSerbeBYtJ9ktyXZJFSfZO8uK1PN/0JK9bjevmJTlkDea9KMnA6l7fNc42Sd6+puMMM+4RSR4zDuO8Nckbx6MmSZIkSZIkrTvrXbAIHAZ8oqpmADsBazVYBKYDPQeLE8g2wLgHi8ARQE/BYpLJQz9X1Rer6qurO4YkSZIkSZL6Y0IEi0m2SDI/ybVJliY5NMnzklyTZEmSE5NsmuTNwKuBY5OcCpwAHNpWLx46zLh7JPlRG/eqJFslmZLkpDbuNUkObH2nJ7k0ydXtz7PbMHOA/doc70kyKcnHkyxIsjjJ37frk+RzSa5PMh949Cj3u2eSM9vxy5PcneThrbaburq+qtX90yT7tf4jzb9lkgta7UuSvLyr/ie1+j/e+v7vruuP77r/nyT5clsRel6SzUao/xBgADiljbtZkt2TXJxkYZJzk0xrfS9K8q9JLgbeNczn45Ic0/o+Kcn32xiXJtm5tc9L8skkFwIfHfFBkiRJkiRJ0jozUVZ/vRD4ZVXNBEgyFVgKPK+qfprkq8DbqupTSfYFvlNVZyQ5AhioqncMHTDJw4HTgEOrakGSrYG7gXcBVNUuLbg6L8mTgduAv6mqe5LsCJxKJzybDRxTVS9p484CllfVHkk2BS5Pch6wG50VlLsA2wPXAyeOcL9Xt/4A+7V73YPO38eVXf0mV9We6Wz3/jBwEPB3I8z/c+CVVfWHJI8CrkhyTqv/6W2FJ0meD+wI7AkEOCfJ/sB/t/bXVtVbkvwXcDDw9aHFt9/9O9rvZTDJJsBngZdX1W9ayPsR4E3tkm2q6jlt/pcO+Xxc19BzgbdW1c+S7AV8HnhuO/dk4KCqWjG0nvZ3Mgtg0tbbjfArlyRJkiRJ0niaKMHiEuATST4KfAf4A3BzVf20nT8ZOAr4VA9j7gT8qqoWAFTVHwBaMPnZ1nZDklvohFa3AJ9LMgNY0dqG83xg1zz4/sSpdAK5/YFTW/D1yyQ/HKmwqro/yf9N8hQ6Ad8n2/WTgEu7up7Zfi6ksyV7tPl/AfxrCwkfAHagE3AOV//zgWva5y3b9f9N53e+aJg5x7IT8HTg/CS0+/hV1/nThvQf+pkkWwLPBk5vYwBs2tXl9OFCRYCqmksnlGTTaTvWKtYsSZIkSZKkNTAhgsW2KnF3Ou9L/DfgvNUZJ8m5dMK0QeAzwHAhU4ZpA3gP8GvgGXS2iN8z0jTAO6vq3CFzv3iE+UZyKfAi4D7gB8A8OoHcMV197m0/V/Dg39VI8x8BbAfsXlX3JVkGTBmh/n+rqi8NuX5613wr5xx2K/QIY15XVXuPcP7OMT5D53f++5UrK1dhDEmSJEmSJPXRRHnH4mOAu6rq68An6Kxcm57kr1uXNwAXD3PpH4GtVn6oqhdU1YyqejNwA/CYJHu0ObZK54s/LqHzBTC0LdCPA26ks/LvV1X1QJtv0nBzAOcCb2vbf0ny5CRbtHFf096BOA04cIzbvgR4N/DjqvoNsC2wM3DdGNeNNP9U4LYWKh4IPH6U+t/UVgiSZIckI74PchTd494IbJdk7zbmJkme1stgbUXpzUle1cZIkmesRl2SJEmSJElaBybEikU67yX8eJIH6KzgexudoOz0FgYuAL44zHUXArOTLKKzCu/PW2yr6k/tXX+fbV9CcjeddxR+HvhikiXA/cARVXVvks8D32zB1oU8uEJuMXB/kmvprCr8NJ0twlens2f3N8ArgLPovA9wCfBThg9Cu11JZ3XlJV3z3FZVY616/MoI858CfDvJILCITrBKVf1PksuTLAW+V1X/u23B/nHbcnwH8Ho6KxR7MY/O7/FuYG/gEOAz7f2Yk+lsWx8rJB3qMOALST4IbAJ8A7i2xzEkSZIkSZK0DmTsHEtafwwMDNTg4GC/y5AkSZIkSdpgJFlYVQND2yfEVmhJkiRJkiRJ65eJshV6g5XkLOAJQ5r/aeiXr0xUSf4D2GdI86er6qR+1CNJkiRJkqSJwWBxLauqV/a7hjVRVUf1uwZJkiRJkiRNPG6FliRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPTNYlCRJkiRJktQzg0VJkiRJkiRJPZvc7wKk8bTk1uVMnz2/32VIkiRNeMvmzOx3CZIkaT3nikVJkiRJkiRJPTNYlCRJkiRJktQzg8UJJsnRSX6S5JS1NP68JIesYt8Dknynx/GPS3LMaHOtzriSJEmSJEmaWHzH4sTzduBFVXXzyoYkk6vq/j7WJEmSJEmSJD2EKxYnkCRfBJ4InJNkeZK5Sc4DvppkuyTfTLKg/dmnXXNckhOTXJTkpiRHd433xiSLk1yb5GtdU+2f5Eet/1irF7dOclaS65N8McnD2th3dM1zSJJ5Y9zbC5PckOQy4G+72h+Z5OxW5xVJdm3t2yU5P8nVSb6U5JYkjxph7FlJBpMMrrhr+Ri3I0mSJEmSpPFgsDiBVNVbgV8CBwL/DuwOvLyqXgd8Gvj3qtoDOBj4StelOwMvAPYEPpxkkyRPAz4APLeqngG8q6v/NGBf4CXAnDHK2hP4R2AX4El0hYKrKskU4MvAS4H9gP/Vdfp44Jqq2hV4P/DV1v5h4IdV9UzgLOBxI41fVXOraqCqBiZtPrXX8iRJkiRJkrQa3Ao9sZ1TVXe344OApyZZeW7rJFu14/lVdS9wb5LbgO2B5wJnVNVvAarqd13jnl1VDwDXJ9l+jBquqqqbAJKcSieQPKPH+9gZuLmqftbG+Towq53bl05QSlX9MMm2Saa29le29u8nub3HOSVJkiRJkrQWGSxObHd2HT8M2LsraASgBY33djWtoPP3GqBGGLe7f0bos9LQMWqY9iljjDHcOKPNX6tQlyRJkiRJkvrIrdDrj/OAd6z8kGTGGP0vAF6dZNvW/5GrOe+eSZ7Q3q14KHBZa/91kqe09leOMcYNwBOSPKl9fm3XuUuAw1qNBwC/rao/tHle3dqfDzxiNeuXJEmSJEnSWmCwuP44GhhoX3JyPfDW0TpX1XXAR4CLk1wLfHI15/0xnfcwLgVupvO+Q4DZwHeAHwK/GqOWe+hsfZ7fvrzllq7Tx9Huq81zeGs/Hnh+kquBF7U5/ria9yBJkiRJkqRxlqqRdqhK/ZNkU2BFVd2fZG/gC1U1Y6zrBgYGanBwcK3XJ0mSJEmStLFIsrCqBoa2+45FTVSPA/6rbbX+E/CWPtcjSZIkSZKkLgaLIskuwNeGNN9bVXv1ox6A9g3Su/VrfkmSJEmSJI3OYFFU1RJgRr/rkCRJkiRJ0vrDL2+RJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1LPJ/S5AGk9Lbl3O9Nnz+12GJEnShLdszsx+lyBJktZzrliUJEmSJEmS1DODRa0VSR6T5IzVuG5ZkketjZokSZIkSZI0ftwKrbWiqn4JHNLvOiRJkiRJkrR2uGJRayzJR5O8vevzcUn+McnS9vkrSRa1P79J8uEk05Jc0tqWJtlvmHHPTrIwyXVJZq3Le5IkSZIkSdLoDBY1Hr4BHNr1+dXAgpUfqurNVTUDeDnwP8A84HXAua39GcCiYcZ9U1XtDgwARyfZdi3ULkmSJEmSpNXgVmitsaq6JsmjkzwG2A64Hfjv7j5JpgCnA++oqluSLABOTLIJcHZVLRpm6KOTvLIdPxbYkU4w+RBtNeMsgElbbzdOdyVJkiRJkqTRuGJR4+UMOu9UPJTOCsahvgicWVU/AKiqS4D9gVuBryV5Y3fnJAcABwF7V9UzgGuAKcNNXFVzq2qgqgYmbT51fO5GkiRJkiRJo3LFosbLN4AvA48CngNsuvJEkqOArapqTlfb44Fbq+rLSbYAngl8tWu8qcDtVXVXkp2BZ62De5AkSZIkSdIqMljUuKiq65JsRScs/FWS6V2njwHuS7Koff4icDfwv5PcB9wBPGTFIvB94K1JFgM3AleszfolSZIkSZLUG4NFjZuq2qXreBnw9Hb8hBEuOXmYMaZ3fXzROJYnSZIkSZKkceQ7FiVJkiRJkiT1zBWL2qDsssNUBufM7HcZkiRJkiRJGzxXLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ4ZLEqSJEmSJEnqmcGiJEmSJEmSpJ5N7ncB0nhacutyps+e3+8yJEmS+m7ZnJn9LkGSJG3gXLEoSZIkSZIkqWcGixuRJNskeXvX5+lJXrca4xyQ5DvjW92Ycx6X5Jh1OackSZIkSZJGZrC4cdkGeHvX5+lAT8FikknjWI8kSZIkSZLWUwaLG7Ak/5BkafvzbmAO8KQki5J8vH3er31+T5JJST6eZEGSxUn+vo1zQJILk/wnsKQNv2WSM5LckOSUJGl9n5fkmiRLkpyYZNPWvizJo9rxQJKL2vFxrd9FSW5KcnRX/R9IcmOSHwA7rZNfmiRJkiRJklaJX96ygUqyO3AksBcQ4Erg9cDTq2pG63MAcExVvaR9ngUsr6o9WiB4eZLz2pB7tmtvbtftBjwN+CVwObBPkkFgHvC8qvppkq8CbwM+NUa5OwMHAlsBNyb5ArAr8Jo2z2TgamDhav9CJEmSJEmSNK5csbjh2hc4q6rurKo7gDOB/ca45vnAG5MsohNEbgvs2M5dVVU3d/W9qqp+UVUPAIvobKveCbi5qn7a+pwM7L8Ktc6vqnur6rfAbcD2rdazququqvoDcM5IFyeZlWQwyeCKu5avwnSSJEmSJElaU65Y3HBlNa95Z1Wd+5DGzgrFO4f0vbfreAWdZ2m0Oe/nwSB7yiqMBVBjVgxU1VxgLsCm03ZcpWskSZIkSZK0ZlyxuOG6BHhFks2TbAG8ks6W5a26+vxxyOdzgbcl2QQgyZPbtavqBmB6kr9un98AXNyOlwG7t+ODV7H+VybZLMlWwEt7qEOSJEmSJElrmSsWN1BVdXWSecBVrekrVbUwyeVJlgLfA94P3J/kWjrvRvw0nS3NV7cvY/kN8Ioe5rwnyZHA6UkmAwuAL7bTxwP/J8n76WyzXpX6T6OzzfoW4NJVrUOSJEmSJElrX6rcOaoNx6bTdqxph3+q32VIkiT13bI5M/tdgiRJ2kAkWVhVA0PbXbGoDcouO0xl0H9ES5IkSZIkrXW+Y1GSJEmSJElSzwwWJUmSJEmSJPXMYFGSJEmSJElSzwwWJUmSJEmSJPXMYFGSJEmSJElSzwwWJUmSJEmSJPXMYFGSJEmSJElSzwwWJUmSJEmSJPXMYFGSJEmSJElSzwwWJUmSJEmSJPXMYFGSJEmSJElSzyb3uwBpPC25dTnTZ8/vdxmSJEl9t2zOzH6XIEmSNnCuWJQkSZIkSZLUM4NFSZIkSZIkST0zWJwAkmyT5O3t+DFJzmjHRyT5XI9jvX9t1DjekrwiyVO7Pp+Q5KB2vF+S65IsSrJZko+3zx/vX8WSJEmSJEnqZrA4MWwDvB2gqn5ZVYeswVjrRbAIvAL4c7BYVcdW1Q/ax8OAT1TVjKq6G/h74JlV9b/XfZmSJEmSJEkajsHixDAHeFJboXd6kqVd5x6b5PtJbkzy4ZWNSV6f5Kp2zZeSTEoyB9istZ3S+p2dZGFb8Ter6/o7knwkybVJrkiy/UjFJZmX5AtJLkxyU5LnJDkxyU+SzOvq94Ukg22u47va5yS5PsniJJ9I8mzgZcDHW61PanMckuTNwKuBY5OckuQcYAvgyiSHjlDfrDbv4Iq7lvf2m5ckSZIkSdJq8VuhJ4bZwNOrakaS6cB3us7tCTwduAtYkGQ+cCdwKLBPVd2X5PPAYVU1O8k7qmpG1/VvqqrfJdmsXf/NqvofOmHdFVX1gSQfA94C/MsoNT4CeC6dQPDbwD7Am9uYM6pqEfCBNtck4IIkuwK/AF4J7FxVlWSbqvp9Cwy/U1Urt30DUFVfSbLvkHN3DLmnh6iqucBcgE2n7Vij3IMkSZIkSZLGicHixHd+CwJJciawL3A/sDudUA9gM+C2Ea4/Oskr2/FjgR2B/wH+xIMB5kLgb8ao49stGFwC/LqqlrSargOmA4uAV7dVkZOBaXS2Ol8P3AN8pYWi3xlmbEmSJEmSJK1nDBYnvqEr8AoIcHJVvW+0C5McABwE7F1VdyW5CJjSTt9XVSvHXsHYz8K97ecDXccrP09O8gTgGGCPqrq9bZGeUlX3J9kTeB7wGuAddFY+SpIkSZIkaT3mOxYnhj8CW41w7m+SPLJtZX4FcDlwAXBIkkcDtPOPb/3vS7JJO54K3N5CxZ2BZ621O4Ct6WzRXt7e1/iiVtuWwNSq+i7wbmBG6z/aPUuSJEmSJGmCc8XiBFBV/5Pk8valLT8Zcvoy4GvAXwP/WVWDAEk+CJyX5GHAfcBRwC103jW4OMnVwJuAtyZZDNwIXLEW7+HaJNcA1wE30QlAoRMefivJFDorLd/T2r8BfDnJ0cCafAu2JEmSJEmS+iAP7oaV1n8DAwM1ODjY7zIkSZIkSZI2GEkWVtXA0Ha3QkuSJEmSJEnqmVuh9WdJPgC8akjz6VX1kX7UI0mSJEmSpInLYFF/1gJEQ0RJkiRJkiSNya3QkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJkno2ud8FSONpya3LmT57fr/LkCRJ6rtlc2b2uwRJkrSBc8WiJEmSJEmSpJ4ZLEqSJEmSJEnqmcHiBJDkhCQHrea1M5K8eBxruSjJwHiNJ0mSJEmSpA2T71icAKrq2DW4fAYwAHx3fKqZuJJMqqoV/a5DkiRJkiRJrlhc55J8KMkNSc5PcmqSY5LMS3JIO39skgVJliaZmySt/aIkH01yVZKfJtkvycOBE4BDkyxKcugIcz6nnV+U5JokW7X29yZZkuTaJHO6LnlV9zyt7xFJzkzy/SQ/S/KxrvG/kGQwyXVJju9qX5bkUe14IMlF7fi7XfUsT3J4kklJPt7ufXGSv299D0hyYZL/BJaM21+EJEmSJEmS1ogrFtehtsX4YGA3Or/7q4GFQ7p9rqpOaP2/BrwE+HY7N7mq9mxbnz9cVQclORYYqKp3jDL1McBRVXV5ki2Be5K8CHgFsFdV3ZXkkV39HzIPsHKb9oxW+73AjUk+W1U/Bz5QVb9LMgm4IMmuVbV4pGKq6sXt/nYHTgLOBv4OWF5VeyTZFLg8yXntkj2Bp1fVzcONl2QWMAtg0tbbjfJrkCRJkiRJ0nhxxeK6tS/wraq6u6r+yIOBYbcDk1yZZAnwXOBpXefObD8XAtN7mPdy4JNJjga2qar76YSFJ1XVXQBV9btVmOeCqlpeVfcA1wOPb+2vTnI1cE2r96ljFdRWMn4NeF1VLQeeD7wxySLgSmBbYMfW/aqRQsVW+9yqGqiqgUmbTx1rakmSJEmSJI0DVyyuWxn1ZDIF+DydFYg/T3IcMKWry73t5wp6+LurqjlJ5gMvBq5oXxQToEa4ZKR57u06XgFMTvIEOisi96iq25PM66r5fh4Mr/98H21l4zeAE6pq6cpm4J1VdW53IUkOAO5ctTuVJEmSJEnSuuKKxXXrMuClSaa0Lckzh5xfGb79tp0/ZBXG/COw1WgdkjypqpZU1UeBQWBn4DzgTUk2b30eOdoYo9iaTvC3PMn2wIu6zi0Ddm/HB3e1zwEWV9U3utrOBd6WZJNWz5OTbLGaNUmSJEmSJGktM1hch6pqAXAOcC2d7caDwPKu878HvkznS0rOBhaswrAXAk8d7ctbgHe3L4O5Frgb+F5Vfb/VMti2Hx+zmvd0LZ0t0NcBJ9LZdr3S8cCnk1xKZ4XjSscAz+/6ApeXAV+hs7366iRLgS/hilpJkiRJkqQJK1Uj7YbV2pBky6q6o60UvASYVVVX97uuDcWm03asaYd/qt9lSJIk9d2yOUM3x0iSJK2eJAuramBouyvC1r25SZ5KZ9vzyYaK42uXHaYy6D+iJUmSJEmS1jqDxXWsql63tsZOciTwriHNl1fVUWtrTkmSJEmSJG2cDBY3IFV1EnBSv+uQJEmSJEnShs8vb5EkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST0zWJQkSZIkSZLUM4NFSZIkSZIkST2b3O8CpPG05NblTJ89v99lSJIk9d2yOTP7XYIkSdrAuWJRkiRJkiRJUs8MFiVJkiRJkiT1zGBxA5XkoiQD7fiOcR77iCSfG88xV2HOeUkOWZdzSpIkSZIkaWQGixpREt/BKUmSJEmSpGEZLE5wSd6b5Oh2/O9JftiOn5fk60m+kGQwyXVJjh9jrEcl+XGSmUm2S/LNJAvan31an+OSzE1yHvDVUYZ7TJLvJ/lZko91zfHaJEuSLE3y0a72O7qOD0kyrx3PS/KZJD9KctPKVYnp+FyS65PMBx7d6+9OkiRJkiRJa48r0ia+S4B/BD4DDACbJtkE2Be4FDi9qn6XZBJwQZJdq2rx0EGSbA+cA3ywqs5P8p/Av1fVZUkeB5wLPKV13x3Yt6ruHqWuGcBuwL3AjUk+C6wAPtquvx04L8krqursMe5xWrufnVuNZwCvBHYCdgG2B64HThzu4iSzgFkAk7beboypJEmSJEmSNB4MFie+hcDuSbaiE+JdTSdg3A84Gnh1C9Ym0wnongoMDRY3AS4Ajqqqi1vbQcBTk6zss3WbA+CcMUJFgAuqajlAkuuBxwPbAhdV1W9a+ynA/sDZY4x1dlU9AFzfAlDadadW1QrglytXag6nquYCcwE2nbZjjTGXJEmSJEmSxoHB4gRXVfclWQYcCfyITmh4IPAk4G7gGGCPqrq9bS+eMsww99MJKF8ArAwWHwbsPTRAbEHjnatQ2r1dxyvoPEsZoS9Ad+A3tMbusbrHMCSUJEmSJEmaoHzH4vrhEjoB4iV0tj+/FVgEbE0nBFzeVvq9aITrC3gTsHOS2a3tPOAdKzskmTEOdV4JPKe9y3ES8FoeDDJ/neQpSR5GZ5vzWC4BXpNkUpJpdMJUSZIkSZIkTRCuWFw/XAp8APhxVd2Z5B7g0qq6Nsk1wHXATcDlIw1QVSuSvAb4dpI/0NlG/R9JFtN5Di6hE1iutqr6VZL3ARfSWXn43ar6Vjs9G/gO8HNgKbDlGMOdBTwXWAL8lAcDSkmSJEmSJE0AqXK3qTYcAwMDNTg42O8yJEmSJEmSNhhJFlbVwNB2t0JLkiRJkiRJ6plboTWiJC8APjqk+eaqWpV3JEqSJEmSJGkDZrCoEVXVucC5/a5DkiRJkiRJE49boSVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8m97sAaTwtuXU502fP73cZkiRJfbdszsx+lyBJkjZwrliUJEmSJEmS1DODRUmSJEmSJEk9M1jUnyU5IMl3xmms45IcMx5jtfGOSPK58RpPkiRJkiRJa8ZgcYJI4vsuuySZ1O8aJEmSJEmSNDKDxXGW5ENJbkhyfpJTkxyT5ElJvp9kYZJLk+zc+s5L8skkFwIfbZ+/kOTCJDcleU6SE5P8JMm8rjm+kGQwyXVJju9qX5bk+CRXJ1mycp4R6nxOkkXtzzVJtmqntkxyRruHU5Kk9d89ycXtHs5NMq21X5TkU0l+lGRpkj27pnlqO39TkqO75n59kqva3F9aGSImuSPJCUmuBPZOcmSSnya5GNhnlHuZ1X4fgyvuWr7qf1mSJEmSJElabQaL4yjJAHAwsBvwt8BAOzUXeGdV7Q4cA3y+67InAwdV1T+2z48Angu8B/g28O/A04BdksxofT5QVQPArsBzkuzaNd5vq+qZwBfaXCM5BjiqqmYA+wF3t/bdgHcDTwWeCOyTZBPgs8Ah7R5OBD7SNdYWVfVs4O3t3Eo7Ay8A9gQ+nGSTJE8BDgX2aXOvAA5bOQ6wtKr2Av5f4Hg6geLftHqGVVVzq2qgqgYmbT51lFuWJEmSJEnSeHH77fjaF/hWVd0NkOTbwBTg2cDpbfEfwKZd15xeVSu6Pn+7qirJEuDXVbWkjXUdMB1YBLw6ySw6f3/T6IRui9v1Z7afC+mEmyO5HPhkklOAM6vqF62+q6rqF23ORW3O3wNPB85vfSYBv+oa61SAqrokydZJtmnt86vqXuDeJLcB2wPPA3YHFrSxNgNua/1XAN9sx3sBF1XVb1otp9EJYSVJkiRJkjQBGCyOrwzT9jDg92113nDuHPL53vbzga7jlZ8nJ3kCndWGe1TV7W2L9JRhrl/BKH+/VTUnyXzgxcAVSQ4acn33GAGuq6q9RxpuhM8jjXVyVb1vmHHuGRKyDh1XkiRJkiRJE4RbocfXZcBLk0xJsiUwE7gLuDnJqwDS8Yw1mGNrOmHk8iTbAy9anUGSPKmqllTVR4FBOtuWR3IjsF2Svdu1myR5Wtf5Q1v7vsDyqhrtRYcXAIckeXS75pFJHj9MvyuBA5Js27Ziv2qVb06SJEmSJElrnSsWx1FVLUhyDnAtcAudwG45nXcIfiHJB4FNgG+0Pqszx7VJrgGuA26is6V5dbw7yYF0VhJeD3wPGHZFYlX9KckhwGeSTKXz3Hyq1QBwe5If0Qk93zRG/de338N5SR4G3AccRef31d3vV0mOA35MZ9v11XS2YEuSJEmSJGkCSJW7TcdTki2r6o4kmwOXALOq6up+17W2JLkIOKaqBvtdC8DAwEANDk6IUiRJkiRJkjYISRa2LxJ+CFcsjr+5SZ5K572HJ2/IoaIkSZIkSZI2XgaL46yqXtfvGrolORJ415Dmy6vqqPEYv6oOGI9xJEmSJEmStH4xWNzAVdVJwEn9rkOSJEmSJEkbFr8VWpIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPDBYlSZIkSZIk9cxgUZIkSZIkSVLPJve7AGk8Lbl1OdNnz+93GZIkSWtk2ZyZ/S5BkiRpTK5YlCRJkiRJktQzg0VJkiRJkiRJPTNYnMCSzEtyyDDtByT5Tp9qev8Y57+bZJt1VI4kSZIkSZL6xGBRfyHJpFFODxsspuNhVfXiqvr92qlszNokSZIkSZK0jhgsrmNJPpTkhiTnJzk1yTFJZiS5IsniJGclecQw172wXXcZ8Ldd7VskOTHJgiTXJHl5az8iyZlJvp/kZ0k+NkZddyQ5IcmVwN5JXp/kqiSLknwpyaQkc4DNWtspSaYn+UmSzwNXA49NsizJo9qYw43xtu5aWp2fHan/cLWt6d+BJEmSJEmS1pzB4jqUZAA4GNiNTjg40E59FfinqtoVWAJ8eMh1U4AvAy8F9gP+V9fpDwA/rKo9gAOBjyfZop2bARwK7AIcmuSxo5S3BbC0qvYC/qddt09VzQBWAIdV1Wzg7qqaUVWHtet2Ar5aVbtV1S1dNT9luDGAM+gKRluf00bp/5DaquqyoYUnmZVkMMngiruWj3KLkiRJkiRJGi+T+13ARmZf4FtVdTdAkm/TCc22qaqLW5+TgdOHXLczcHNV/axd93VgVjv3fOBlSY5pn6cAj2vHF1TV8nbN9cDjgZ+PUNsK4Jvt+HnA7sCCJACbAbeNcN0tVXXFMO3DjlFVv0lyU5JnAT+jE0xeDhw1ypzdtf2FqpoLzAXYdNqONVI/SZIkSZIkjR+DxXUra3DtSIFZgIOr6saHNCZ7Afd2Na1g9L/ve6pqRdeYJ1fV+1ahrjtHqWukMU4DXg3cAJxVVZVOmjhS/+7aJEmSJEmSNAG4FXrdugx4aZIpSbYEZtIJ5m5Psl/r8wbg4iHX3QA8IcmT2ufXdp07F3hnC+ZIsts41HkBcEiSR7cxH5nk8e3cfUk2WcMxzgReQec+TluF/pIkSZIkSZpgDBbXoapaAJwDXEsnXBsElgOH03k34mI670U8Ych199DZ+jy/fXnLLV2n/xnYBFicZGn7vKZ1Xg98EDiv1XQ+MK2dntvmOmV1x6iq24HrgcdX1VWrMKckSZIkSZImmFT5Srp1KcmWVXVHks2BS4BZVXV1v+vaUGw6bceadvin+l2GJEnSGlk2Z2a/S5AkSfqzJAuramBou+9YXPfmJnkqnS9ZOdlQcXztssNUBv2HuCRJkiRJ0lpnsLiOVdXr+jl/kiuBTYc0v6GqlvSjHkmSJEmSJK2fDBY3MlW1V79rkCRJkiRJ0vrPL2+RJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9M1iUJEmSJEmS1DODRUmSJEmSJEk9m9zvAqTxtOTW5UyfPb/fZUiSJK2RZXNm9rsESZKkMbliUZIkSZIkSVLPDBYlSZIkSZIk9cxgcZwkmZ5k6RpcPy/JIeNZUz8leVmS2e14uyRXJrkmyX5JXpXkJ0ku7HedkiRJkiRJWj2+Y3EdSjKpqlb0u461LcnkqjoHOKc1PQ+4oaoOb+e/D7y9qgwWJUmSJEmS1lOuWBxfk5OcnGRxkjOSbJ5kWZJjk1wGvCrJW5IsSHJtkm8m2bzr+oOSXJrkp0leAn9eCXlpkqvbn2e39gOSXNTmuSHJKUnSzu2R5EdtjquSbJVkSpKTkixpKwcPbH2PSHJmku8n+VmSj412g0n+rtV3UZIvJ/lca5+X5JNtFeJH27ifSzID+Bjw4iSLknwY2Bf4YpKPj1ddkiRJkiRJWrdcsTi+dgL+rqouT3Ii8PbWfk9V7QuQZNuq+nI7/hfg74DPtn7TgecATwIuTPLXwG3A31TVPUl2BE4FBlr/3YCnAb8ELgf2SXIVcBpwaFUtSLI1cDfwLoCq2iXJzsB5SZ7cxpnRxroXuDHJZ6vq50NvLsljgA8BzwT+CPwQuLary5OBg6pqRZIj2nyLkhwLDFTVO9o4BwLHVNVgkn8ch7pmAbMAJm293dDTkiRJkiRJWgtcsTi+fl5Vl7fjr9NZmQedoG+lp7cViEuAw+gEgyv9V1U9UFU/A24CdgY2Ab7c+p8OPLWr/1VV9YuqegBYRCeY3An4VVUtAKiqP1TV/a2Wr7W2G4Bb6ASBABdU1fKquge4Hnj8CPe3J3BxVf2uqu5r9XQ7fTW2eq9xXVU1t6oGqmpg0uZTe5xekiRJkiRJq8MVi+OrRvh8Z1fbPOAVVXVtW9V3wBjXvwf4NfAMOkHwPV3n7+06XkHn7zPDjENrH8lw4wxntDHgofe5qsajLkmSJEmSJK1jrlgcX49Lsnc7fi1w2TB9tgJ+lWQTOisWu70qycOSPAl4InAjMJXOCsQHgDcAk8ao4QbgMUn2AGjvV5wMXLJyvrbV+HFt/F5cBTwnySPamAf3eP1wxqMuSZIkSZIkrWMGi+PrJ8DhSRYDjwS+MEyfDwFXAufTCQG73QhcDHwPeGvbAvz5NuYVdLYIj7oqsKr+BBwKfDbJtW2eKW2cSW1L9WnAEVV178gjDTv2rcC/tvp/QGd78vJexhjGGtclSZIkSZKkdS9Vw+2alYaXZMuquqOtWDwLOLGqzup3XSsNDAzU4OBgv8uQJEmSJEnaYCRZWFUDQ9tdsaheHZdkEbAUuBk4u6/VSJIkSZIkqS/8MgwNK8mVwKZDmt9QVcf0ox5JkiRJkiRNLAaLGlZV7dXvGiRJkiRJkjRxuRVakiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1zGBRkiRJkiRJUs8MFiVJkiRJkiT1bHK/C5DG05JblzN99vx+lyFJkrRGls2Z2e8SJEmSxuSKRUmSJEmSJEk9M1jcyCSZnmRpv+tYaaLVI0mSJEmSpFVjsKj1ShK370uSJEmSJE0ABosbsSRPTHJNkj2SXJFkcZKzkjyinb8oyb8nuSTJT1q/M5P8LMm/dI3zD0mWtj/vbm3T2zVfTnJdkvOSbNbO7Z7k2iQ/Bo7qGmdKkpOSLGl1Hdjaj0hyepJvA+etw1+RJEmSJEmSRmCwuJFKshPwTeBI4P8A/1RVuwJLgA93df1TVe0PfBH4Fp0g8OnAEUm2TbJ7G2Mv4FnAW5Ls1q7dEfiPqnoa8Hvg4NZ+EnB0Ve09pKyjAKpqF+C1wMlJprRzewOHV9Vzh7mXWUkGkwyuuGv56v1CJEmSJEmS1BODxY3TdnRCwtcDNwPbVNXF7dzJwP5dfc9pP5cA11XVr6rqXuAm4LHAvsBZVXVnVd0BnAns1665uaoWteOFwPQkU4fM97WuufZd+bmqbgBuAZ7czp1fVb8b7maqam5VDVTVwKTNp/bye5AkSZIkSdJqMljcOC0Hfg7sswp9720/H+g6Xvl5MpBVuBZgRVf/GqH/aGPdOXqZkiRJkiRJWpcMFjdOfwJeAbwRmAncnmTlKsM3ABePcN1wLgFekWTzJFsArwQuHalzVf0eWJ5k39Z02JCxDgNI8mTgccCNPdQiSZIkSZKkdcRv2N1IVdWdSV4CnE9n+/LHk2xOZ4vzkT2Mc3WSecBVrekrVXVNkumjXHYkcGKSu4Bzu9o/D3wxyRLgfuCIqro3GW0hoyRJkiRJkvohVSPtSpXWP5tO27GmHf6pfpchSZK0RpbNmdnvEiRJkv4sycKqGhja7opFbVB22WEqg/5DXJIkSZIkaa3zHYuSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnBouSJEmSJEmSemawKEmSJEmSJKlnk/tdgDSelty6nOmz5/e7DEmSpBEtmzOz3yVIkiSNC1csSpIkSZIkSeqZwaIkSZIkSZKknhksboSSXJRkYJj27ybZZh3VsCzJo9bFXJIkSZIkSRp/vmNRf1ZVL+53DZIkSZIkSVo/uGJxA5Lk9UmuSrIoyZeSTEoyL8nSJEuSvGdI/4clOTnJv7TPy5I8Ksn0JDck+Uq79pQkByW5PMnPkuzZ+j8yydlJFie5Ismuo9S2bZLzklyT5EtAus79Q5tnaZJ3d7V/qNVxfpJTkxwz3r8zSZIkSZIkrR6DxQ1EkqcAhwL7VNUMYAXwQWCHqnp6Ve0CnNR1yWTgFOCnVfXBYYb8a+DTwK7AzsDrgH2BY4D3tz7HA9dU1a6t7aujlPhh4LKq2g04B3hcq3t34EhgL+BZwFuS7Na2ah8M7Ab8LfAXW7e77n1WksEkgyvuWj5KCZIkSZIkSRovBosbjucBuwMLkixqnx8JPDHJZ5O8EPhDV/8vAUur6iMjjHdzVS2pqgeA64ALqqqAJcD01mdf4GsAVfVDYNskU0cYb3/g663vfOD2rjHOqqo7q+oO4Exgv9b+raq6u6r+CHx7pBuvqrlVNVBVA5M2H2l6SZIkSZIkjSeDxQ1HgJOrakb7s1NVvQt4BnARcBTwla7+PwIOTDJlhPHu7Tp+oOvzAzz4bs7wl2qUGoc7N9wYo7VLkiRJkiRpAjBY3HBcAByS5NHw5/cfPh54WFV9E/gQ8Myu/v8H+C5wepLV/RKfS4DD2nwHAL+tqj+sQt8XAY/oan9Fks2TbAG8ErgUuAx4aZIpSbYEZq5mjZIkSZIkSVoL/FboDURVXZ/kg8B5SR4G3Af8A3BW+wzwviHXfLJtXf5aksNWY9rjgJOSLAbuAg4fpe/xwKlJrgYuBv671XB1knnAVa3fV6rqGoAk5wDXArcAg4AvUJQkSZIkSZog0nltnjTxJNmyqu5IsjmdlY2zqurq0a4ZGBiowcHBdVOgJEmSJEnSRiDJwqr6iy/WdcWiJrK5SZ4KTKHz/shRQ0VJkiRJkiStOwaLGldJjgTeNaT58qo6qtexqup141OVJEmSJEmSxpvBosZVVZ0EnNTvOiRJkiRJkrR2+a3QkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZwaLkiRJkiRJknpmsChJkiRJkiSpZ5P7XYA0npbcupzps+f3uwxJkqQRLZszs98lSJIkjQtXLEqSJEmSJEnqmcGi1kiS6UmWrkK/E5IctLbnkSRJkiRJ0rrhVmitdUkmVdWxPV4zuaruX1s1SZIkSZIkac0YLGo8TE5yMrAb8FPgjcD1wInA84HPJXkh8J2qOiPJscBLgc2AHwF/X1WV5KL2eR/gnPb5ROAu4LJ1e0uSJEmSJEkajVuhNR52AuZW1a7AH4C3t/Z7qmrfqvrGkP6fq6o9qurpdMLFl3Sd26aqnlNV/w9wEnB0Ve092uRJZiUZTDK44q7l43NHkiRJkiRJGpXBosbDz6vq8nb8dWDfdnzaCP0PTHJlkiXAc4GndZ07DSDJVDoh48Wt/WsjTV5Vc6tqoKoGJm0+dbVvQpIkSZIkSavOrdAaDzXC5zuHdkwyBfg8MFBVP09yHDClq8vKazLMuJIkSZIkSZogXLGo8fC4JCu3K7+W0d+HuDJE/G2SLYFDhutUVb8HlidZufrxsPEoVJIkSZIkSePDYFHj4SfA4UkWA48EvjBSxxYYfhlYApwNLBhl3COB/0jyY+Du8SpWkiRJkiRJay5V7jbVhmPTaTvWtMM/1e8yJEmSRrRszsx+lyBJktSTJAuramBou+9Y1AZllx2mMug/1iVJkiRJktY6t0JLkiRJkiRJ6pnBoiRJkiRJkqSeGSxKkiRJkiRJ6pnBoiRJkiRJkqSeGSxKkiRJkiRJ6lmqqt81SOMmyR+BG/tdhzSCRwG/7XcR0ih8RjXR+YxqovMZ1UTm86mJzmd0Ynt8VW03tHFyPyqR1qIbq2qg30VIw0ky6POpicxnVBOdz6gmOp9RTWQ+n5rofEbXT26FliRJkiRJktQzg0VJkiRJkiRJPTNY1IZmbr8LkEbh86mJzmdUE53PqCY6n1FNZD6fmuh8RtdDfnmLJEmSJEmSpJ65YlGSJEmSJElSzwwWtUFI8sIkNyb5v0lm97seKcljk1yY5CdJrkvyrtb+yCTnJ/lZ+/mIfteqjVeSSUmuSfKd9tnnUxNGkm2SnJHkhvZ/S/f2GdVEkuQ97X/jlyY5NckUn1H1U5ITk9yWZGlX24jPZJL3tf9+ujHJC/pTtTYmIzyjH2//W784yVlJtuk65zO6HjBY1HovySTgP4AXAU8FXpvkqf2tSuJ+4B+r6inAs4Cj2nM5G7igqnYELmifpX55F/CTrs8+n5pIPg18v6p2Bp5B51n1GdWEkGQH4GhgoKqeDkwCXoPPqPprHvDCIW3DPpPt36WvAZ7Wrvl8++8qaW2ax18+o+cDT6+qXYGfAu8Dn9H1icGiNgR7Av+3qm6qqj8B3wBe3ueatJGrql9V1dXt+I90/oN4BzrP5smt28nAK/pSoDZ6Sf4KmAl8pavZ51MTQpKtgf2B/wNQVX+qqt/jM6qJZTKwWZLJwObAL/EZVR9V1SXA74Y0j/RMvhz4RlXdW1U3A/+Xzn9XSWvNcM9oVZ1XVfe3j1cAf9WOfUbXEwaL2hDsAPy86/MvWps0ISSZDuwGXAlsX1W/gk74CDy6j6Vp4/Yp4L3AA11tPp+aKJ4I/AY4qW3X/0qSLfAZ1QRRVbcCnwD+G/gVsLyqzsNnVBPPSM+k/w2liehNwPfasc/oesJgURuCDNPm151rQkiyJfBN4N1V9Yd+1yMBJHkJcFtVLex3LdIIJgPPBL5QVbsBd+KWUk0g7T11LweeADwG2CLJ6/tbldQT/xtKE0qSD9B5ndQpK5uG6eYzOgEZLGpD8AvgsV2f/4rOVhSpr5JsQidUPKWqzmzNv04yrZ2fBtzWr/q0UdsHeFmSZXReH/HcJF/H51MTxy+AX1TVle3zGXSCRp9RTRQHATdX1W+q6j7gTODZ+Ixq4hnpmfS/oTRhJDkceAlwWFWtDA99RtcTBovaECwAdkzyhCQPp/OC13P6XJM2cklC591gP6mqT3adOgc4vB0fDnxrXdcmVdX7quqvqmo6nf+b+cOqej0+n5ogqur/A36eZKfW9DzgenxGNXH8N/CsJJu3/81/Hp33KfuMaqIZ6Zk8B3hNkk2TPAHYEbiqD/VpI5fkhcA/AS+rqru6TvmMrifyYBgsrb+SvJjO+8ImASdW1Uf6W5E2dkn2BS4FlvDgO+zeT+c9i/8FPI7Of5S8qqqGvmRbWmeSHAAcU1UvSbItPp+aIJLMoPPlQg8HbgKOpPP/FPcZ1YSQ5HjgUDpb964B3gxsic+o+iTJqcABwKOAXwMfBs5mhGeybT19E51n+N1V9b2/HFUaPyM8o+8DNgX+p3W7oqre2vr7jK4HDBYlSZIkSZIk9cyt0JIkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWcGi5IkSZIkSZJ6ZrAoSZIkSZIkqWf/P+YCcMWVs79DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x3600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_plot.plot(kind = 'barh', figsize=(20,50), title=\"Count Per Breed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120.000000\n",
       "mean      85.183333\n",
       "std       13.298122\n",
       "min       66.000000\n",
       "25%       75.000000\n",
       "50%       82.000000\n",
       "75%       91.250000\n",
       "max      126.000000\n",
       "Name: id, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_plot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0075dc49dab4024d12fafe67074d8a81</td>\n",
       "      <td>norfolk_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>007b5a16db9d9ff9d7ad39982703e429</td>\n",
       "      <td>wire-haired_fox_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007ff9a78eba2aebb558afea3a51c469</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10192</th>\n",
       "      <td>ff4afeb51a1473f7ba18669a8ff48bc9</td>\n",
       "      <td>border_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10194</th>\n",
       "      <td>ff52a3909f5801a71161cec95d213107</td>\n",
       "      <td>west_highland_white_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>ff84992beff3edd99b72718bec9448d2</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>ff8e3fa7e04faca99af85195507ee54d</td>\n",
       "      <td>sealyham_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10212</th>\n",
       "      <td>ffc532991d3cd7880d27a449ed1c4770</td>\n",
       "      <td>tibetan_terrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1621 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                        breed\n",
       "5      002211c81b498ef88e1b40b9abf84e1d           bedlington_terrier\n",
       "6      00290d3e1fdd27226ba27a8ce248ce85           bedlington_terrier\n",
       "14     0075dc49dab4024d12fafe67074d8a81              norfolk_terrier\n",
       "16     007b5a16db9d9ff9d7ad39982703e429      wire-haired_fox_terrier\n",
       "18     007ff9a78eba2aebb558afea3a51c469             lakeland_terrier\n",
       "...                                 ...                          ...\n",
       "10192  ff4afeb51a1473f7ba18669a8ff48bc9               border_terrier\n",
       "10194  ff52a3909f5801a71161cec95d213107  west_highland_white_terrier\n",
       "10201  ff84992beff3edd99b72718bec9448d2           bedlington_terrier\n",
       "10202  ff8e3fa7e04faca99af85195507ee54d             sealyham_terrier\n",
       "10212  ffc532991d3cd7880d27a449ed1c4770              tibetan_terrier\n",
       "\n",
       "[1621 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrier = data[data['breed'].str.contains('terrier')]\n",
    "terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tibetan_terrier                   107\n",
       "australian_terrier                102\n",
       "lakeland_terrier                   99\n",
       "border_terrier                     91\n",
       "silky_terrier                      90\n",
       "bedlington_terrier                 89\n",
       "sealyham_terrier                   88\n",
       "norfolk_terrier                    83\n",
       "irish_terrier                      82\n",
       "wire-haired_fox_terrier            82\n",
       "kerry_blue_terrier                 82\n",
       "yorkshire_terrier                  82\n",
       "scotch_terrier                     82\n",
       "west_highland_white_terrier        81\n",
       "toy_terrier                        79\n",
       "staffordshire_bullterrier          79\n",
       "norwich_terrier                    78\n",
       "american_staffordshire_terrier     74\n",
       "soft-coated_wheaten_terrier        71\n",
       "Name: breed, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrier['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1621, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00a366d4b4a9bbb6c8a63126697b7656</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>00cc68a50b2d016a6b29af628ea4e04b</td>\n",
       "      <td>labrador_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0100f55e4f0fe28f2c0465d3fc4b9897</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>02ff77af410e966b7b661f6f0789d947</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10134</th>\n",
       "      <td>fdc614c16f54555064a32bc94522b4a4</td>\n",
       "      <td>curly-coated_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>febcab8eb2da444bf83336cffec7eb92</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10182</th>\n",
       "      <td>ff05f3976c17fef275cc0306965b3fe4</td>\n",
       "      <td>labrador_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>ff6f47aa8e181b6efa4d0be7b09b5628</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10221</th>\n",
       "      <td>fff43b07992508bc822f33d8ffd902ae</td>\n",
       "      <td>chesapeake_bay_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                     breed\n",
       "4      0021f9ceb3235effd7fcde7f7538ed62          golden_retriever\n",
       "25     00a366d4b4a9bbb6c8a63126697b7656          golden_retriever\n",
       "31     00cc68a50b2d016a6b29af628ea4e04b        labrador_retriever\n",
       "37     0100f55e4f0fe28f2c0465d3fc4b9897          golden_retriever\n",
       "127    02ff77af410e966b7b661f6f0789d947          golden_retriever\n",
       "...                                 ...                       ...\n",
       "10134  fdc614c16f54555064a32bc94522b4a4    curly-coated_retriever\n",
       "10172  febcab8eb2da444bf83336cffec7eb92          golden_retriever\n",
       "10182  ff05f3976c17fef275cc0306965b3fe4        labrador_retriever\n",
       "10198  ff6f47aa8e181b6efa4d0be7b09b5628          golden_retriever\n",
       "10221  fff43b07992508bc822f33d8ffd902ae  chesapeake_bay_retriever\n",
       "\n",
       "[378 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = data[data['breed'].str.contains('retriever')]\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labrador_retriever          84\n",
       "chesapeake_bay_retriever    83\n",
       "flat-coated_retriever       72\n",
       "curly-coated_retriever      72\n",
       "golden_retriever            67\n",
       "Name: breed, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>004396df1acd0f1247b740ca2b14616e</td>\n",
       "      <td>shetland_sheepdog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00693b8bc2470375cc744a6391d397ec</td>\n",
       "      <td>maltese_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00792e341f3c6eb33663e415d0715370</td>\n",
       "      <td>african_hunting_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>014c2b0cd8e3b517e649cecf8543b8fe</td>\n",
       "      <td>african_hunting_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0177a92a906192bfde8adbb8a237e524</td>\n",
       "      <td>greater_swiss_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10154</th>\n",
       "      <td>fe3e760d763e186541e18f303cd7caca</td>\n",
       "      <td>bernese_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>fee98c990f4d69c6a8467dd0f0668440</td>\n",
       "      <td>greater_swiss_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10178</th>\n",
       "      <td>fef5d4cdaf50cf159102e803c7d6aa9c</td>\n",
       "      <td>bernese_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>ff7d9c08091acc3b18b869951feeb013</td>\n",
       "      <td>maltese_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>ffa0055ec324829882186bae29491645</td>\n",
       "      <td>maltese_dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                       breed\n",
       "10     004396df1acd0f1247b740ca2b14616e           shetland_sheepdog\n",
       "12     00693b8bc2470375cc744a6391d397ec                 maltese_dog\n",
       "15     00792e341f3c6eb33663e415d0715370         african_hunting_dog\n",
       "50     014c2b0cd8e3b517e649cecf8543b8fe         african_hunting_dog\n",
       "61     0177a92a906192bfde8adbb8a237e524  greater_swiss_mountain_dog\n",
       "...                                 ...                         ...\n",
       "10154  fe3e760d763e186541e18f303cd7caca        bernese_mountain_dog\n",
       "10176  fee98c990f4d69c6a8467dd0f0668440  greater_swiss_mountain_dog\n",
       "10178  fef5d4cdaf50cf159102e803c7d6aa9c        bernese_mountain_dog\n",
       "10200  ff7d9c08091acc3b18b869951feeb013                 maltese_dog\n",
       "10204  ffa0055ec324829882186bae29491645                 maltese_dog\n",
       "\n",
       "[698 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = data[data['breed'].str.contains('dog')]\n",
    "dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maltese_dog                   117\n",
       "bernese_mountain_dog          114\n",
       "old_english_sheepdog           87\n",
       "african_hunting_dog            86\n",
       "greater_swiss_mountain_dog     82\n",
       "shetland_sheepdog              76\n",
       "french_bulldog                 70\n",
       "eskimo_dog                     66\n",
       "Name: breed, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [boston, bull]\n",
       "1                             [dingo]\n",
       "2                          [pekinese]\n",
       "3                          [bluetick]\n",
       "4                 [golden, retriever]\n",
       "                     ...             \n",
       "10217                        [borzoi]\n",
       "10218               [dandie, dinmont]\n",
       "10219                      [airedale]\n",
       "10220           [miniature, pinscher]\n",
       "10221    [chesapeake, bay, retriever]\n",
       "Name: breed, Length: 10222, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breeds = data['breed']\n",
    "breeds = breeds.str.split('_')\n",
    "breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bull',\n",
       " 'dingo',\n",
       " 'pekinese',\n",
       " 'bluetick',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'borzoi',\n",
       " 'basenji',\n",
       " 'deerhound',\n",
       " 'sheepdog',\n",
       " 'hound',\n",
       " 'dog',\n",
       " 'bluetick',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'redbone',\n",
       " 'terrier',\n",
       " 'boxer',\n",
       " 'doberman',\n",
       " 'otterhound',\n",
       " 'otterhound',\n",
       " 'terrier',\n",
       " 'dingo',\n",
       " 'retriever',\n",
       " 'schnauzer',\n",
       " 'spaniel',\n",
       " 'coonhound',\n",
       " 'cairn',\n",
       " 'affenpinscher',\n",
       " 'retriever',\n",
       " 'hound',\n",
       " 'setter',\n",
       " 'hound',\n",
       " 'weimaraner',\n",
       " 'schnauzer',\n",
       " 'retriever',\n",
       " 'bull',\n",
       " 'groenendael',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'dhole',\n",
       " 'dingo',\n",
       " 'affenpinscher',\n",
       " 'poodle',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'elkhound',\n",
       " 'dog',\n",
       " 'spaniel',\n",
       " 'hound',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'schnauzer',\n",
       " 'affenpinscher',\n",
       " 'shih-tzu',\n",
       " 'terrier',\n",
       " 'kuvasz',\n",
       " 'shepherd',\n",
       " 'dog',\n",
       " 'basset',\n",
       " 'terrier',\n",
       " 'schipperke',\n",
       " 'ridgeback',\n",
       " 'setter',\n",
       " 'appenzeller',\n",
       " 'shepherd',\n",
       " 'bloodhound',\n",
       " 'samoyed',\n",
       " 'schnauzer',\n",
       " 'spaniel',\n",
       " 'setter',\n",
       " 'kelpie',\n",
       " 'papillon',\n",
       " 'collie',\n",
       " 'spaniel',\n",
       " 'appenzeller',\n",
       " 'deerhound',\n",
       " 'entlebucher',\n",
       " 'collie',\n",
       " 'malamute',\n",
       " 'spaniel',\n",
       " 'chihuahua',\n",
       " 'terrier',\n",
       " 'saluki',\n",
       " 'weimaraner',\n",
       " 'entlebucher',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'bloodhound',\n",
       " 'pug',\n",
       " 'schnauzer',\n",
       " 'malinois',\n",
       " 'setter',\n",
       " 'terrier',\n",
       " 'pug',\n",
       " 'terrier',\n",
       " 'boxer',\n",
       " 'ridgeback',\n",
       " 'komondor',\n",
       " 'airedale',\n",
       " 'terrier',\n",
       " 'setter',\n",
       " 'leonberg',\n",
       " 'schnauzer',\n",
       " 'hairless',\n",
       " 'terrier',\n",
       " 'ridgeback',\n",
       " 'saluki',\n",
       " 'leonberg',\n",
       " 'mastiff',\n",
       " 'dingo',\n",
       " 'setter',\n",
       " 'airedale',\n",
       " 'spaniel',\n",
       " 'mastiff',\n",
       " 'dog',\n",
       " 'bluetick',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'entlebucher',\n",
       " 'spaniel',\n",
       " 'schnauzer',\n",
       " 'terrier',\n",
       " 'schnauzer',\n",
       " 'retriever',\n",
       " 'ridgeback',\n",
       " 'lhasa',\n",
       " 'pekinese',\n",
       " 'cardigan',\n",
       " 'greyhound',\n",
       " 'dhole',\n",
       " 'clumber',\n",
       " 'terrier',\n",
       " 'collie',\n",
       " 'setter',\n",
       " 'terrier',\n",
       " 'hound',\n",
       " 'groenendael',\n",
       " 'shih-tzu',\n",
       " 'terrier',\n",
       " 'lhasa',\n",
       " 'cairn',\n",
       " 'setter',\n",
       " 'hound',\n",
       " 'sheepdog',\n",
       " 'bernard',\n",
       " 'leonberg',\n",
       " 'borzoi',\n",
       " 'bernard',\n",
       " 'hound',\n",
       " 'pinscher',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'schnauzer',\n",
       " 'cairn',\n",
       " 'otterhound',\n",
       " 'groenendael',\n",
       " 'poodle',\n",
       " 'deerhound',\n",
       " 'wolfhound',\n",
       " 'malamute',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'borzoi',\n",
       " 'griffon',\n",
       " 'terrier',\n",
       " 'chow',\n",
       " 'affenpinscher',\n",
       " 'retriever',\n",
       " 'samoyed',\n",
       " 'terrier',\n",
       " 'hound',\n",
       " 'elkhound',\n",
       " 'mastiff',\n",
       " 'collie',\n",
       " 'setter',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'bullterrier',\n",
       " 'coonhound',\n",
       " 'clumber',\n",
       " 'terrier',\n",
       " 'foxhound',\n",
       " 'setter',\n",
       " 'husky',\n",
       " 'papillon',\n",
       " 'doberman',\n",
       " 'hound',\n",
       " 'affenpinscher',\n",
       " 'bloodhound',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'husky',\n",
       " 'malinois',\n",
       " 'dog',\n",
       " 'basenji',\n",
       " 'husky',\n",
       " 'bloodhound',\n",
       " 'clumber',\n",
       " 'newfoundland',\n",
       " 'newfoundland',\n",
       " 'cardigan',\n",
       " 'bluetick',\n",
       " 'doberman',\n",
       " 'spaniel',\n",
       " 'sheepdog',\n",
       " 'komondor',\n",
       " 'pinscher',\n",
       " 'briard',\n",
       " 'retriever',\n",
       " 'groenendael',\n",
       " 'airedale',\n",
       " 'hound',\n",
       " 'dog',\n",
       " 'dinmont',\n",
       " 'retriever',\n",
       " 'basset',\n",
       " 'dog',\n",
       " 'ridgeback',\n",
       " 'coonhound',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'retriever',\n",
       " 'shih-tzu',\n",
       " 'pyrenees',\n",
       " 'beagle',\n",
       " 'saluki',\n",
       " 'deerhound',\n",
       " 'vizsla',\n",
       " 'deerhound',\n",
       " 'terrier',\n",
       " 'deerhound',\n",
       " 'dog',\n",
       " 'appenzeller',\n",
       " 'greyhound',\n",
       " 'dog',\n",
       " 'hound',\n",
       " 'shepherd',\n",
       " 'greyhound',\n",
       " 'bluetick',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'foxhound',\n",
       " 'saluki',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'whippet',\n",
       " 'leonberg',\n",
       " 'appenzeller',\n",
       " 'dhole',\n",
       " 'dingo',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'shih-tzu',\n",
       " 'collie',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'hound',\n",
       " 'basset',\n",
       " 'terrier',\n",
       " 'shih-tzu',\n",
       " 'schnauzer',\n",
       " 'spaniel',\n",
       " 'poodle',\n",
       " 'pekinese',\n",
       " 'pyrenees',\n",
       " 'groenendael',\n",
       " 'retriever',\n",
       " 'greyhound',\n",
       " 'setter',\n",
       " 'poodle',\n",
       " 'keeshond',\n",
       " 'pug',\n",
       " 'redbone',\n",
       " 'boxer',\n",
       " 'poodle',\n",
       " 'basenji',\n",
       " 'dog',\n",
       " 'airedale',\n",
       " 'foxhound',\n",
       " 'terrier',\n",
       " 'retriever',\n",
       " 'spaniel',\n",
       " 'weimaraner',\n",
       " 'basset',\n",
       " 'poodle',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'poodle',\n",
       " 'terrier',\n",
       " 'basenji',\n",
       " 'doberman',\n",
       " 'leonberg',\n",
       " 'bull',\n",
       " 'mastiff',\n",
       " 'dog',\n",
       " 'clumber',\n",
       " 'kuvasz',\n",
       " 'whippet',\n",
       " 'pomeranian',\n",
       " 'doberman',\n",
       " 'foxhound',\n",
       " 'dingo',\n",
       " 'clumber',\n",
       " 'husky',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'retriever',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'boxer',\n",
       " 'greyhound',\n",
       " 'pug',\n",
       " 'bull',\n",
       " 'airedale',\n",
       " 'cairn',\n",
       " 'pembroke',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'otterhound',\n",
       " 'sheepdog',\n",
       " 'sheepdog',\n",
       " 'pomeranian',\n",
       " 'cardigan',\n",
       " 'spaniel',\n",
       " 'papillon',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'pinscher',\n",
       " 'terrier',\n",
       " 'cardigan',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'sheepdog',\n",
       " 'pekinese',\n",
       " 'dinmont',\n",
       " 'collie',\n",
       " 'wolfhound',\n",
       " 'basset',\n",
       " 'whippet',\n",
       " 'dog',\n",
       " 'chow',\n",
       " 'elkhound',\n",
       " 'cairn',\n",
       " 'dane',\n",
       " 'terrier',\n",
       " 'hound',\n",
       " 'bloodhound',\n",
       " 'greyhound',\n",
       " 'shih-tzu',\n",
       " 'kelpie',\n",
       " 'deerhound',\n",
       " 'terrier',\n",
       " 'borzoi',\n",
       " 'chihuahua',\n",
       " 'spaniel',\n",
       " 'komondor',\n",
       " 'spaniel',\n",
       " 'chow',\n",
       " 'dog',\n",
       " 'cairn',\n",
       " 'dhole',\n",
       " 'briard',\n",
       " 'redbone',\n",
       " 'terrier',\n",
       " 'papillon',\n",
       " 'hound',\n",
       " 'schnauzer',\n",
       " 'samoyed',\n",
       " 'retriever',\n",
       " 'redbone',\n",
       " 'foxhound',\n",
       " 'pinscher',\n",
       " 'collie',\n",
       " 'pinscher',\n",
       " 'wolfhound',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'hound',\n",
       " 'spaniel',\n",
       " 'pyrenees',\n",
       " 'bloodhound',\n",
       " 'sheepdog',\n",
       " 'pointer',\n",
       " 'whippet',\n",
       " 'basenji',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'kuvasz',\n",
       " 'bulldog',\n",
       " 'poodle',\n",
       " 'bernard',\n",
       " 'poodle',\n",
       " 'bluetick',\n",
       " 'dog',\n",
       " 'hound',\n",
       " 'pomeranian',\n",
       " 'terrier',\n",
       " 'malamute',\n",
       " 'airedale',\n",
       " 'papillon',\n",
       " 'redbone',\n",
       " 'hound',\n",
       " 'komondor',\n",
       " 'otterhound',\n",
       " 'kuvasz',\n",
       " 'komondor',\n",
       " 'redbone',\n",
       " 'newfoundland',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'lhasa',\n",
       " 'terrier',\n",
       " 'kelpie',\n",
       " 'dingo',\n",
       " 'hound',\n",
       " 'bloodhound',\n",
       " 'basset',\n",
       " 'redbone',\n",
       " 'hairless',\n",
       " 'samoyed',\n",
       " 'hairless',\n",
       " 'collie',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'samoyed',\n",
       " 'bulldog',\n",
       " 'poodle',\n",
       " 'spaniel',\n",
       " 'flandres',\n",
       " 'leonberg',\n",
       " 'mastiff',\n",
       " 'terrier',\n",
       " 'dinmont',\n",
       " 'collie',\n",
       " 'cardigan',\n",
       " 'briard',\n",
       " 'sheepdog',\n",
       " 'retriever',\n",
       " 'pomeranian',\n",
       " 'spaniel',\n",
       " 'dog',\n",
       " 'shepherd',\n",
       " 'hound',\n",
       " 'keeshond',\n",
       " 'spaniel',\n",
       " 'collie',\n",
       " 'mastiff',\n",
       " 'terrier',\n",
       " 'basenji',\n",
       " 'retriever',\n",
       " 'appenzeller',\n",
       " 'greyhound',\n",
       " 'vizsla',\n",
       " 'springer',\n",
       " 'bloodhound',\n",
       " 'poodle',\n",
       " 'malamute',\n",
       " 'collie',\n",
       " 'bull',\n",
       " 'kuvasz',\n",
       " 'wolfhound',\n",
       " 'greyhound',\n",
       " 'setter',\n",
       " 'spaniel',\n",
       " 'papillon',\n",
       " 'spaniel',\n",
       " 'basenji',\n",
       " 'deerhound',\n",
       " 'dane',\n",
       " 'kuvasz',\n",
       " 'dog',\n",
       " 'beagle',\n",
       " 'spaniel',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'entlebucher',\n",
       " 'deerhound',\n",
       " 'retriever',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'newfoundland',\n",
       " 'spaniel',\n",
       " 'wolfhound',\n",
       " 'hound',\n",
       " 'briard',\n",
       " 'setter',\n",
       " 'hairless',\n",
       " 'otterhound',\n",
       " 'malamute',\n",
       " 'retriever',\n",
       " 'setter',\n",
       " 'chow',\n",
       " 'kuvasz',\n",
       " 'keeshond',\n",
       " 'groenendael',\n",
       " 'basenji',\n",
       " 'dog',\n",
       " 'shih-tzu',\n",
       " 'springer',\n",
       " 'vizsla',\n",
       " 'sheepdog',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'dhole',\n",
       " 'schipperke',\n",
       " 'retriever',\n",
       " 'husky',\n",
       " 'retriever',\n",
       " 'cairn',\n",
       " 'terrier',\n",
       " 'poodle',\n",
       " 'samoyed',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'spaniel',\n",
       " 'spaniel',\n",
       " 'spaniel',\n",
       " 'clumber',\n",
       " 'pinscher',\n",
       " 'pointer',\n",
       " 'bloodhound',\n",
       " 'pekinese',\n",
       " 'flandres',\n",
       " 'griffon',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'basset',\n",
       " 'spaniel',\n",
       " 'dinmont',\n",
       " 'hound',\n",
       " 'airedale',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'entlebucher',\n",
       " 'dingo',\n",
       " 'husky',\n",
       " 'retriever',\n",
       " 'chow',\n",
       " 'setter',\n",
       " 'pembroke',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'entlebucher',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'bluetick',\n",
       " 'cairn',\n",
       " 'borzoi',\n",
       " 'samoyed',\n",
       " 'schnauzer',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'hound',\n",
       " 'terrier',\n",
       " 'bullterrier',\n",
       " 'briard',\n",
       " 'husky',\n",
       " 'terrier',\n",
       " 'setter',\n",
       " 'leonberg',\n",
       " 'pyrenees',\n",
       " 'boxer',\n",
       " 'pug',\n",
       " 'setter',\n",
       " 'poodle',\n",
       " 'sheepdog',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'doberman',\n",
       " 'groenendael',\n",
       " 'elkhound',\n",
       " 'basset',\n",
       " 'entlebucher',\n",
       " 'malinois',\n",
       " 'bluetick',\n",
       " 'airedale',\n",
       " 'schipperke',\n",
       " 'griffon',\n",
       " 'bloodhound',\n",
       " 'poodle',\n",
       " 'retriever',\n",
       " 'beagle',\n",
       " 'mastiff',\n",
       " 'deerhound',\n",
       " 'terrier',\n",
       " 'poodle',\n",
       " 'spaniel',\n",
       " 'spaniel',\n",
       " 'schnauzer',\n",
       " 'hound',\n",
       " 'dingo',\n",
       " 'malamute',\n",
       " 'dog',\n",
       " 'beagle',\n",
       " 'terrier',\n",
       " 'beagle',\n",
       " 'foxhound',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'flandres',\n",
       " 'leonberg',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'shih-tzu',\n",
       " 'hound',\n",
       " 'basset',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'entlebucher',\n",
       " 'keeshond',\n",
       " 'retriever',\n",
       " 'shih-tzu',\n",
       " 'keeshond',\n",
       " 'poodle',\n",
       " 'spaniel',\n",
       " 'chihuahua',\n",
       " 'wolfhound',\n",
       " 'terrier',\n",
       " 'chihuahua',\n",
       " 'terrier',\n",
       " 'cardigan',\n",
       " 'pug',\n",
       " 'terrier',\n",
       " 'saluki',\n",
       " 'elkhound',\n",
       " 'mastiff',\n",
       " 'schnauzer',\n",
       " 'ridgeback',\n",
       " 'pinscher',\n",
       " 'ridgeback',\n",
       " 'pembroke',\n",
       " 'samoyed',\n",
       " 'terrier',\n",
       " 'appenzeller',\n",
       " 'spaniel',\n",
       " 'retriever',\n",
       " 'spaniel',\n",
       " 'deerhound',\n",
       " 'retriever',\n",
       " 'vizsla',\n",
       " 'setter',\n",
       " 'affenpinscher',\n",
       " 'terrier',\n",
       " 'bluetick',\n",
       " 'husky',\n",
       " 'basenji',\n",
       " 'terrier',\n",
       " 'pembroke',\n",
       " 'dog',\n",
       " 'spaniel',\n",
       " 'cardigan',\n",
       " 'spaniel',\n",
       " 'redbone',\n",
       " 'flandres',\n",
       " 'elkhound',\n",
       " 'retriever',\n",
       " 'affenpinscher',\n",
       " 'dhole',\n",
       " 'bull',\n",
       " 'newfoundland',\n",
       " 'dane',\n",
       " 'terrier',\n",
       " 'pug',\n",
       " 'retriever',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'bullterrier',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'pyrenees',\n",
       " 'spaniel',\n",
       " 'basset',\n",
       " 'briard',\n",
       " 'whippet',\n",
       " 'affenpinscher',\n",
       " 'dinmont',\n",
       " 'retriever',\n",
       " 'samoyed',\n",
       " 'dog',\n",
       " 'flandres',\n",
       " 'hound',\n",
       " 'malamute',\n",
       " 'bullterrier',\n",
       " 'dog',\n",
       " 'schipperke',\n",
       " 'poodle',\n",
       " 'malinois',\n",
       " 'setter',\n",
       " 'schnauzer',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'bloodhound',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'weimaraner',\n",
       " 'bull',\n",
       " 'rottweiler',\n",
       " 'saluki',\n",
       " 'dingo',\n",
       " 'bloodhound',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'affenpinscher',\n",
       " 'redbone',\n",
       " 'samoyed',\n",
       " 'retriever',\n",
       " 'dog',\n",
       " 'poodle',\n",
       " 'sheepdog',\n",
       " 'setter',\n",
       " 'terrier',\n",
       " 'rottweiler',\n",
       " 'terrier',\n",
       " 'clumber',\n",
       " 'pug',\n",
       " 'basenji',\n",
       " 'redbone',\n",
       " 'beagle',\n",
       " 'vizsla',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'setter',\n",
       " 'basset',\n",
       " 'papillon',\n",
       " 'dog',\n",
       " 'poodle',\n",
       " 'hound',\n",
       " 'spaniel',\n",
       " 'basenji',\n",
       " 'lhasa',\n",
       " 'clumber',\n",
       " 'terrier',\n",
       " 'basenji',\n",
       " 'pyrenees',\n",
       " 'pekinese',\n",
       " 'terrier',\n",
       " 'pointer',\n",
       " 'terrier',\n",
       " 'saluki',\n",
       " 'terrier',\n",
       " 'bulldog',\n",
       " 'bullterrier',\n",
       " 'collie',\n",
       " 'vizsla',\n",
       " 'komondor',\n",
       " 'deerhound',\n",
       " 'collie',\n",
       " 'otterhound',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'pointer',\n",
       " 'dog',\n",
       " 'retriever',\n",
       " 'hairless',\n",
       " 'terrier',\n",
       " 'shepherd',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'retriever',\n",
       " 'elkhound',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'deerhound',\n",
       " 'hound',\n",
       " 'schnauzer',\n",
       " 'shih-tzu',\n",
       " 'retriever',\n",
       " 'malamute',\n",
       " 'flandres',\n",
       " 'spaniel',\n",
       " 'malinois',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'foxhound',\n",
       " 'groenendael',\n",
       " 'terrier',\n",
       " 'whippet',\n",
       " 'doberman',\n",
       " 'pekinese',\n",
       " 'sheepdog',\n",
       " 'kelpie',\n",
       " 'malinois',\n",
       " 'pomeranian',\n",
       " 'terrier',\n",
       " 'schipperke',\n",
       " 'keeshond',\n",
       " 'flandres',\n",
       " 'leonberg',\n",
       " 'bull',\n",
       " 'pyrenees',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'pinscher',\n",
       " 'airedale',\n",
       " 'dinmont',\n",
       " 'saluki',\n",
       " 'flandres',\n",
       " 'dog',\n",
       " 'retriever',\n",
       " 'retriever',\n",
       " 'spaniel',\n",
       " 'beagle',\n",
       " 'schnauzer',\n",
       " 'chow',\n",
       " 'dane',\n",
       " 'husky',\n",
       " 'shih-tzu',\n",
       " 'doberman',\n",
       " 'lhasa',\n",
       " 'basenji',\n",
       " 'bull',\n",
       " 'basset',\n",
       " 'entlebucher',\n",
       " 'papillon',\n",
       " 'terrier',\n",
       " 'chihuahua',\n",
       " 'schnauzer',\n",
       " 'coonhound',\n",
       " 'kuvasz',\n",
       " 'terrier',\n",
       " 'basenji',\n",
       " 'whippet',\n",
       " 'terrier',\n",
       " 'greyhound',\n",
       " 'terrier',\n",
       " 'boxer',\n",
       " 'malamute',\n",
       " 'spaniel',\n",
       " 'keeshond',\n",
       " 'airedale',\n",
       " 'schnauzer',\n",
       " 'terrier',\n",
       " 'saluki',\n",
       " 'mastiff',\n",
       " 'boxer',\n",
       " 'hairless',\n",
       " 'setter',\n",
       " 'bernard',\n",
       " 'pyrenees',\n",
       " 'keeshond',\n",
       " 'keeshond',\n",
       " 'retriever',\n",
       " 'chihuahua',\n",
       " 'dog',\n",
       " 'griffon',\n",
       " 'collie',\n",
       " 'groenendael',\n",
       " 'schnauzer',\n",
       " 'sheepdog',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'retriever',\n",
       " 'pug',\n",
       " 'elkhound',\n",
       " 'terrier',\n",
       " 'poodle',\n",
       " 'terrier',\n",
       " 'vizsla',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'dog',\n",
       " 'griffon',\n",
       " 'pembroke',\n",
       " 'setter',\n",
       " 'shih-tzu',\n",
       " 'retriever',\n",
       " 'setter',\n",
       " 'wolfhound',\n",
       " 'bloodhound',\n",
       " 'beagle',\n",
       " 'hound',\n",
       " 'redbone',\n",
       " 'pomeranian',\n",
       " 'newfoundland',\n",
       " 'wolfhound',\n",
       " 'dog',\n",
       " 'poodle',\n",
       " 'lhasa',\n",
       " 'hairless',\n",
       " 'cardigan',\n",
       " 'pinscher',\n",
       " 'bernard',\n",
       " 'coonhound',\n",
       " 'saluki',\n",
       " 'husky',\n",
       " 'dhole',\n",
       " 'weimaraner',\n",
       " 'chihuahua',\n",
       " 'husky',\n",
       " 'spaniel',\n",
       " 'deerhound',\n",
       " 'retriever',\n",
       " 'collie',\n",
       " 'dog',\n",
       " 'mastiff',\n",
       " 'sheepdog',\n",
       " 'husky',\n",
       " 'hound',\n",
       " 'saluki',\n",
       " 'pembroke',\n",
       " 'groenendael',\n",
       " 'bull',\n",
       " 'kuvasz',\n",
       " 'schnauzer',\n",
       " 'doberman',\n",
       " 'malamute',\n",
       " 'poodle',\n",
       " 'wolfhound',\n",
       " 'poodle',\n",
       " 'dog',\n",
       " 'terrier',\n",
       " 'pointer',\n",
       " 'malamute',\n",
       " 'terrier',\n",
       " 'lhasa',\n",
       " 'foxhound',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'terrier',\n",
       " 'sheepdog',\n",
       " 'pointer',\n",
       " 'foxhound',\n",
       " 'dingo',\n",
       " 'schnauzer',\n",
       " 'bull',\n",
       " 'schnauzer',\n",
       " 'terrier',\n",
       " 'terrier',\n",
       " 'spaniel',\n",
       " 'samoyed',\n",
       " 'bullterrier',\n",
       " 'dinmont',\n",
       " 'entlebucher',\n",
       " 'saluki',\n",
       " 'lhasa',\n",
       " 'appenzeller',\n",
       " 'retriever',\n",
       " 'sheepdog',\n",
       " 'retriever',\n",
       " 'cardigan',\n",
       " 'cairn',\n",
       " 'terrier',\n",
       " 'flandres',\n",
       " 'terrier',\n",
       " 'hairless',\n",
       " 'clumber',\n",
       " 'poodle',\n",
       " 'terrier',\n",
       " 'whippet',\n",
       " 'collie',\n",
       " 'chihuahua',\n",
       " 'pomeranian',\n",
       " 'samoyed',\n",
       " 'setter',\n",
       " 'spaniel',\n",
       " 'pomeranian',\n",
       " 'pembroke',\n",
       " 'mastiff',\n",
       " 'terrier',\n",
       " 'boxer',\n",
       " 'dhole',\n",
       " 'terrier',\n",
       " 'cairn',\n",
       " 'setter',\n",
       " 'retriever',\n",
       " 'terrier',\n",
       " 'malamute',\n",
       " 'keeshond',\n",
       " 'schnauzer',\n",
       " 'newfoundland',\n",
       " 'terrier',\n",
       " 'pekinese',\n",
       " 'schipperke',\n",
       " 'mastiff',\n",
       " 'wolfhound',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_instances = [i[len(i)-1] for i in breeds]\n",
    "breed_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_instances_series = pd.Series(breed_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "terrier        1542\n",
       "spaniel         589\n",
       "dog             465\n",
       "retriever       378\n",
       "hound           276\n",
       "setter          252\n",
       "poodle          238\n",
       "schnauzer       219\n",
       "sheepdog        163\n",
       "collie          159\n",
       "mastiff         144\n",
       "deerhound       126\n",
       "entlebucher     115\n",
       "shih-tzu        112\n",
       "pyrenees        111\n",
       "pomeranian      111\n",
       "basenji         110\n",
       "samoyed         109\n",
       "airedale        107\n",
       "cairn           106\n",
       "leonberg        106\n",
       "beagle          105\n",
       "pinscher        102\n",
       "wolfhound       101\n",
       "saluki           99\n",
       "papillon         96\n",
       "elkhound         95\n",
       "whippet          95\n",
       "husky            95\n",
       "pug              94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_instances_series.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malamute         81\n",
       "keeshond         81\n",
       "clumber          80\n",
       "dingo            80\n",
       "affenpinscher    80\n",
       "hairless         80\n",
       "bullterrier      79\n",
       "appenzeller      78\n",
       "coonhound        77\n",
       "dhole            76\n",
       "cardigan         76\n",
       "rottweiler       76\n",
       "boxer            75\n",
       "borzoi           75\n",
       "springer         75\n",
       "pointer          75\n",
       "dane             75\n",
       "pekinese         75\n",
       "doberman         74\n",
       "malinois         73\n",
       "redbone          72\n",
       "kuvasz           71\n",
       "chihuahua        71\n",
       "vizsla           70\n",
       "bulldog          70\n",
       "shepherd         69\n",
       "otterhound       69\n",
       "griffon          67\n",
       "komondor         67\n",
       "briard           66\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_instances_series.value_counts().tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "terrier        18\n",
       "spaniel         7\n",
       "dog             5\n",
       "retriever       5\n",
       "poodle          3\n",
       "setter          3\n",
       "hound           3\n",
       "schnauzer       3\n",
       "mastiff         2\n",
       "sheepdog        2\n",
       "collie          2\n",
       "griffon         1\n",
       "chow            1\n",
       "bullterrier     1\n",
       "wolfhound       1\n",
       "pinscher        1\n",
       "bernard         1\n",
       "bull            1\n",
       "clumber         1\n",
       "greyhound       1\n",
       "foxhound        1\n",
       "lhasa           1\n",
       "hairless        1\n",
       "leonberg        1\n",
       "airedale        1\n",
       "cardigan        1\n",
       "dinmont         1\n",
       "husky           1\n",
       "pomeranian      1\n",
       "springer        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breeds_unique = data['breed'].unique()\n",
    "breeds_unique\n",
    "\n",
    "for i in range(len(breeds_unique)):\n",
    "    j = breeds_unique[i].split('_')\n",
    "    breeds_unique[i] = j[len(j)-1]\n",
    "    \n",
    "pd.Series(breeds_unique).value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['boston_bull', 'dingo', 'pekinese', 'bluetick', 'golden_retriever',\n",
       "       'bedlington_terrier', 'borzoi', 'basenji', 'scottish_deerhound',\n",
       "       'shetland_sheepdog', 'walker_hound', 'maltese_dog',\n",
       "       'norfolk_terrier', 'african_hunting_dog',\n",
       "       'wire-haired_fox_terrier', 'redbone', 'lakeland_terrier', 'boxer',\n",
       "       'doberman', 'otterhound', 'standard_schnauzer',\n",
       "       'irish_water_spaniel', 'black-and-tan_coonhound', 'cairn',\n",
       "       'affenpinscher', 'labrador_retriever', 'ibizan_hound',\n",
       "       'english_setter', 'weimaraner', 'giant_schnauzer', 'groenendael',\n",
       "       'dhole', 'toy_poodle', 'border_terrier', 'tibetan_terrier',\n",
       "       'norwegian_elkhound', 'shih-tzu', 'irish_terrier', 'kuvasz',\n",
       "       'german_shepherd', 'greater_swiss_mountain_dog', 'basset',\n",
       "       'australian_terrier', 'schipperke', 'rhodesian_ridgeback',\n",
       "       'irish_setter', 'appenzeller', 'bloodhound', 'samoyed',\n",
       "       'miniature_schnauzer', 'brittany_spaniel', 'kelpie', 'papillon',\n",
       "       'border_collie', 'entlebucher', 'collie', 'malamute',\n",
       "       'welsh_springer_spaniel', 'chihuahua', 'saluki', 'pug', 'malinois',\n",
       "       'komondor', 'airedale', 'leonberg', 'mexican_hairless',\n",
       "       'bull_mastiff', 'bernese_mountain_dog',\n",
       "       'american_staffordshire_terrier', 'lhasa', 'cardigan',\n",
       "       'italian_greyhound', 'clumber', 'scotch_terrier', 'afghan_hound',\n",
       "       'old_english_sheepdog', 'saint_bernard', 'miniature_pinscher',\n",
       "       'eskimo_dog', 'irish_wolfhound', 'brabancon_griffon',\n",
       "       'toy_terrier', 'chow', 'flat-coated_retriever', 'norwich_terrier',\n",
       "       'soft-coated_wheaten_terrier', 'staffordshire_bullterrier',\n",
       "       'english_foxhound', 'gordon_setter', 'siberian_husky',\n",
       "       'newfoundland', 'briard', 'chesapeake_bay_retriever',\n",
       "       'dandie_dinmont', 'great_pyrenees', 'beagle', 'vizsla',\n",
       "       'west_highland_white_terrier', 'kerry_blue_terrier', 'whippet',\n",
       "       'sealyham_terrier', 'standard_poodle', 'keeshond',\n",
       "       'japanese_spaniel', 'miniature_poodle', 'pomeranian',\n",
       "       'curly-coated_retriever', 'yorkshire_terrier', 'pembroke',\n",
       "       'great_dane', 'blenheim_spaniel', 'silky_terrier',\n",
       "       'sussex_spaniel', 'german_short-haired_pointer', 'french_bulldog',\n",
       "       'bouvier_des_flandres', 'tibetan_mastiff', 'english_springer',\n",
       "       'cocker_spaniel', 'rottweiler'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['breed'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Preprocessing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7988\\1418028161.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  toRemove = toRemove.append(data[data['breed'] == i])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>010d65bd29d246aea53d9849da142ccf</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0755a940eac9a9b8cf0328b4be062096</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>07d7cfbdbd3682cae50902b53c798028</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0b3d3120a62c2bc280f589d473041d06</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9632</th>\n",
       "      <td>f25a4184e33741e745175fd1d7c6d172</td>\n",
       "      <td>rottweiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9823</th>\n",
       "      <td>f72df3c3daa677aa76027366ad55721f</td>\n",
       "      <td>rottweiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>f8271e8e638b9bab6a0d3e164874dd53</td>\n",
       "      <td>rottweiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>fab782d25875a7cf5298cd2e2aa01cd5</td>\n",
       "      <td>rottweiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>fc77bf555c892344771a2c6714e72659</td>\n",
       "      <td>rottweiler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6635 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        breed\n",
       "0      000bec180eb18c7604dcecc8fe0dba07  boston_bull\n",
       "38     010d65bd29d246aea53d9849da142ccf  boston_bull\n",
       "304    0755a940eac9a9b8cf0328b4be062096  boston_bull\n",
       "324    07d7cfbdbd3682cae50902b53c798028  boston_bull\n",
       "471    0b3d3120a62c2bc280f589d473041d06  boston_bull\n",
       "...                                 ...          ...\n",
       "9632   f25a4184e33741e745175fd1d7c6d172   rottweiler\n",
       "9823   f72df3c3daa677aa76027366ad55721f   rottweiler\n",
       "9870   f8271e8e638b9bab6a0d3e164874dd53   rottweiler\n",
       "9997   fab782d25875a7cf5298cd2e2aa01cd5   rottweiler\n",
       "10078  fc77bf555c892344771a2c6714e72659   rottweiler\n",
       "\n",
       "[6635 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toRemove = pd.DataFrame()\n",
    "for i in data['breed'].unique():\n",
    "    length = len(data[data['breed'] == i])\n",
    "    if length < 90:\n",
    "        toRemove = toRemove.append(data[data['breed'] == i])\n",
    "toRemove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>basenji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>scottish_deerhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00693b8bc2470375cc744a6391d397ec</td>\n",
       "      <td>maltese_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007ff9a78eba2aebb558afea3a51c469</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00bee065dcec471f26394855c5c2f3de</td>\n",
       "      <td>cairn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10212</th>\n",
       "      <td>ffc532991d3cd7880d27a449ed1c4770</td>\n",
       "      <td>tibetan_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10215</th>\n",
       "      <td>ffcde16e7da0872c357fbc7e2168c05f</td>\n",
       "      <td>airedale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>ffcffab7e4beef9a9b8076ef2ca51909</td>\n",
       "      <td>samoyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>ffe2ca6c940cddfee68fa3cc6c63213f</td>\n",
       "      <td>airedale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10220</th>\n",
       "      <td>ffe5f6d8e2bff356e9482a80a6e29aac</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3587 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id               breed\n",
       "8      003df8b8a8b05244b1d920bb6cf451f9             basenji\n",
       "9      0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound\n",
       "12     00693b8bc2470375cc744a6391d397ec         maltese_dog\n",
       "18     007ff9a78eba2aebb558afea3a51c469    lakeland_terrier\n",
       "29     00bee065dcec471f26394855c5c2f3de               cairn\n",
       "...                                 ...                 ...\n",
       "10212  ffc532991d3cd7880d27a449ed1c4770     tibetan_terrier\n",
       "10215  ffcde16e7da0872c357fbc7e2168c05f            airedale\n",
       "10216  ffcffab7e4beef9a9b8076ef2ca51909             samoyed\n",
       "10219  ffe2ca6c940cddfee68fa3cc6c63213f            airedale\n",
       "10220  ffe5f6d8e2bff356e9482a80a6e29aac  miniature_pinscher\n",
       "\n",
       "[3587 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = data.drop(labels=toRemove.index, axis=0)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>check new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>basenji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>scottish_deerhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00693b8bc2470375cc744a6391d397ec</td>\n",
       "      <td>maltese_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007ff9a78eba2aebb558afea3a51c469</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00bee065dcec471f26394855c5c2f3de</td>\n",
       "      <td>cairn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10212</th>\n",
       "      <td>ffc532991d3cd7880d27a449ed1c4770</td>\n",
       "      <td>tibetan_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10215</th>\n",
       "      <td>ffcde16e7da0872c357fbc7e2168c05f</td>\n",
       "      <td>airedale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>ffcffab7e4beef9a9b8076ef2ca51909</td>\n",
       "      <td>samoyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>ffe2ca6c940cddfee68fa3cc6c63213f</td>\n",
       "      <td>airedale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10220</th>\n",
       "      <td>ffe5f6d8e2bff356e9482a80a6e29aac</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3587 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id               breed\n",
       "8      003df8b8a8b05244b1d920bb6cf451f9             basenji\n",
       "9      0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound\n",
       "12     00693b8bc2470375cc744a6391d397ec         maltese_dog\n",
       "18     007ff9a78eba2aebb558afea3a51c469    lakeland_terrier\n",
       "29     00bee065dcec471f26394855c5c2f3de               cairn\n",
       "...                                 ...                 ...\n",
       "10212  ffc532991d3cd7880d27a449ed1c4770     tibetan_terrier\n",
       "10215  ffcde16e7da0872c357fbc7e2168c05f            airedale\n",
       "10216  ffcffab7e4beef9a9b8076ef2ca51909             samoyed\n",
       "10219  ffe2ca6c940cddfee68fa3cc6c63213f            airedale\n",
       "10220  ffe5f6d8e2bff356e9482a80a6e29aac  miniature_pinscher\n",
       "\n",
       "[3587 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = new_data.groupby('breed')['id'].count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breed\n",
       "silky_terrier            90\n",
       "lhasa                    90\n",
       "ibizan_hound             91\n",
       "newfoundland             91\n",
       "border_terrier           91\n",
       "pembroke                 92\n",
       "italian_greyhound        92\n",
       "chow                     93\n",
       "pug                      94\n",
       "norwegian_elkhound       95\n",
       "whippet                  95\n",
       "siberian_husky           95\n",
       "papillon                 96\n",
       "saluki                   99\n",
       "lakeland_terrier         99\n",
       "irish_wolfhound         101\n",
       "australian_terrier      102\n",
       "blenheim_spaniel        102\n",
       "miniature_pinscher      102\n",
       "beagle                  105\n",
       "japanese_spaniel        105\n",
       "leonberg                106\n",
       "cairn                   106\n",
       "tibetan_terrier         107\n",
       "airedale                107\n",
       "samoyed                 109\n",
       "basenji                 110\n",
       "great_pyrenees          111\n",
       "pomeranian              111\n",
       "shih-tzu                112\n",
       "bernese_mountain_dog    114\n",
       "entlebucher             115\n",
       "afghan_hound            116\n",
       "maltese_dog             117\n",
       "scottish_deerhound      126\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_breeds = 35\n",
    "im_size = 224\n",
    "batch_size = 64\n",
    "encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['img_file'] = new_data['id'].apply(lambda x: x + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "      <th>img_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>basenji</td>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>scottish_deerhound</td>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00693b8bc2470375cc744a6391d397ec</td>\n",
       "      <td>maltese_dog</td>\n",
       "      <td>00693b8bc2470375cc744a6391d397ec.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007ff9a78eba2aebb558afea3a51c469</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "      <td>007ff9a78eba2aebb558afea3a51c469.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00bee065dcec471f26394855c5c2f3de</td>\n",
       "      <td>cairn</td>\n",
       "      <td>00bee065dcec471f26394855c5c2f3de.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10212</th>\n",
       "      <td>ffc532991d3cd7880d27a449ed1c4770</td>\n",
       "      <td>tibetan_terrier</td>\n",
       "      <td>ffc532991d3cd7880d27a449ed1c4770.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10215</th>\n",
       "      <td>ffcde16e7da0872c357fbc7e2168c05f</td>\n",
       "      <td>airedale</td>\n",
       "      <td>ffcde16e7da0872c357fbc7e2168c05f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>ffcffab7e4beef9a9b8076ef2ca51909</td>\n",
       "      <td>samoyed</td>\n",
       "      <td>ffcffab7e4beef9a9b8076ef2ca51909.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>ffe2ca6c940cddfee68fa3cc6c63213f</td>\n",
       "      <td>airedale</td>\n",
       "      <td>ffe2ca6c940cddfee68fa3cc6c63213f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10220</th>\n",
       "      <td>ffe5f6d8e2bff356e9482a80a6e29aac</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>ffe5f6d8e2bff356e9482a80a6e29aac.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3587 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id               breed  \\\n",
       "8      003df8b8a8b05244b1d920bb6cf451f9             basenji   \n",
       "9      0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound   \n",
       "12     00693b8bc2470375cc744a6391d397ec         maltese_dog   \n",
       "18     007ff9a78eba2aebb558afea3a51c469    lakeland_terrier   \n",
       "29     00bee065dcec471f26394855c5c2f3de               cairn   \n",
       "...                                 ...                 ...   \n",
       "10212  ffc532991d3cd7880d27a449ed1c4770     tibetan_terrier   \n",
       "10215  ffcde16e7da0872c357fbc7e2168c05f            airedale   \n",
       "10216  ffcffab7e4beef9a9b8076ef2ca51909             samoyed   \n",
       "10219  ffe2ca6c940cddfee68fa3cc6c63213f            airedale   \n",
       "10220  ffe5f6d8e2bff356e9482a80a6e29aac  miniature_pinscher   \n",
       "\n",
       "                                   img_file  \n",
       "8      003df8b8a8b05244b1d920bb6cf451f9.jpg  \n",
       "9      0042188c895a2f14ef64a918ed9c7b64.jpg  \n",
       "12     00693b8bc2470375cc744a6391d397ec.jpg  \n",
       "18     007ff9a78eba2aebb558afea3a51c469.jpg  \n",
       "29     00bee065dcec471f26394855c5c2f3de.jpg  \n",
       "...                                     ...  \n",
       "10212  ffc532991d3cd7880d27a449ed1c4770.jpg  \n",
       "10215  ffcde16e7da0872c357fbc7e2168c05f.jpg  \n",
       "10216  ffcffab7e4beef9a9b8076ef2ca51909.jpg  \n",
       "10219  ffe2ca6c940cddfee68fa3cc6c63213f.jpg  \n",
       "10220  ffe5f6d8e2bff356e9482a80a6e29aac.jpg  \n",
       "\n",
       "[3587 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Open images and pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(number of dataset records, image size , image size, 3 for rgb channel ayer)\n",
    "#this will be input for model\n",
    "train_x = np.zeros((len(new_data), im_size, im_size, 3), dtype='float32')\n",
    "train_file = 'train/' \n",
    "#iterate over img_file column of our dataset\n",
    "for i, img_id in enumerate(new_data['img_file']):\n",
    "  #read the image file and convert into numeric format\n",
    "  #resize all images to one dimension i.e. 224x224\n",
    "  #we will get array with the shape of\n",
    "  # (224,224,3) where 3 is the RGB channels layers\n",
    "    img = cv2.resize(cv2.imread(train_file+img_id,cv2.IMREAD_COLOR),((im_size,im_size)))\n",
    "  #scale array into the range of -1 to 1.\n",
    "  #preprocess the array and expand its dimension on the axis 0 \n",
    "    img_array = preprocess_input(np.expand_dims(np.array(img[...,::-1].astype(np.float32)).copy(), axis=0))\n",
    "  #update the train_x variable with new element\n",
    "    train_x[i] = img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will be the target for the model.\n",
    "#convert breed names into numerical format\n",
    "train_y = encoder.fit_transform(new_data[\"breed\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 29, 19, ..., 28,  1, 20])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: ( (2869, 224, 224, 3) , (2869,) )\n",
      "test data: ( (718, 224, 224, 3) , (718,) )\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_x,train_y,test_size=0.2,random_state=42,stratify=train_y)\n",
    "print(\"training data: (\",x_train.shape, \",\",y_train.shape,\")\")\n",
    "print(\"test data: (\",x_test.shape, \",\",y_test.shape,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Splitting into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: ( (1721, 224, 224, 3) , (1721,) )\n",
      "test data: ( (1148, 224, 224, 3) , (1148,) )\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.4,random_state=42,stratify=y_train)\n",
    "print(\"training data: (\",x_train.shape, \",\",y_train.shape,\")\")\n",
    "print(\"test data: (\",x_val.shape, \",\",y_val.shape,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=45,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.25,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    " \n",
    "#generate images for training sets \n",
    "train_generator = train_datagen.flow(x_train, \n",
    "                                     y_train, \n",
    "                                     batch_size=batch_size)\n",
    " \n",
    "#same process for Testing sets also by declaring the instance\n",
    "test_datagen = ImageDataGenerator()\n",
    " \n",
    "test_generator = test_datagen.flow(x_val, \n",
    "                                     y_val, \n",
    "                                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent overfitting the model we will use an early stopping callback and it will monitor the validation loss if it is still decreasing, we set patience to 5 which corresponds to the # of epochs that that the model has no improvement which will stop training the model and with restore_best_weights=true we restore the weights of the epoch with the best value of the monitored quantity which is val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback= callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the model using ResNet50V2 with input shape of our image array\n",
    "#weights for our network will be from of imagenet dataset\n",
    "\n",
    "resnet = ResNet50V2(input_shape = [im_size,im_size,3], weights='imagenet', include_top=False)\n",
    "#freeze all trainable layers and train only top layers \n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    " \n",
    "    #add global average pooling layer and Batch Normalization layer\n",
    "x = resnet.output\n",
    "x = BatchNormalization()(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "#add fully connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 2048)   8192        post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 35)           35875       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,707,043\n",
      "Trainable params: 2,138,147\n",
      "Non-trainable params: 23,568,896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#add output layer having the shape equal to number of breeds\n",
    "predictions = Dense(num_breeds, activation='softmax')(x)\n",
    " \n",
    "#create model class with inputs and outputs\n",
    "model = Model(inputs=resnet.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 96s 4s/step - loss: 1.9893 - accuracy: 0.4593 - val_loss: 0.6312 - val_accuracy: 0.8061\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 1.0739 - accuracy: 0.6868 - val_loss: 0.4663 - val_accuracy: 0.8557\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.7966 - accuracy: 0.7538 - val_loss: 0.4569 - val_accuracy: 0.8511\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.7294 - accuracy: 0.7803 - val_loss: 0.4213 - val_accuracy: 0.8667\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.6636 - accuracy: 0.7864 - val_loss: 0.4235 - val_accuracy: 0.8649\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.6062 - accuracy: 0.7948 - val_loss: 0.4134 - val_accuracy: 0.8621\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.5567 - accuracy: 0.8189 - val_loss: 0.4130 - val_accuracy: 0.8631\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.5122 - accuracy: 0.8196 - val_loss: 0.4416 - val_accuracy: 0.8631\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.4867 - accuracy: 0.8377 - val_loss: 0.4251 - val_accuracy: 0.8640\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.5027 - accuracy: 0.8371 - val_loss: 0.4472 - val_accuracy: 0.8594\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 99s 4s/step - loss: 0.4556 - accuracy: 0.8533 - val_loss: 0.4454 - val_accuracy: 0.8658\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.4692 - accuracy: 0.8365 - val_loss: 0.4337 - val_accuracy: 0.8695\n"
     ]
    }
   ],
   "source": [
    "#epochs for model training \n",
    "epochs = 50\n",
    "\n",
    " \n",
    "#using RMSprop optimizer to compile or build the model\n",
    "optimizer = RMSprop()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])\n",
    " \n",
    "#fit the training generator data and train the model\n",
    "hist = model.fit(train_generator,\n",
    "                 steps_per_epoch= x_train.shape[0] // batch_size,\n",
    "                 epochs= epochs,callbacks=[callback],\n",
    "                 validation_data= test_generator,\n",
    "                 validation_steps= x_val.shape[0] // batch_size)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> predictions on test data </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(x_test)\n",
    "probs = np.argmax(predictions, axis=1)\n",
    "num_correct = (probs == y_test).sum()\n",
    "accuracy = num_correct/len(y_test)\n",
    "print('{:.4f}'.format(accuracy.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Image loading and preprocessing for  InceptionResNetV2 and InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>since the size of images in resnet is different from what is required in the next 2 models we need to do data pre-processing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 299 #image size needed for both inceptionRESNetV2 and inceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(number of dataset records, image size , image size, 3 for rgb channel ayer)\n",
    "#this will be input for model\n",
    "train_x = np.zeros((len(new_data), im_size, im_size, 3), dtype='float32')\n",
    "train_file = 'train/' \n",
    "#iterate over img_file column of our dataset\n",
    "for i, img_id in enumerate(new_data['img_file']):\n",
    "  #read the image file and convert into numeric format\n",
    "  #resize all images to one dimension i.e. 224x224\n",
    "  #we will get array with the shape of\n",
    "  # (224,224,3) where 3 is the RGB channels layers\n",
    "    img = cv2.resize(cv2.imread(train_file+img_id,cv2.IMREAD_COLOR),((im_size,im_size)))\n",
    "  #scale array into the range of -1 to 1.\n",
    "  #preprocess the array and expand its dimension on the axis 0 \n",
    "    img_array = preprocess_input(np.expand_dims(np.array(img[...,::-1].astype(np.float32)).copy(), axis=0))\n",
    "  #update the train_x variable with new element\n",
    "    train_x[i] = img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = encoder.fit_transform(new_data[\"breed\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: ( (2869, 299, 299, 3) , (2869,) )\n",
      "test data: ( (718, 299, 299, 3) , (718,) )\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_x,train_y,test_size=0.2,random_state=42,stratify=train_y)\n",
    "print(\"training data: (\",x_train.shape, \",\",y_train.shape,\")\")\n",
    "print(\"test data: (\",x_test.shape, \",\",y_test.shape,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split training into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: ( (1721, 299, 299, 3) , (1721,) )\n",
      "test data: ( (1148, 299, 299, 3) , (1148,) )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.4,random_state=42,stratify=y_train)\n",
    "print(\"training data: (\",x_train.shape, \",\",y_train.shape,\")\")\n",
    "print(\"test data: (\",x_val.shape, \",\",y_val.shape,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=45,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.25,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    " \n",
    "#generate images for training sets \n",
    "train_generator = train_datagen.flow(x_train, \n",
    "                                     y_train, \n",
    "                                     batch_size=batch_size)\n",
    " \n",
    "#same process for Testing sets also by declaring the instance\n",
    "test_datagen = ImageDataGenerator()\n",
    " \n",
    "test_generator = test_datagen.flow(x_val, \n",
    "                                     y_val, \n",
    "                                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>InceptionResNet V2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRnet = InceptionResNetV2(weights='imagenet', include_top=False, input_shape = [im_size,im_size,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 48)   13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 48)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 64)   27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 48)   13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 48)   13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 48)   144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 64)   27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 64)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 48)   13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 35, 35, 48)   144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 64)   27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 48)   13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 48)   144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 64)   27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 35, 35, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 64)   192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 48)   13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 35, 35, 48)   144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 64)   27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 35, 35, 64)   192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 48)   13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 35, 35, 48)   144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 64)   27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 35, 35, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 35, 35, 64)   192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 48)   13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 35, 35, 48)   144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 35, 35, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 32)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 64)   27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 48)   13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 35, 35, 48)   144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 35, 35, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 32)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 64)   27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 35, 35, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 35, 35, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 35, 35, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 35, 35, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 48)   13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 35, 35, 48)   144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 35, 35, 48)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 64)   27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 35, 35, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 35, 35, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 35, 35, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 35, 35, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 35, 35, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 35, 35, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 256)  589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 384)  884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 384)  1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 384)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 384)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 160)  143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 160)  480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 160)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 192)  215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 128)  384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 128)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 160)  143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 160)  480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 160)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 192)  215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 128)  384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 160)  143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 160)  480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 160)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 192)  215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 128)  384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 160)  143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 160)  480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 160)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 192)  215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 128)  384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 160)  143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 160)  480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 160)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 128)  384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 128)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 160)  143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 160)  480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 160)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 128)  384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 128)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 160)  143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 17, 17, 160)  480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 160)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 192)  215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 192)  576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 128)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 160)  143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 17, 17, 160)  480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 160)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 192)  215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 17, 17, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 128)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 160)  143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 17, 17, 160)  480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 160)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 192)  215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 17, 17, 192)  576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 128)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 17, 17, 160)  143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 17, 17, 160)  480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 17, 17, 160)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 17, 17, 192)  215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 17, 17, 192)  576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 17, 17, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 17, 17, 128)  384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 17, 17, 160)  143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 17, 17, 160)  480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 17, 17, 160)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 17, 17, 192)  215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 17, 17, 192)  576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 17, 17, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 17, 17, 128)  384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 17, 17, 160)  143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 17, 17, 160)  480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 17, 17, 160)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 17, 17, 192)  215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 160)  143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 17, 17, 160)  480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 160)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 192)  215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 160)  143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 17, 17, 160)  480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 160)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 192)  215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 17, 17, 128)  384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 128)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 160)  143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 17, 17, 160)  480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 17, 17, 192)  215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 17, 17, 128)  384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 17, 17, 128)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 17, 17, 160)  143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 17, 17, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 17, 17, 192)  576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 17, 17, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 17, 17, 128)  384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 17, 17, 128)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 17, 17, 160)  143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 17, 17, 128)  384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 17, 17, 128)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 17, 17, 160)  143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 17, 17, 128)  384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 17, 17, 128)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 17, 17, 160)  143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 17, 17, 192)  215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 17, 17, 128)  384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 128)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 160)  143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 17, 17, 160)  480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 160)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 17, 17, 192)  215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 17, 17, 256)  768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 17, 17, 256)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 288)  663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 17, 17, 256)  768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 17, 17, 256)  768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 17, 17, 288)  864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 256)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 17, 17, 256)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 288)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 8, 8, 384)    884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 288)    663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 320)    829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 8, 8, 384)    1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 8, 8, 288)    864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 8, 8, 320)    960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 8, 8, 384)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 8, 8, 288)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 8, 8, 320)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 224)    129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 224)    672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 224)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 256)    172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 256)    768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 256)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 224)    129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 224)    672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 224)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 256)    172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 256)    768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 256)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 224)    129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 8, 8, 224)    672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 224)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 256)    172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 192)    576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 8, 8, 256)    768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 256)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 224)    129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 8, 8, 224)    672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 224)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 256)    172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 8, 8, 192)    576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 8, 8, 256)    768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 256)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 224)    129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 8, 8, 224)    672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 224)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 256)    172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 8, 8, 256)    768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 256)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_185 (Conv2D)             (None, 8, 8, 224)    129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 224)    672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 224)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 256)    172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 192)    576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 256)    768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 256)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 8, 8, 224)    129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 8, 8, 224)    672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 224)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 8, 8, 256)    172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 8, 8, 256)    768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 256)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 8, 8, 224)    129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 8, 8, 224)    672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 224)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 8, 8, 256)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 8, 8, 192)    576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 8, 8, 256)    768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 256)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 8, 8, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 8, 8, 192)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 8, 8, 224)    129024      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 8, 8, 224)    672         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 8, 8, 224)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 8, 8, 256)    172032      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 8, 8, 192)    576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 8, 8, 256)    768         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 8, 8, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 8, 8, 256)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 8, 8, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 8, 8, 192)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 224)    129024      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 8, 8, 224)    672         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 8, 8, 224)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 256)    172032      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 8, 8, 192)    576         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 8, 8, 256)    768         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 8, 8, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 8, 8, 256)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_199[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 8, 8, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 8, 8, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 8, 8, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 35)           53795       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 54,390,531\n",
      "Trainable params: 53,795\n",
      "Non-trainable params: 54,336,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in IRnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = IRnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_breeds, activation='softmax')(x)\n",
    "\n",
    "model= Model(inputs=IRnet.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " \n",
    "#using SGD to compile or build the model\n",
    "optimizer = SGD()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 281s 11s/step - loss: 3.4838 - accuracy: 0.0857 - val_loss: 3.2323 - val_accuracy: 0.2050\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 296s 11s/step - loss: 3.0730 - accuracy: 0.3386 - val_loss: 2.8333 - val_accuracy: 0.6176\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 298s 11s/step - loss: 2.7065 - accuracy: 0.6548 - val_loss: 2.4610 - val_accuracy: 0.8254\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 2.3666 - accuracy: 0.8039 - val_loss: 2.1293 - val_accuracy: 0.8915\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 290s 11s/step - loss: 2.0738 - accuracy: 0.8443 - val_loss: 1.8384 - val_accuracy: 0.9099\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 295s 11s/step - loss: 1.8061 - accuracy: 0.8715 - val_loss: 1.5767 - val_accuracy: 0.9265\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 291s 11s/step - loss: 1.5745 - accuracy: 0.8841 - val_loss: 1.3564 - val_accuracy: 0.9366\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 1.3846 - accuracy: 0.8980 - val_loss: 1.1674 - val_accuracy: 0.9421\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 290s 11s/step - loss: 1.2235 - accuracy: 0.9034 - val_loss: 1.0173 - val_accuracy: 0.9458\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 1.0771 - accuracy: 0.9046 - val_loss: 0.8953 - val_accuracy: 0.9449\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 290s 11s/step - loss: 0.9672 - accuracy: 0.9089 - val_loss: 0.7955 - val_accuracy: 0.9458\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.8843 - accuracy: 0.9155 - val_loss: 0.7062 - val_accuracy: 0.9458\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 290s 11s/step - loss: 0.8150 - accuracy: 0.9083 - val_loss: 0.6419 - val_accuracy: 0.9504\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 292s 11s/step - loss: 0.7366 - accuracy: 0.9167 - val_loss: 0.5834 - val_accuracy: 0.9513\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 289s 11s/step - loss: 0.6913 - accuracy: 0.9179 - val_loss: 0.5319 - val_accuracy: 0.9531\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.6421 - accuracy: 0.9221 - val_loss: 0.4954 - val_accuracy: 0.9513\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 292s 11s/step - loss: 0.6067 - accuracy: 0.9221 - val_loss: 0.4612 - val_accuracy: 0.9485\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 296s 11s/step - loss: 0.5786 - accuracy: 0.9221 - val_loss: 0.4273 - val_accuracy: 0.9522\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 292s 11s/step - loss: 0.5392 - accuracy: 0.9234 - val_loss: 0.4011 - val_accuracy: 0.9513\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.5182 - accuracy: 0.9306 - val_loss: 0.3837 - val_accuracy: 0.9476\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 292s 11s/step - loss: 0.4909 - accuracy: 0.9252 - val_loss: 0.3615 - val_accuracy: 0.9485\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.4878 - accuracy: 0.9179 - val_loss: 0.3466 - val_accuracy: 0.9504\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 291s 11s/step - loss: 0.4601 - accuracy: 0.9270 - val_loss: 0.3299 - val_accuracy: 0.9494\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.4518 - accuracy: 0.9209 - val_loss: 0.3165 - val_accuracy: 0.9504\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 293s 11s/step - loss: 0.4497 - accuracy: 0.9209 - val_loss: 0.2997 - val_accuracy: 0.9531\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 296s 11s/step - loss: 0.4254 - accuracy: 0.9191 - val_loss: 0.2952 - val_accuracy: 0.9540\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 291s 11s/step - loss: 0.4053 - accuracy: 0.9234 - val_loss: 0.2861 - val_accuracy: 0.9540\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 293s 11s/step - loss: 0.3926 - accuracy: 0.9300 - val_loss: 0.2754 - val_accuracy: 0.9559\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.3839 - accuracy: 0.9252 - val_loss: 0.2703 - val_accuracy: 0.9522\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 297s 11s/step - loss: 0.3653 - accuracy: 0.9348 - val_loss: 0.2622 - val_accuracy: 0.9531\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 295s 11s/step - loss: 0.3817 - accuracy: 0.9215 - val_loss: 0.2591 - val_accuracy: 0.9522\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 295s 11s/step - loss: 0.3735 - accuracy: 0.9246 - val_loss: 0.2469 - val_accuracy: 0.9540\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 295s 11s/step - loss: 0.3485 - accuracy: 0.9264 - val_loss: 0.2438 - val_accuracy: 0.9531\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 297s 11s/step - loss: 0.3627 - accuracy: 0.9246 - val_loss: 0.2417 - val_accuracy: 0.9522\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 293s 11s/step - loss: 0.3431 - accuracy: 0.9306 - val_loss: 0.2352 - val_accuracy: 0.9531\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 306s 12s/step - loss: 0.3328 - accuracy: 0.9330 - val_loss: 0.2296 - val_accuracy: 0.9550\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 295s 11s/step - loss: 0.3317 - accuracy: 0.9336 - val_loss: 0.2229 - val_accuracy: 0.9540\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 305s 12s/step - loss: 0.3295 - accuracy: 0.9297 - val_loss: 0.2235 - val_accuracy: 0.9540\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 298s 11s/step - loss: 0.3292 - accuracy: 0.9282 - val_loss: 0.2164 - val_accuracy: 0.9540\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 293s 11s/step - loss: 0.3286 - accuracy: 0.9318 - val_loss: 0.2123 - val_accuracy: 0.9540\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 304s 12s/step - loss: 0.3295 - accuracy: 0.9282 - val_loss: 0.2119 - val_accuracy: 0.9513\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 301s 12s/step - loss: 0.3133 - accuracy: 0.9324 - val_loss: 0.2121 - val_accuracy: 0.9513\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.3189 - accuracy: 0.9276 - val_loss: 0.2022 - val_accuracy: 0.9531\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 306s 12s/step - loss: 0.2891 - accuracy: 0.9378 - val_loss: 0.2032 - val_accuracy: 0.9513\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 306s 12s/step - loss: 0.3138 - accuracy: 0.9270 - val_loss: 0.1962 - val_accuracy: 0.9550\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 295s 11s/step - loss: 0.3071 - accuracy: 0.9264 - val_loss: 0.1975 - val_accuracy: 0.9531\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.2735 - accuracy: 0.9445 - val_loss: 0.1975 - val_accuracy: 0.9531\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 299s 11s/step - loss: 0.2847 - accuracy: 0.9342 - val_loss: 0.1934 - val_accuracy: 0.9540\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 310s 12s/step - loss: 0.2965 - accuracy: 0.9318 - val_loss: 0.1957 - val_accuracy: 0.9522\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 320s 12s/step - loss: 0.2900 - accuracy: 0.9342 - val_loss: 0.1907 - val_accuracy: 0.9513\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "#fit the training generator data and train the model\n",
    "hist = model.fit(train_generator,\n",
    "                 steps_per_epoch= x_train.shape[0] // batch_size,\n",
    "                 epochs= epochs,callbacks=[callback],\n",
    "                 validation_data= test_generator,\n",
    "                 validation_steps= x_val.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9694\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(x_test)\n",
    "probs = np.argmax(predictions, axis=1)\n",
    "num_correct = (probs == y_test).sum()\n",
    "accuracy = num_correct/len(y_test)\n",
    "print('{:.4f}'.format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(num_breeds, activation='softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 149, 149, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 149, 149, 32) 96          conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 149, 149, 32) 0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 147, 147, 32) 9216        activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 147, 147, 32) 96          conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 147, 147, 32) 0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 147, 147, 64) 18432       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 147, 147, 64) 192         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 147, 147, 64) 0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 73, 73, 64)   0           activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 73, 73, 80)   240         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 73, 73, 80)   0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 71, 71, 192)  138240      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 71, 71, 192)  576         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 71, 71, 192)  0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 35, 35, 192)  0           activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 35, 35, 64)   192         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 35, 35, 64)   0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 35, 35, 96)   55296       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 35, 35, 48)   144         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 35, 35, 96)   288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 35, 35, 48)   0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 35, 35, 96)   0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 35, 35, 64)   76800       activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 35, 35, 96)   82944       activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 35, 35, 64)   192         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 35, 35, 64)   192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 35, 35, 96)   288         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 35, 35, 32)   96          conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 35, 35, 64)   0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 35, 35, 64)   0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 35, 35, 96)   0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 35, 35, 32)   0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_302[0][0]             \n",
      "                                                                 activation_304[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "                                                                 activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 35, 35, 64)   192         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 35, 35, 64)   0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 35, 35, 96)   55296       activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 35, 35, 48)   144         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 35, 35, 96)   288         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 35, 35, 48)   0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 35, 35, 96)   0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 35, 35, 64)   76800       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 35, 35, 96)   82944       activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 35, 35, 64)   192         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 35, 35, 64)   192         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 35, 35, 96)   288         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 35, 35, 64)   192         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 35, 35, 64)   0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 35, 35, 64)   0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 35, 35, 96)   0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 35, 35, 64)   0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_309[0][0]             \n",
      "                                                                 activation_311[0][0]             \n",
      "                                                                 activation_314[0][0]             \n",
      "                                                                 activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 35, 35, 64)   192         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 35, 35, 64)   0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 35, 35, 96)   55296       activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 35, 35, 48)   144         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 35, 35, 96)   288         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 35, 35, 48)   0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 35, 35, 96)   0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 35, 35, 64)   76800       activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 35, 35, 96)   82944       activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 35, 35, 64)   192         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 35, 35, 64)   192         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 35, 35, 96)   288         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 35, 35, 64)   192         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 35, 35, 64)   0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 35, 35, 64)   0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 35, 35, 96)   0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 35, 35, 64)   0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_316[0][0]             \n",
      "                                                                 activation_318[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 35, 35, 64)   192         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 35, 35, 64)   0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 35, 35, 96)   55296       activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 35, 35, 96)   288         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 35, 35, 96)   0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 17, 17, 96)   82944       activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 17, 17, 384)  1152        conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 17, 17, 96)   288         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 17, 17, 384)  0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 17, 17, 96)   0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_323[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 17, 17, 128)  384         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 17, 17, 128)  0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 17, 17, 128)  114688      activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 17, 17, 128)  384         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 17, 17, 128)  0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 17, 17, 128)  114688      activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 17, 17, 128)  384         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 17, 17, 128)  384         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 17, 17, 128)  0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 17, 17, 128)  0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 17, 17, 128)  114688      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 17, 17, 128)  114688      activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 17, 17, 128)  384         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 17, 17, 128)  384         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 17, 17, 128)  0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 17, 17, 128)  0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 17, 17, 192)  172032      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 17, 17, 192)  172032      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 17, 17, 192)  576         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 17, 17, 192)  576         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 17, 17, 192)  576         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 17, 17, 192)  576         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 17, 17, 192)  0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 17, 17, 192)  0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 17, 17, 192)  0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 17, 17, 192)  0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_327[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "                                                                 activation_335[0][0]             \n",
      "                                                                 activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 17, 17, 160)  480         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 17, 17, 160)  0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 17, 17, 160)  179200      activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 17, 17, 160)  480         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 17, 17, 160)  0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 17, 17, 160)  179200      activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 17, 17, 160)  480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 17, 17, 160)  480         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 17, 17, 160)  0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 17, 17, 160)  0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 17, 17, 160)  179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 17, 17, 160)  179200      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 17, 17, 160)  480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 17, 17, 160)  480         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 17, 17, 160)  0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 17, 17, 160)  0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 17, 17, 192)  215040      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 17, 17, 192)  215040      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 17, 17, 192)  576         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 17, 17, 192)  576         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 17, 17, 192)  576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 17, 17, 192)  576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 17, 17, 192)  0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 17, 17, 192)  0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 17, 17, 192)  0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 17, 17, 192)  0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_337[0][0]             \n",
      "                                                                 activation_340[0][0]             \n",
      "                                                                 activation_345[0][0]             \n",
      "                                                                 activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 17, 17, 160)  480         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 17, 17, 160)  0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 17, 17, 160)  179200      activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 17, 17, 160)  480         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 17, 17, 160)  0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 17, 17, 160)  179200      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 17, 17, 160)  480         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 17, 17, 160)  480         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 17, 17, 160)  0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 17, 17, 160)  0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 17, 17, 160)  179200      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 17, 17, 160)  179200      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 17, 17, 160)  480         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 17, 17, 160)  480         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 17, 17, 160)  0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 17, 17, 160)  0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 17, 17, 192)  215040      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 17, 17, 192)  215040      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 17, 17, 192)  576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 17, 17, 192)  576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 17, 17, 192)  576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 17, 17, 192)  576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 17, 17, 192)  0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 17, 17, 192)  0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 17, 17, 192)  0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 17, 17, 192)  0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_347[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "                                                                 activation_355[0][0]             \n",
      "                                                                 activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 17, 17, 192)  576         conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 17, 17, 192)  0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 17, 17, 192)  258048      activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 17, 17, 192)  576         conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 17, 17, 192)  0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 17, 17, 192)  258048      activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 17, 17, 192)  576         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 17, 17, 192)  576         conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 17, 17, 192)  0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 17, 17, 192)  0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 17, 17, 192)  258048      activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 17, 17, 192)  258048      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 17, 17, 192)  576         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 17, 17, 192)  576         conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 17, 17, 192)  0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 17, 17, 192)  0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 17, 17, 192)  258048      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 17, 17, 192)  258048      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 17, 17, 192)  576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 17, 17, 192)  576         conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 17, 17, 192)  576         conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 17, 17, 192)  576         conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 17, 17, 192)  0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 17, 17, 192)  0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 17, 17, 192)  0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 17, 17, 192)  0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_357[0][0]             \n",
      "                                                                 activation_360[0][0]             \n",
      "                                                                 activation_365[0][0]             \n",
      "                                                                 activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 17, 17, 192)  576         conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 17, 17, 192)  0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 17, 17, 192)  258048      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 17, 17, 192)  576         conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 17, 17, 192)  0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 17, 17, 192)  258048      activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 17, 17, 192)  576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 17, 17, 192)  576         conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 17, 17, 192)  0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 17, 17, 192)  0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 8, 8, 320)    552960      activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 8, 8, 192)    331776      activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 8, 8, 320)    960         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 8, 8, 192)    576         conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 8, 8, 320)    0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 8, 8, 192)    0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_368[0][0]             \n",
      "                                                                 activation_372[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 8, 8, 448)    1344        conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 8, 8, 448)    0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 8, 8, 384)    1548288     activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 8, 8, 384)    1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 8, 8, 384)    1152        conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 8, 8, 384)    0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 8, 8, 384)    0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 8, 8, 384)    442368      activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 8, 8, 384)    442368      activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 8, 8, 384)    442368      activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 8, 8, 384)    442368      activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 8, 8, 384)    1152        conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 8, 8, 384)    1152        conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 8, 8, 384)    1152        conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 8, 8, 384)    1152        conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 8, 8, 320)    960         conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 8, 8, 384)    0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 8, 8, 384)    0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 8, 8, 384)    0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 8, 8, 384)    0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 8, 8, 192)    576         conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 8, 8, 320)    0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_375[0][0]             \n",
      "                                                                 activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_379[0][0]             \n",
      "                                                                 activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 8, 8, 192)    0           batch_normalization_382[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_373[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 8, 8, 448)    1344        conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 8, 8, 448)    0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 8, 8, 384)    1548288     activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 8, 8, 384)    1152        conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 8, 8, 384)    1152        conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 8, 8, 384)    0           batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 8, 8, 384)    0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 8, 8, 384)    442368      activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 8, 8, 384)    442368      activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 8, 8, 384)    442368      activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 8, 8, 384)    442368      activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 8, 8, 384)    1152        conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 8, 8, 384)    1152        conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 8, 8, 384)    1152        conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 8, 8, 384)    1152        conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 8, 8, 320)    960         conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 8, 8, 384)    0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 8, 8, 384)    0           batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 8, 8, 384)    0           batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 8, 8, 384)    0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 8, 8, 192)    576         conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 8, 8, 320)    0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_384[0][0]             \n",
      "                                                                 activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_388[0][0]             \n",
      "                                                                 activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 8, 8, 192)    0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_382[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          1049088     global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 35)           17955       dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,869,827\n",
      "Trainable params: 1,067,043\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 136s 5s/step - loss: 1.3219 - accuracy: 0.6886 - val_loss: 0.2034 - val_accuracy: 0.9366\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 132s 5s/step - loss: 0.3626 - accuracy: 0.8890 - val_loss: 0.2051 - val_accuracy: 0.9347\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 129s 5s/step - loss: 0.3712 - accuracy: 0.8793 - val_loss: 0.1689 - val_accuracy: 0.9458\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 130s 5s/step - loss: 0.2804 - accuracy: 0.9113 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 130s 5s/step - loss: 0.2770 - accuracy: 0.9161 - val_loss: 0.2021 - val_accuracy: 0.9357\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 130s 5s/step - loss: 0.2533 - accuracy: 0.9191 - val_loss: 0.2352 - val_accuracy: 0.9366\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 133s 5s/step - loss: 0.2213 - accuracy: 0.9312 - val_loss: 0.1826 - val_accuracy: 0.9375\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 121s 5s/step - loss: 0.2116 - accuracy: 0.9306 - val_loss: 0.2188 - val_accuracy: 0.9393\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist = model.fit(train_generator,\n",
    "                 steps_per_epoch= x_train.shape[0] // batch_size,\n",
    "                 epochs= epochs,callbacks=[callback],\n",
    "                 validation_data= test_generator,\n",
    "                 validation_steps= x_val.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9582\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(x_test)\n",
    "probs = np.argmax(predictions, axis=1)\n",
    "num_correct = (probs == y_test).sum()\n",
    "accuracy = num_correct/len(y_test)\n",
    "print('{:.4f}'.format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Model selection and fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model             | Optimizer | Epochs | Train Acc(Final) | Test Acc |\n",
    "|-------------------|-----------|--------|------------------|----------|\n",
    "| Resnet50V2        | RmsProp   | 12     | 83.65%           | 85.52%   |\n",
    "| InceptionResnetV2 | SGD       | 50     | 93.42%           | 96.94%   |\n",
    "| InceptionV3       | Adam      | 8      | 93.06%           | 95.82%   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained and tested 3 different pretrained models using transfer learning, we will now pick a model to retrain and fine tune to try and improve the performance of the model in terms of accuracy.\n",
    "\n",
    "From above we can see that InceptionResNetV2 is the best performing one in terms of the train and test accuracy followed by InceptionV3, then by Resnet50. Given the default optimizers that where used  with no fine tuning.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these models performed really well with our data achieving higher than 80% for both final training and test accuracy.\n",
    "\n",
    "For this project we will select InceptionV3 to fine tune. We will use this model since it was able to get a results similar to the InceptionResnetV2 model but it did it in a shorter time. We will try to fine tune the model to see if there can be improvements made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fine tuning InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of fine tuning the model, one way is to change some hyperparameters to get the best result, we will try changing the learning rate of the model and see if there are improvements.\n",
    "\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fine tuning we will use keras tuner , which is a library by keras that allows hyperparamater tuning in deep learning. One of the inputs needed for the tuner is a model builder that will build the model and also use hyperparameters so we will make one now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    #instantiate base model\n",
    "    base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(299, 299, 3))\n",
    "    #freeze convolutional layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    #get the extracted features from the base model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "   \n",
    "    \n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    #choose from learning rates of 0.01, 0.001,  0.0001 , or 0.0003\n",
    "    lr=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4 ,3e-4])\n",
    "    predictions = Dense(num_breeds, activation='softmax')(x)\n",
    "    model = Model(inputs = base_model.input, outputs = predictions)\n",
    "    model.compile(Adam(lr=lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then instantiate a keras tuner, we will use RandomSearch tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_trials=4\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then we call on the search function of the tuner to get the best hyperparameters. The parameters needed is similar to the fit function of the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 18m 05s]\n",
      "val_accuracy: 0.9439338445663452\n",
      "\n",
      "Best val_accuracy So Far: 0.9595588445663452\n",
      "Total elapsed time: 02h 44m 14s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "stop_early = callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(train_generator,\n",
    "                 steps_per_epoch= x_train.shape[0] // batch_size,\n",
    "                 epochs= epochs,callbacks=[stop_early],\n",
    "                 validation_data= test_generator,\n",
    "                 validation_steps= x_val.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the best learning rate from tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.The optimal learning rate for the optimizer\n",
      "is 0.0001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_adam_hps=tuner.get_best_hyperparameters()[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.The optimal learning rate for the optimizer\n",
    "is {best_adam_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we rebuild our model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_adam_hps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we retrain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 141s 5s/step - loss: 3.1108 - accuracy: 0.3125 - val_loss: 2.4002 - val_accuracy: 0.7831\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 143s 6s/step - loss: 1.9441 - accuracy: 0.7779 - val_loss: 1.2669 - val_accuracy: 0.9127\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 142s 5s/step - loss: 1.0865 - accuracy: 0.8564 - val_loss: 0.6439 - val_accuracy: 0.9412\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.6695 - accuracy: 0.8932 - val_loss: 0.4121 - val_accuracy: 0.9393\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.4826 - accuracy: 0.9053 - val_loss: 0.3137 - val_accuracy: 0.9485\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 144s 6s/step - loss: 0.3865 - accuracy: 0.9209 - val_loss: 0.2609 - val_accuracy: 0.9531\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.3837 - accuracy: 0.9034 - val_loss: 0.2431 - val_accuracy: 0.9449\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.3370 - accuracy: 0.9221 - val_loss: 0.2204 - val_accuracy: 0.9504\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 142s 5s/step - loss: 0.3139 - accuracy: 0.9131 - val_loss: 0.1965 - val_accuracy: 0.9540\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.2915 - accuracy: 0.9252 - val_loss: 0.1897 - val_accuracy: 0.9586\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.2832 - accuracy: 0.9197 - val_loss: 0.1900 - val_accuracy: 0.9494\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.2495 - accuracy: 0.9360 - val_loss: 0.1771 - val_accuracy: 0.9513\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.2623 - accuracy: 0.9276 - val_loss: 0.1800 - val_accuracy: 0.9540\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.2361 - accuracy: 0.9306 - val_loss: 0.1721 - val_accuracy: 0.9513\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 145s 6s/step - loss: 0.2288 - accuracy: 0.9384 - val_loss: 0.1724 - val_accuracy: 0.9550\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.2375 - accuracy: 0.9330 - val_loss: 0.1720 - val_accuracy: 0.9467\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1999 - accuracy: 0.9403 - val_loss: 0.1613 - val_accuracy: 0.9513\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 142s 5s/step - loss: 0.2162 - accuracy: 0.9360 - val_loss: 0.1588 - val_accuracy: 0.9550\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.2194 - accuracy: 0.9372 - val_loss: 0.1588 - val_accuracy: 0.9540\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 137s 5s/step - loss: 0.1990 - accuracy: 0.9445 - val_loss: 0.1630 - val_accuracy: 0.9531\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 138s 5s/step - loss: 0.2063 - accuracy: 0.9360 - val_loss: 0.1636 - val_accuracy: 0.9559\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 137s 5s/step - loss: 0.1780 - accuracy: 0.9511 - val_loss: 0.1557 - val_accuracy: 0.9605\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1902 - accuracy: 0.9493 - val_loss: 0.1607 - val_accuracy: 0.9494\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 138s 5s/step - loss: 0.1927 - accuracy: 0.9439 - val_loss: 0.1564 - val_accuracy: 0.9504\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 138s 5s/step - loss: 0.1773 - accuracy: 0.9439 - val_loss: 0.1605 - val_accuracy: 0.9531\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1762 - accuracy: 0.9445 - val_loss: 0.1566 - val_accuracy: 0.9513\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 145s 6s/step - loss: 0.1581 - accuracy: 0.9547 - val_loss: 0.1551 - val_accuracy: 0.9550\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1636 - accuracy: 0.9505 - val_loss: 0.1606 - val_accuracy: 0.9531\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 142s 5s/step - loss: 0.1647 - accuracy: 0.9487 - val_loss: 0.1531 - val_accuracy: 0.9559\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 142s 5s/step - loss: 0.1545 - accuracy: 0.9493 - val_loss: 0.1579 - val_accuracy: 0.9513\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1636 - accuracy: 0.9499 - val_loss: 0.1599 - val_accuracy: 0.9485\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.1331 - accuracy: 0.9626 - val_loss: 0.1502 - val_accuracy: 0.9550\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 140s 5s/step - loss: 0.1384 - accuracy: 0.9590 - val_loss: 0.1583 - val_accuracy: 0.9522\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1461 - accuracy: 0.9578 - val_loss: 0.1599 - val_accuracy: 0.9485\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1417 - accuracy: 0.9602 - val_loss: 0.1556 - val_accuracy: 0.9550\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1406 - accuracy: 0.9565 - val_loss: 0.1562 - val_accuracy: 0.9522\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 139s 5s/step - loss: 0.1472 - accuracy: 0.9547 - val_loss: 0.1581 - val_accuracy: 0.9494\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "hist = model.fit(train_generator,\n",
    "                 steps_per_epoch= x_train.shape[0] // batch_size,\n",
    "                 epochs= epochs,callbacks=[callback],\n",
    "                 validation_data= test_generator,\n",
    "                 validation_steps= x_val.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(x_test)\n",
    "probs = np.argmax(predictions, axis=1)\n",
    "num_correct = (probs == y_test).sum()\n",
    "accuracy = num_correct/len(y_test)\n",
    "print('{:.4f}'.format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Insights and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
